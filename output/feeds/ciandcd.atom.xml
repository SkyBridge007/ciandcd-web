<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>ciandcd</title><link href="http://www.ciandcd.com/" rel="alternate"></link><link href="http://www.ciandcd.com/feeds/ciandcd.atom.xml" rel="self"></link><id>http://www.ciandcd.com/</id><updated>2015-06-27T08:31:19+08:00</updated><entry><title>Book Review: The Phoenix Project</title><link href="http://www.ciandcd.com/book-review-the-phoenix-project.html" rel="alternate"></link><updated>2015-06-27T08:31:19+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:book-review-the-phoenix-project.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2013/01/book-review-the-phoenix-project/"&gt;http://continuousdelivery.com/2013/01/book-review-the-phoenix-project/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Book Review: The Phoenix Project&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;I am not going to do a ton of book reviews on this blog (I have one more planned for next month). I&amp;#8217;ll only bother posting reviews of books that I believe are both excellent and relevant to &lt;a href="http://continuousdelivery.com/"&gt;Continuous Delivery&lt;/a&gt;. This book easily satisfies both criteria. Full disclosure: Gene gave me a draft of this book for free for reviewing purposes.&lt;/p&gt;
&lt;p&gt;You&amp;#8217;ve probably heard of Gene Kim, Kevin Behr and George Spafford before. They are the three amigos responsible for &lt;a href="http://www.amazon.com/dp/0975568612?tag=contindelive-20"&gt;The Visible Ops Handbook&lt;/a&gt;, which can be found in the book pile of every good IT operator. Their new book, &lt;a href="http://www.amazon.com/dp/0988262592?tag=contindelive-20"&gt;The Phoenix Project:  A Novel About IT, DevOps, and Helping Your Business Win&lt;/a&gt;, follows the format of Eliyahu Goldratt&amp;#8217;s classic, &lt;a href="http://www.amazon.com/dp/0884271951?tag=contindelive-20"&gt;The Goal&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Told from the perspective of newly-minted VP of IT Operations Bill Palmer, it describes the turnaround of failing auto parts company Parts Unlimited. This is to be achieved through the delivery of the eponymous Phoenix Project, a classic &amp;#8220;too big to fail&amp;#8221; software project designed to build a system which will revive the fortunes of the company.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;To quote (p51):&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;
The plot is simple: First, you take an urgent date-driven project, where the shipment date cannot be delayed because of external commitments made to Wall Street or customers. Then you add a bunch of developers who use up all the time in the schedule, leaving no time for testing or operations deployment. And because no one is willing to slip the deployment date, everyone after Development has to take outrageous and unacceptable shortcuts to hit the date.&lt;/p&gt;
&lt;p&gt;The results are never pretty. Usually, the software product is so unstable and unusable that even the people who were screaming for it end up saying that it&amp;#8217;s not worth shipping. And it&amp;#8217;s always IT Operations who still has to stay up all night, rebooting servers hourly to compensate for crappy code, doing whatever heroics are required to hide from the rest of the world just how bad things really are.
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Part One of the book describes in loving detail the enormous clusterfuck pie that is baked from these ingredients. The pie is spiced with an internal Sarbanes-Oxley audit which reveals 952 control deficiencies, an outage of the payroll processing system, and various other problems that conspire to deepen the woe of the operations group, all of which are clearly drawn from the deep well of the authors&amp;#8217; real-life experiences.&lt;/p&gt;
&lt;p&gt;Apart from the main characters &amp;#8211; our hero Bill, his boss Steve, and the evil villain Sarah &amp;#8211; The Phoenix Project features a delightful rogues&amp;#8217; gallery which anyone working in an enterprise will recognize:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Brent Geller, the boy wonder whose encyclopedic knowledge of the company&amp;#8217;s Byzantine IT systems means that his involvement is necessary to get anything done.&lt;/li&gt;
&lt;li&gt;Patty McKee, the Director of Support who runs a change management process so bureaucratic that everybody bypasses it.&lt;/li&gt;
&lt;li&gt;John Pesche, the black binder wielding Chief Information Security Officer whose constant meddling under the guise of improving security has turned him into a pariah.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second part of the book details how the IT group is reborn from the ashes of the Phoenix Project into a high-performing organization that is a strategic partner to the business. This is achieved through the application of a heavy dose of lean thinking (including &lt;a href="http://www.amazon.com/dp/0321601912?tag=contindelive-20"&gt;continuous delivery&lt;/a&gt;) administered by Erik, a mercurial IT and manufacturing guru Steve is courting to join the board. The book does an excellent job of showing &amp;#8211; as well as telling &amp;#8211; how to apply the concepts (and the effect of doing so) in an enterprise with plenty of technical debt. Perhaps the most eyebrow-raising part of this section is the way in which John has his soul mercilessly crushed to the point where he goes on a multi-day drinking spree before he is rehabilitated towards the end of the book (he is a phoenix too).&lt;/p&gt;
&lt;p&gt;John&amp;#8217;s narrative arc is just one example of how the book also succeeds as a novel. It&amp;#8217;s gripping, with moments of drama and high emotion, as well as some great one-liners. There was even one point when I teared up (bear in mind that I also cried during Forrest Gump &amp;#8211; unlike the book&amp;#8217;s central characters, I did not serve in the armed forces). &lt;/p&gt;
&lt;p&gt;Nobody who has read The Goal will miss The Phoenix Project&amp;#8217;s similarity in terms of style and plot. Perhaps my favourite thing about the book&amp;#8217;s pedagogical style is the way Erik (like Jonah in The Goal) uses the Socratic Method to give Bill the tools to solve his problems by himself. Of course this learning process is fictional, but it means you get to see Bill struggling with the questions and trying things out.&lt;/p&gt;
&lt;p&gt;It remains to be seen whether readers of the book will be able to apply these techniques as successfully as Bill without a real Erik to guide them. But of course, this is a limitation of any book. If I had one criticism it&amp;#8217;s that unlike real life, there aren&amp;#8217;t many experiments in the book that end up making things worse, and it&amp;#8217;s this process of failing fast, learning from your failures, and coming up with new experiments that is instrumental to a real learning culture.&lt;/p&gt;
&lt;p&gt;One important point worth noting if you are working in an organization like Parts Unlimited is this: the IT department&amp;#8217;s rebirth is only possible because of the Titanic proportions of the disaster that unfolds in Part One. For management to truly embrace change, a compelling event or a teachable moment (i.e. a Charlie Foxtrot) is required. Unless your organization faces the same existential threat that Parts Unlimited does, you&amp;#8217;ll have a much harder time convincing people they should adopt the tools described in the book.&lt;/p&gt;
&lt;p&gt;Overall, The Phoenix Project is a fantastic read. It&amp;#8217;s entertaining, cathartic, inspirational and informative. If, like me, you have an enormous backlog of books (and more work in process than you&amp;#8217;d like) I suggest giving yourself a break and putting this one to the top of your list. It&amp;#8217;ll only take you a day or two, and despite its conceptual density it will leave you feeling refreshed and energized with a bunch of new ideas to try out. &lt;a href="http://www.amazon.com/dp/0988262592?tag=contindelive-20"&gt;The Phoenix Project&lt;/a&gt; deserves to be read by everyone who works in &amp;#8211; or with &amp;#8211; IT.&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>Continuous Delivery</title><link href="http://www.ciandcd.com/continuous-delivery.html" rel="alternate"></link><updated>2015-06-27T08:31:18+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:continuous-delivery.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2013/05/announcing-flowcon/"&gt;http://continuousdelivery.com/2013/05/announcing-flowcon/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Announcing FlowCon&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;I spend quite a lot of time at conferences, and it consistently bothers me that they are so often focused on one particular function: development, testing, UX, systems administration. The point of continuous delivery is to accelerate the rate at which we can learn from each other &amp;#8211; and from our customers. That requires everyone involved in the delivery process (including users, product owners and entrepreneurs) to collaborate throughout. So why isn&amp;#8217;t there a conference which focuses on flow &amp;#8211; the emergent property of great teams?&lt;/p&gt;
&lt;p&gt;So I got together with a bunch of like-minded folks &amp;#8211; &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Elizabeth+Hendrickson"&gt;Elisabeth Hendrickson&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Gene+Kim"&gt;Gene Kim&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/John+Esser"&gt;John Esser&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Lane+Halley"&gt;Lane Halley&lt;/a&gt; &amp;#8211; and now there is a conference about creating flow: &lt;a href="http://flowcon.org/"&gt;FlowCon&lt;/a&gt;. It&amp;#8217;s on &lt;strong&gt;Friday November 1 in San Francisco&lt;/strong&gt;, and it&amp;#8217;s produced by &lt;a href="http://www.thoughtworks.com/"&gt;ThoughtWorks&lt;/a&gt; and &lt;a href="http://www.trifork.com/"&gt;Trifork&lt;/a&gt; (creators of the &lt;a href="http://gotocon.com/"&gt;GOTO conferences&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;The conference is based around four values:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning&lt;/strong&gt;: Our goal is to provide the best possible conference forum for practitioners to learn from each other how to build great products and services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open Information&lt;/strong&gt;: We aim to uncover how great products and services are built in real life and make this information freely available to the widest audience possible.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Diversity&lt;/strong&gt;: We believe the technology community &amp;#8211; and thus the conference speakers and participants &amp;#8211; should reflect the demographics of our customers and the wider world.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spanning boundaries&lt;/strong&gt;: We believe that the best products and services are created collaboratively by people with a range of skills and experiences.&lt;/p&gt;
&lt;p&gt;We have put together nearly half of the &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;program&lt;/a&gt;, and we&amp;#8217;re delighted to announce that &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Adrian+Cockcroft"&gt;Adrian Cockcroft&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Catherine+Courage"&gt;Catherine Courage&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Jeff+Gothelf"&gt;Jeff Gothelf&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Linda+Rising"&gt;Linda Rising&lt;/a&gt; will be giving keynotes. &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;The program&lt;/a&gt; is still a work in process (a minimum viable product, if you will). In particular, the after lunch sessions are empty &amp;#8211; for a good reason: &lt;strong&gt;we want you to speak in those slots&lt;/strong&gt;. We&amp;#8217;re looking for people working to create flow in their organization &amp;#8211; especially those who:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Span multiple roles and work across organizational silos.&lt;/li&gt;
&lt;li&gt;Work in any of the following areas: a highly regulated environment; a large, traditional enterprise; in the pursuit of social and economic justice.&lt;/li&gt;
&lt;li&gt;Are willing to share obstacles encountered or mistakes made and how you overcame them &amp;#8211; whether cultural or technological.&lt;/li&gt;
&lt;li&gt;Offer actionable advice &amp;#8220;the rest of us&amp;#8221; can apply today (even if we don&amp;#8217;t have the resources of Etsy / Amazon / Google).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Your talk could be about culture, technology, design, process &amp;#8211; the only really important criterion is that it draws on what you&amp;#8217;ve learned about helping to create flow in your organization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If that sounds like you, please &lt;a href="http://flowcon.org/flowcon-sanfran-2013/submit"&gt;submit your proposal&lt;/a&gt;. If you know someone who would do a great job, please encourage them to submit. Our submission process is designed to be entirely merit-based, which means that the first round is anonymous. The deadline is midnight Pacific time, Sunday June 23, 2013.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://secure.trifork.com/flowcon-sanfran-2013/registration/"&gt;Tickets for the conference are now on sale&lt;/a&gt; &amp;#8211; at $350 if you register before July 31, or $500 if you register afterwards. Whatever your role or domain, you&amp;#8217;re sure to find inspirational, disruptive thinking that will make you better at creating great products and services. I hope to see you there!&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>Videos from the Continuous Delivery track at QCon SF 2012</title><link href="http://www.ciandcd.com/videos-from-the-continuous-delivery-track-at-qcon-sf-2012.html" rel="alternate"></link><updated>2015-06-27T08:31:17+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:videos-from-the-continuous-delivery-track-at-qcon-sf-2012.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2013/05/videos-from-the-continuous-delivery-track-at-qcon-sf-2012/"&gt;http://continuousdelivery.com/2013/05/videos-from-the-continuous-delivery-track-at-qcon-sf-2012/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Videos from the Continuous Delivery track at QCon SF 2012&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;At last year&amp;#8217;s QCon San Francisco I got to curate a track on continuous delivery. One of the goals of the &lt;a href="http://www.qconferences.com/"&gt;QCon conferences&lt;/a&gt; is &amp;#8220;information Robin Hood&amp;#8221; &amp;#8211; finding ways to get out into public the secret sauce of high performing organizations. So I set out to find talks that would answer the questions I frequently get asked: can continuous integration, automated testing, and trunk-based development scale? How does continuous delivery affect the way we do product management? What&amp;#8217;s the business case for continuous delivery? How do you grow a culture that enables it?&lt;/p&gt;
&lt;p&gt;You&amp;#8217;ll find the all these questions answered in the talks below, from the leaders who have been at the forefront of continuous delivery at Amazon, Facebook, Google and Etsy. They also discuss the tools they built and the and practices they use to enable continuous delivery. Finally, you get me talking about how you can adopt continuous delivery at your organization.&lt;/p&gt;
&lt;p&gt;Thanks so much to Jesse Robbins, Frank Harris, Nell Thomas, John Penix and Chuck Rossi for these great talks, and to the folks behind &lt;a href="http://qconsf.com/"&gt;QCon SF&lt;/a&gt; for an awesome conference.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;a href="http://twitter.com/jesserobbins"&gt;Jesse Robbins&lt;/a&gt; ran ops at Amazon before quitting to co-found Opscode (creators of &lt;a href="http://www.opscode.com/chef/"&gt;Chef&lt;/a&gt;). He is also co-founder of &lt;a href="velocityconf.com"&gt;Velocity&lt;/a&gt;. In his copious spare time, he&amp;#8217;s a volunteer firefighter. Basically, Jesse is an enormous over-achiever. This is a fabulous &amp;#8211; and hilarious &amp;#8211; talk that discusses the hardest part of implementing continuous delivery: cultural change. This talk features my favourite devops aphorism:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.infoq.com/presentations/Hacking-Culture"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-9.15.46-AM.png" alt="Don&amp;#x27;t fight stupid, make more awesome" width="400" class="alignleft size-full wp-image-967"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br clear="all"&gt;&lt;/p&gt;
 
&lt;p&gt;One of the main goals of continuous delivery is to get fast feedback on your &lt;a href="http://www.drdobbs.com/architecture-and-design/hypothesis-driven-development/229000656"&gt;hypotheses&lt;/a&gt; so you can build the right thing. In this talk &lt;a href="http://twitter.com/hirefrank"&gt;Frank Harris&lt;/a&gt; and &lt;a href="http://twitter.com/nellwyn"&gt;Nell Thomas&lt;/a&gt; of &lt;a href="http://codeascraft.com/"&gt;Etsy&lt;/a&gt; show off a bunch of their tools, including the A/B testing framework they built for running experiments (which uses &lt;a href="http://martinfowler.com/bliki/FeatureToggle.html"&gt;feature toggles&lt;/a&gt; under the hood). They give an example of an experiment they&amp;#8217;re running right now, and discuss how the ability to gather and analyze data on customer behaviour in real time (see screenshot below) affects the way they do product development.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.infoq.com/presentations/Etsy-Deployment"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-10.31.38-AM.png" alt="Etsy&amp;#x27;ss A/B testing tool, Atlas" width="400" class="alignleft size-full wp-image-971"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br clear="all"&gt;&lt;/p&gt;
 
&lt;p&gt;In this talk, &lt;a href="http://research.google.com/pubs/author2207.html"&gt;John Penix&lt;/a&gt; of Google shows off the awesome product he and his team built for continuous integration and cloud-based testing at Google. Teams at Google are free to choose their own development practices and toolchain, but this one has a pretty high uptake. When people ask me if trunk-based development and continuous integration can scale, I like to show them the following slide:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.infoq.com/presentations/Continuous-Testing-Build-Cloud"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-11.15.03-AM.png" alt="CI at scale at Google" width="400" class="alignleft size-full wp-image-979"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br clear="all"&gt;&lt;/p&gt;
 
&lt;p&gt;In addition to discussing the process he uses to release twice a day, Facebook&amp;#8217;s lead release engineer &lt;a href="http://twitter.com/chuckr"&gt;Chuck Rossi&lt;/a&gt; shows off the extensive toolchain they built to deploy at scale. Highlights include Gatekeeper (screenshot below), which manages who gets to see which features as part of their dark launching process, and their deploy tool which categorizes all proposed patches based on the size of the patch, the amount of discussion around it, and the &amp;#8220;push karma&amp;#8221; of the committers. &lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.infoq.com/presentations/Facebook-Release-Process"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-11.39.28-AM.png" alt="Gatekeeper" width="400" class="alignleft size-full wp-image-982"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br clear="all"&gt;&lt;/p&gt;
 
&lt;p&gt;Amazon, Etsy, Google and Facebook are all primarily software development shops which command enormous amounts of resources. They are, to use &lt;a href="https://twitter.com/BMC_DevOps"&gt;Christopher Little&amp;#8217;s&lt;/a&gt; metaphor, unicorns. How can the rest of us adopt continuous delivery? That&amp;#8217;s the subject of my talk, which describes four case studies of organizations that adopted continuous delivery, with varying degrees of success.&lt;/p&gt;
&lt;p&gt;One of my favourites &amp;#8211; partly because it&amp;#8217;s embedded software, not a website &amp;#8211; is the story of HP&amp;#8217;s LaserJet Firmware team, who re-architected their software around the principles of continuous delivery. People always want to know the business case for continuous delivery: the FutureSmart team provide one in &lt;a href="http://www.amazon.com/dp/0321821726?tag=contindelive-20"&gt;the book they wrote&lt;/a&gt; that discusses how they did it:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-11.51.39-AM.png"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-11.51.39-AM.png" alt="Economics of continuous delivery" width="400" class="alignleft size-full wp-image-984"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>Risk Management Theatre: On Show At An Organization Near You</title><link href="http://www.ciandcd.com/risk-management-theatre-on-show-at-an-organization-near-you.html" rel="alternate"></link><updated>2015-06-27T08:31:16+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:risk-management-theatre-on-show-at-an-organization-near-you.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2013/08/risk-management-theatre/"&gt;http://continuousdelivery.com/2013/08/risk-management-theatre/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&amp;#13;
&amp;#13;
				 &amp;#13;
		 &amp;#13;
		 &amp;#13;
		&amp;#13;
				&amp;#13;
&amp;#13;
		 &amp;#13;
		&amp;#13;
&amp;#13;
		&amp;#13;
		&amp;#13;
				&lt;a href="http://continuousdelivery.com/2013/09/how-we-got-40-female-speakers-at-flowcon/" rel="next"&gt;How To Create A More Diverse Tech Conference&lt;/a&gt; &amp;#160;&lt;a href="http://continuousdelivery.com/2013/05/videos-from-the-continuous-delivery-track-at-qcon-sf-2012/" rel="prev"&gt;Videos from the Continuous Delivery track at QCon SF 2012&lt;/a&gt; &amp;#187;&lt;p class="post-headline"&gt;&lt;h1&gt;Risk Management Theatre: On Show At An Organization Near You&lt;/h1&gt;&lt;/p&gt;				&lt;p&gt;&lt;strong&gt;Translations:&lt;/strong&gt; &lt;a href="http://cdkr.egloos.com/1908527"&gt;&amp;#54620;&amp;#44397;&amp;#47568;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One of the concepts that will feature in the &lt;a href="http://www.amazon.com/dp/1449368425?tag=contindelive-20"&gt;new book I am working on&lt;/a&gt; is &amp;#8220;risk management theatre&amp;#8221;. This is the name I coined for the commonly-encountered control apparatus, imposed in a top-down way, which makes life painful for the innocent but can be circumvented by the guilty (the name comes by analogy with &lt;a href="http://www.vanityfair.com/culture/features/2011/12/tsa-insanity-201112"&gt;security theatre&lt;/a&gt;.) Risk management theatre is the outcome of optimizing processes for the case that somebody will do something stupid or bad, because (to quote &lt;a href="http://www.amazon.com/dp/0470405163?tag=contindelive-20"&gt;Bjarte Bogsnes talking about management&lt;/a&gt;), &amp;#8220;there might be someone who who cannot be trusted. The strategy seems to be preventative control on everybody instead of damage control on those few.&amp;#8221;&lt;/p&gt;
&lt;p&gt;Unfortunately risk management theatre is everywhere in large organizations, and reflects the continuing dominance of the &lt;a href="http://en.wikipedia.org/wiki/Theory_X_and_Theory_Y"&gt;Theory X&lt;/a&gt; management paradigm. The alternative to the top-down control approach is what I have called adaptive risk management, informed by human-centred management theories (for example the work of &lt;a href="http://www.amazon.com/dp/0071808019?tag=contindelive-20"&gt;Ohno&lt;/a&gt;, &lt;a href="https://www.deming.org/theman/theories/fourteenpoints"&gt;Deming&lt;/a&gt;, Drucker, &lt;a href="http://www.forbes.com/sites/stevedenning/2013/06/28/the-financial-times-flubs-the-management-revolution/"&gt;Denning&lt;/a&gt; and &lt;a href="http://onedublin.org/2012/06/19/stanford-universitys-carol-dweck-on-the-growth-mindset-and-education/"&gt;Dweck&lt;/a&gt;) and the study of how complex systems behave, particularly when they &lt;a href="http://www.amazon.com/dp/1409422216?tag=contindelive-20"&gt;drift into failure&lt;/a&gt;. Adaptive risk management is based on systems thinking, transparency, experimentation, and fast feedback loops.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Here are some examples of the differences between the two approaches.&lt;/p&gt;


&lt;strong&gt;Adaptive risk management&lt;/strong&gt; (people work to detect problems through improving transparency and feedback, and solve them through improvisation and experimentation)
&lt;strong&gt;Risk management theatre&lt;/strong&gt; (management imposes controls and processes which make life painful for the innocent but can be circumvented by the guilty)


&lt;strong&gt;Continuous code review&lt;/strong&gt; in which engineers ask a colleague to look over their changes before check-in, technical leads review all check-ins made by their team, and code review tools allow people to comment on each others&amp;#8217; work once it is in trunk.
&lt;strong&gt;Mandatory code review&lt;/strong&gt; enforced by check-in gates where a tool requires changes to be signed off by somebody else before they can be merged into trunk. This is inefficient and delays feedback on non-trivial regressions (including performance regressions).


&lt;strong&gt;Fast, automated unit and acceptance tests&lt;/strong&gt; which inform engineers within minutes (for unit tests) or tens of minutes (for acceptance tests) if they have introduced a known regression into trunk, and which can be run on workstations before commit.
&lt;strong&gt;Manual testing&lt;/strong&gt; as a precondition for integration, especially when performed by a different team or in a different location. Like mandatory code review, this delays feedback on the effect of the change on the system as a whole.


&lt;strong&gt;A &lt;a href="http://www.informit.com/articles/article.aspx?p=1621865"&gt;deployment pipeline&lt;/a&gt;&lt;/strong&gt; which provides complete traceability of all changes from check-in to release, and which detects and rejects risky changes automatically through a combination of automated tests and manual validations.
&lt;strong&gt;A comprehensive documentation trail&lt;/strong&gt; so that in the event of a failure we can discover the human error that is the root cause of failures in the mechanistic, Cartesian paradigm that applies in the domain of &lt;a href="http://en.wikipedia.org/wiki/Cynefin"&gt;systems that are not complex&lt;/a&gt;.


&lt;strong&gt;Situational awareness&lt;/strong&gt; created through tools which make it easy to monitor, analyze and correlate relevant data. This includes process, business and systems level metrics as well as the discussion threads around events.
&lt;strong&gt;Segregation of duties&lt;/strong&gt; which acts as a barrier to knowledge sharing, feedback and collaboration, and reduces the situational awareness which is essential to an effective response in the event of an incident.


&lt;p&gt;It&amp;#8217;s important to emphasize that there are circumstances in which the countermeasures on the right are appropriate. If your delivery and operational processes are chaotic and undisciplined, imposing controls can be an effective way to improve &amp;#8211; so long as we understand they are a temporary countermeasure rather than an end in themselves, and provided they are applied with the consent of the people who must work within them.&lt;/p&gt;
&lt;p&gt;Here are some differences between the two approaches in the field of IT:&lt;/p&gt;


Adaptive risk management (people work to detect problems through improving transparency and feedback, and solve them through improvisation and experimentation)
Risk management theatre (management imposes controls and processes which make life painful for the innocent but can be circumvented by the guilty)


&lt;strong&gt;Principle-based and dynamic:&lt;/strong&gt; principles can be applied to situations that were not envisaged when the principles were created.
&lt;strong&gt;Rule-based and static&lt;/strong&gt;: when we encounter new technologies and processes (for example, cloud computing) we need to rewrite the rules.


&lt;strong&gt;Uses transparency to prevent accidents and bad behaviour.&lt;/strong&gt; When it&amp;#8217;s easy for anybody to see what anybody else is doing, people are more careful. As Louis Brandeis said, &amp;#8220;Publicity is justly commended as a remedy for social and industrial diseases. Sunlight is said to be the best of disinfectants; electric light the most efficient policeman.&amp;#8221;
&lt;strong&gt;Uses controls to prevent accidents and bad behaviour.&lt;/strong&gt; This approach is the default for legislators as a way to prove they have taken action in response to a disaster. But controls limit our ability to adapt quickly to unexpected problems. This introduces a new class of risks, for example over-reliance on emergency change processes because the standard change process is too slow and bureaucratic.


&lt;strong&gt;Accepts that systems drift into failure.&lt;/strong&gt; Our systems and the environment are constantly changing, and there will never be sufficient information to make globally rational decisions. Humans solve our problems and we must rely on them to make judgement calls.
&lt;strong&gt;Assumes humans are the problem.&lt;/strong&gt; If people always follow the processes correctly, nothing bad can happen. Controls are put in place to manage &amp;#8220;bad apples&amp;#8221;. Ignores the fact that process specifications always require interpretation and adaptation in reality.


&lt;strong&gt;Rewards people for collaboration, experimentation, and system-level improvements.&lt;/strong&gt; People collaborate to improve system-level metrics such as lead time and time to restore service. No rewards for &amp;#8220;productivity&amp;#8221; on individual or function level. Accepts that locally rational decisions can lead to system level failures.
&lt;strong&gt;Rewards people based on personal &amp;#8220;productivity&amp;#8221; and local optimization&lt;/strong&gt;. For example operations people optimizing for stability at the expense of throughput, or developers optimizing for velocity at the expense of quality (even though these are false dichotomies.)


&lt;strong&gt;Creates a culture of continuous learning and experimentation&lt;/strong&gt;: People openly discuss mistakes to learn from them and conduct &lt;a href="http://codeascraft.com/2012/05/22/blameless-postmortems/"&gt;blameless post-mortems&lt;/a&gt; after outages or customer service problems with the goal of improving the system. People are encouraged to try things out and experiment (with the expectations that many hypotheses will be invalidated) in order to get better.
&lt;strong&gt;Creates a culture of fear and mistrust&lt;/strong&gt;. Encourages finger pointing and lack of ownership for errors, omissions and failure to get things done. As in: If I don&amp;#8217;t do anything unless someone tells me to, I won&amp;#8217;t be held responsible for any resulting failure.


&lt;strong&gt;Failures are a learning opportunity&lt;/strong&gt;. They occur in controlled circumstances, their effects are appropriately mitigated, and they are encouraged as an opportunity to learn how to improve.
&lt;strong&gt;Failures are caused by human error&lt;/strong&gt; (usually a failure to follow some process correctly), and the primary response is to find the person responsible and punish them, and then use further controls and processes as the main strategy to prevent future problems.


&lt;p&gt;Risk management theatre is not just painful and a barrier to the adoption of continuous delivery (and indeed to continuous improvement in general). It is actually dangerous, primarily because it creates a culture of fear and mistrust. As Bogsnes says, &amp;#8220;if the entire management model reeks of mistrust and control mechanisms against unwanted behavior, the result might actually be more, not less, of what we try to prevent. The more people are treated as criminals, the more we risk that they will behave as such.&amp;#8221;&lt;/p&gt;
&lt;p&gt;This kind of organizational culture is a major factor whenever we see people who are scared of losing their jobs, or engage in activities designed to protect themselves in the case that something goes wrong, or attempt to make themselves indispensable through hoarding information.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m certainly not suggesting that controls, IT governance frameworks, and oversight are bad in and of themselves. Indeed, applied correctly, they are essential for effective risk management. ITIL for example allows for a &lt;a href="http://continuousdelivery.com/2010/11/continuous-delivery-and-itil-change-management/"&gt;lightweight change management&lt;/a&gt; process that is completely compatible with an adaptive approach to risk management. What&amp;#8217;s decisive is how these framework are implemented. The way such frameworks are used and applied is determined by&amp;#8212;and perpetuates&amp;#8212;&lt;a href="http://www.infoq.com/minibooks/agile-adoption-transformation"&gt;organizational culture&lt;/a&gt;.&lt;/p&gt;
&lt;p id="dsq-content"&gt;


             


        &lt;/p&gt;

    &amp;#13;
 &amp;#13;
&amp;#13;
 &amp;#13;
&amp;#13;
 &amp;#13;
 &amp;#13;
 &amp;#13;
&amp;#13;
&lt;/div&gt;&amp;#13;
 &amp;#13;
</summary></entry><entry><title>How To Create A More Diverse Tech Conference</title><link href="http://www.ciandcd.com/how-to-create-a-more-diverse-tech-conference.html" rel="alternate"></link><updated>2015-06-27T08:31:14+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:how-to-create-a-more-diverse-tech-conference.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2013/09/how-we-got-40-female-speakers-at-flowcon/"&gt;http://continuousdelivery.com/2013/09/how-we-got-40-female-speakers-at-flowcon/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;How To Create A More Diverse Tech Conference&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;I have been advised by people I trust that it&amp;#8217;s not a good idea to talk about how you got serious female representation at your conference until after it&amp;#8217;s over. However the shameful RubyConf &lt;a href="https://twitter.com/shanley/status/380179040545406976"&gt;&amp;#8220;binders full of men&amp;#8221;&lt;/a&gt; debacle and the Neanderthal level of discussion around it has wound me up enough to write this account somewhat prematurely. So here is how we achieved &amp;gt;40% female representation on our &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speakers/"&gt;speaker roster&lt;/a&gt; at &lt;a href="http://flowcon.org/"&gt;FlowCon&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 0. Care About The Outcome.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When John Esser approached me to put together a conference about continuous delivery, devops and lean product development, I thought carefully about it. I&amp;#8217;ve helped put together a conference program before (&lt;a href="http://qconsf.com/sf2012/sf2012/"&gt;QCon SF 2012&lt;/a&gt;), and that was pretty hard work, so I wanted to be sure I had the correct motivation.&lt;/p&gt;
&lt;p&gt;One of the things that I have always disliked about tech conferences is being surrounded by a bunch of other straight white guys (nothing personal, some of my best friends are straight white guys). It&amp;#8217;s a constant reminder of the fact that, due to a number of socioeconomic factors, &lt;a href="http://whatever.scalzi.com/2012/05/15/straight-white-male-the-lowest-difficulty-setting-there-is/"&gt;straight white guys have it easier than others&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to put together a conference which reflects my community as I would like it to look, not as it actually looks. So one of the &lt;a href="http://flowcon.org/"&gt;four values&lt;/a&gt; the FlowCon program committee came up with was this: &amp;#8220;Diversity: We believe the technology community &amp;#8211; and thus the conference speakers and participants &amp;#8211; should reflect the demographics of our customers and the wider world.&amp;#8221;&lt;/p&gt;
&lt;p&gt;There are two reasons for this. Firstly, we can&amp;#8217;t effectively change the world through technology without diversity. To find out why, come and see &lt;a href="http://ashedryden.com/"&gt;Ashe Dryden&lt;/a&gt; talk about how &lt;a href="http://flowcon.org/flowcon-sanfran-2013/presentation/Programming%20Diversity"&gt;&amp;#8220;diverse communities and workplaces create better products&amp;#8221;&lt;/a&gt;. Second, one of the main reasons I like working at &lt;a href="http://www.thoughtworks.com/"&gt;ThoughtWorks&lt;/a&gt; is that one of &lt;a href="http://www.thoughtworks.com/about-us"&gt;the three pillars of our mission&lt;/a&gt; is to &amp;#8220;advocate passionately for social and economic justice.&amp;#8221; The fact there are so few women in IT reflects social and economic injustice inherent in our world.&lt;/p&gt;
&lt;p&gt;Making sure you actually have a mission for your conference is something I learned from helping out with &lt;a href="qconsf.com"&gt;QCon SF&lt;/a&gt;. It is a constant reminder of why you&amp;#8217;re doing it and what&amp;#8217;s important about it. If you don&amp;#8217;t have a mission, you&amp;#8217;re at the mercy of the implicit biases of the organizers. As RubyConf shows, you can&amp;#8217;t just throw in the &lt;a href="https://twitter.com/shanley/status/380186471174393856"&gt;&amp;#8220;one weird trick&amp;#8221;&lt;/a&gt; of anonymous submissions and expect that it will somehow solve the problem. Everybody on the program committee actually has to care about the outcome, or they won&amp;#8217;t put in the right amount of work to make it happen.&lt;/p&gt;
&lt;p&gt;Once you do that, the rest of the steps aren&amp;#8217;t that hard.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1. Make Sure Your Program Committee Is Aligned With Your Mission&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once I had an idea about the mission of the conference, I reached out to some people whom I thought would share it. I was lucky enough that &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Elisabeth+Hendrickson"&gt;Elizabeth Hendrickson&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Lane+Halley"&gt;Lane Halley&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Gene+Kim"&gt;Gene Kim&lt;/a&gt; agreed to join &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/John+Esser"&gt;John Esser&lt;/a&gt; and me on the program committee.&lt;/p&gt;
&lt;p&gt;One of the main reasons I asked those particular people, apart from being extremely competent and well-respected in their field, was another conference goal: &amp;#8220;Spanning boundaries: We believe that the best products are created collaboratively by people with a range of skills and experiences.&amp;#8221; The program committee has representation from the UX, testing, operations, product development and programming communities.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2. Make Sure Your Invited Speakers Are Aligned With Your Mission.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We made the decision to have about half the program be invited speakers. Part of that was about ensuring that we had a solid core program. But it was also a chance for us to put our mission into practice, so that when we put out the call for proposals we had a bunch of confirmed speakers who demonstrated we were serious about our mission.&lt;/p&gt;
&lt;p&gt;Thus we made sure that the invited speakers were respected boundary spanners, and that 50% of them were women. This involved more work than we would have had to put in had we just invited our friends (a popular strategy for program committees). It was also telling that we got more refusals from women than we got from men due to schedule conflicts. The main factor here was that female speakers are actually in greater demand than men because there are relatively fewer of them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3. The Anonymous Call For Proposals&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you jump straight to step 3, it&amp;#8217;s likely you will suffer the fate of RubyConf and fail. If you use this as your only strategy for increasing representation it won&amp;#8217;t work. This strategy has been &lt;a href="http://geekfeminism.org/2012/05/21/how-i-got-50-women-speakers-at-my-tech-conference/"&gt;thoroughly&lt;/a&gt; &lt;a href="http://2012.jsconf.eu/2012/09/17/beating-the-odds-how-we-got-25-percent-women-speakers.html"&gt;discussed&lt;/a&gt; by &lt;a href="http://www.startuplessonslearned.com/2012/11/solving-pipeline-problem.html"&gt;others&lt;/a&gt; who have used this approach as part of increasing diversity at their conference.&lt;/p&gt;
&lt;p&gt;We created a form in Google Docs for people to propose talks. They had to enter their email address, but we mentioned in the form that they should use one that didn&amp;#8217;t identify them if they wanted their proposal to be more anonymous. Of the 82 people who submitted a talk proposal, 18 (21%) were women as far as we can work out (once the program was confirmed I used &lt;a href="http://rapportive.com/"&gt;Rapportive&lt;/a&gt; to reverse-engineer email addresses based on publicly available information). Ultimately, three of the eight people who made it into the final program based on submitted proposals were women.&lt;/p&gt;
&lt;p&gt;The low female representation through the CFP is the reason our program isn&amp;#8217;t 50% female. Even getting the 21% of submissions that we did involved reaching out through mailing lists, Twitter, and our networks to encourage women to submit. This step, along with making it clear that you actually care, is essential if you in fact expect women to submit through the anonymous CFP.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These four steps resulted in &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speakers/"&gt;10 of our 24 speakers being women&lt;/a&gt;. I have three main observations coming out of this process:&lt;/p&gt;
&lt;p&gt;First, unlike &lt;a href="https://www.usenix.org/blog/my-daughters-high-school-programming-teacher"&gt;increasing the number of women who take programming classes in school&lt;/a&gt; or enter the IT industry and don&amp;#8217;t immediately quit in horror, creating a conference with reasonable female representation is not actually a hard problem. Yes, we put in more work to achieve this goal than we would have had we not cared. But it wasn&amp;#8217;t significantly more.&lt;/p&gt;
&lt;p&gt;Conference organizers who claim to care but fail to achieve good representation should quit whining and take real steps to achieve this goal. The community should hold them to higher standards. If the conference speakers are a bunch of straight white guys, the only reason is that the organizers didn&amp;#8217;t care enough.&lt;/p&gt;
&lt;p&gt;Second, in the wake of RubyConf, I have been angered but unsurprised to observe the usual chorus about how increasing representation somehow means lowering standards. Not only is this incredibly insulting to the many extraordinary women working in our industry, but it is just false. I dare anyone to look at &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;the kick-ass program&lt;/a&gt; we have put together for FlowCon and try and claim that we have somehow lowered standards to achieve great a barely acceptable level of representation.&lt;/p&gt;
&lt;p&gt;Another thing you will hear is that it is harder to find female speakers on &amp;#8220;hard&amp;#8221; topics such as programming than for &amp;#8220;soft&amp;#8221; ones. I find this claim baffling because in my experience changing organizational culture (considered a &amp;#8220;soft&amp;#8221; topic) is, in my experience, way way harder than knocking out lines of code (even well-factored unit-tested ones). But you&amp;#8217;ll see on our program that women are covering the whole gamut from &lt;a href="http://flowcon.org/flowcon-sanfran-2013/presentation/Organizational%20Change%20Myths%20and%20Patterns%20for%20Evangelists"&gt;organizational change&lt;/a&gt; to &lt;a href="http://flowcon.org/flowcon-sanfran-2013/presentation/Therapeutic%20Refactoring"&gt;refactoring&lt;/a&gt; to &lt;a href="http://flowcon.org/flowcon-sanfran-2013/presentation/Configuration%20Management:%20Stability%20in%20Your%20Pipeline"&gt;configuration management&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Third, it&amp;#8217;s not all good news. In particular, we have only one non-white speaker. I&amp;#8217;ll hold my hand up on this &amp;#8211; we didn&amp;#8217;t explicitly set non-white representation as a goal within the program committee, and by the time it became obvious it was a problem (Step 3) it was too late to do anything. This demonstrates why steps 0-2 are important. If we run FlowCon again, we will do better.&lt;/p&gt;
&lt;p&gt;Meanwhile &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;check out the program&lt;/a&gt;, and &lt;a href="https://secure.trifork.com/flowcon-sanfran-2013/registration/registration.jsp?promotionCode=humb50"&gt;follow this link&lt;/a&gt; to register with a 10% discount. If you need more than a one day conference to come to San Francisco, &lt;a href="http://lanyrd.com/2013/balancedteam/"&gt;Balanced Team are running their conference&lt;/a&gt; the following two days.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://engl165gs.files.wordpress.com/2013/05/colorblind-thought.jpg" width="240"&gt; &lt;strong&gt;End notes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Another popular &lt;a href="http://geekfeminism.wikia.com/wiki/Silencing"&gt;silencing tactic&lt;/a&gt; in this discussion is that bringing attention to the level of diversity in a conference is in itself a form of sexism or racism. There&amp;#8217;s a cartoon on the left which expresses nicely why this is in fact horribly misguided (or you could check out &lt;a href="http://www.sociologyinfocus.com/2012/01/30/im-not-racist-im-colorblind/"&gt;one of the many excellent articles on &amp;#8220;colourblindness&amp;#8221; and racism&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Check out the Geek Feminism &lt;a href="http://geekfeminism.org/"&gt;blog&lt;/a&gt; and &lt;a href="http://geekfeminism.wikia.com"&gt;wiki&lt;/a&gt; for tons of useful information and advice on making things better for women in tech. Also check out the &lt;a href="https://twitter.com/CallbackWomen"&gt;@CallbackWomen&lt;/a&gt; and &lt;a href="https://twitter.com/DevChix"&gt;@DevChix&lt;/a&gt; Twitter accounts to spread the word for your CFP. Ashe Dryden also wrote &lt;a href="http://ashedryden.com/blog/increasing-diversity-at-your-conference"&gt;an excellent post&lt;/a&gt; on creating more diverse conferences.&lt;/p&gt;
&lt;p&gt;Another important factor when designing a woman-friendly conference is to create an &lt;a href="http://gotocon.com/flowcon-sanfran-2013/anti-harassment-policy/"&gt;anti-harassment&lt;/a&gt; policy. Check out &lt;a href="http://www.maryrobinettekowal.com/journal/on-sexual-harassment-at-conventions-elise-matheson-speaks-out/"&gt;this account&lt;/a&gt; of a woman who actually needed to use the anti-harassment policy (trigger alert).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt; Of course, this entry is now starting to receive the attention of anonymous trolls. I&amp;#8217;ve left the first one as an example of the idiocy that passes for dialogue in this debate (and from supposedly smart people at that). But forthwith I&amp;#8217;ll be deleting anonymous or otherwise uncivil posts.&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>FlowCon 2013 Wrap-Up, With Some Hard Data on Gender Diversity in Tech Conferences.</title><link href="http://www.ciandcd.com/flowcon-2013-wrap-up-with-some-hard-data-on-gender-diversity-in-tech-conferences.html" rel="alternate"></link><updated>2015-06-27T08:31:13+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:flowcon-2013-wrap-up-with-some-hard-data-on-gender-diversity-in-tech-conferences.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2013/12/flowcon-2013-wrap-up/"&gt;http://continuousdelivery.com/2013/12/flowcon-2013-wrap-up/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;FlowCon 2013 Wrap-Up, With Some Hard Data on Gender Diversity in Tech Conferences.&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;Thanks to all of you who came along to FlowCon! If you weren&amp;#8217;t able to make it, you can &lt;a href="http://www.youtube.com/channel/UCMk1sRo1hnTLMA3kpn6BVKg"&gt;watch the videos for free&lt;/a&gt; thanks to &lt;a href="https://communities.bmc.com/community/bsm_initiatives/devops/blog"&gt;BMC&lt;/a&gt;&lt;a&gt;&lt;/a&gt; and &lt;a href="http://www.thoughtworks.com/studios"&gt;ThoughtWorks Studios&lt;/a&gt;. The &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;slides are also available&lt;/a&gt; for downloading.&lt;/p&gt;
&lt;p&gt;Let me first express my thanks to our producers: Geeta Schmidt and Niley Barros of &lt;a href="http://www.trifork.com/"&gt;Trifork&lt;/a&gt; and Rebecca Phillips of &lt;a href="http://www.thoughtworks.com/studios"&gt;ThoughtWorks Studios&lt;/a&gt;. I also want to thank my fellow PC members &lt;a href="https://twitter.com/thinknow"&gt;Lane Halley&lt;/a&gt;, &lt;a href="https://twitter.com/testobsessed"&gt;Elisabeth Hendrickson&lt;/a&gt;, &lt;a href="https://twitter.com/RealGeneKim"&gt;Gene Kim&lt;/a&gt; and &lt;a href="https://twitter.com/johndesser"&gt;John Esser&lt;/a&gt;; our fabulous &lt;a href="flowcon.org/flowcon-sanfran-2013/speakers/"&gt;speakers&lt;/a&gt;; our generous &lt;a href="http://flowcon.org/flowcon-sanfran-2013/sponsors/"&gt;sponsors&lt;/a&gt;; and everyone who came along.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h3&gt;The Program&lt;/h3&gt;
&lt;p&gt;The goal of the program committee was to create a conference that represents our industry as we want it to look, not as it is right now. That&amp;#8217;s an ambitious goal that involves changing the way we think about everything from &lt;a href="http://www.youtube.com/watch?v=Nc587c76Syg"&gt;leadership&lt;/a&gt; and &lt;a href="http://www.youtube.com/watch?v=PijCUJDb_hc"&gt;governance&lt;/a&gt; through &lt;a href="http://www.youtube.com/watch?v=5JF_QMIMBls"&gt;product&lt;/a&gt; &lt;a href="http://www.youtube.com/watch?v=vhFcux5UO4A"&gt;development&lt;/a&gt; and &lt;a href="http://www.youtube.com/watch?v=Socg4SIzAB4"&gt;design&lt;/a&gt;, to &lt;a href="http://www.youtube.com/watch?v=6jmZkV23TEs"&gt;IT&lt;/a&gt; &lt;a href="http://www.youtube.com/watch?v=7779Wrun5fo"&gt;operations&lt;/a&gt;. Not only did our speakers cover all these topics; they also provided real examples of how these changes, along with the cultural changes necessary to support them, have been achieved at enterprise scale.&lt;/p&gt;
&lt;p&gt;Thus we attacked one of the main objections we hear time and time again &amp;#8212; &amp;#8220;that sounds great, but it couldn&amp;#8217;t work here&amp;#8221;. Part of our vision was to provide a platform for people to speak about gnarly, real-life examples that demonstrate that, with sufficient hard work and ingenuity, ideas like continuous delivery, devops, and lean product development can provide significant competitive advantage through higher quality, cost savings, and happier customers, even in traditionally slow-moving and highly-regulated industries with large, complex, heterogeneous systems.&lt;/p&gt;
&lt;p&gt;Two talks that I am particularly happy to have on record are &lt;a href="http://www.youtube.com/watch?v=Trqjj3d3lhQ"&gt;Gary Gruver&amp;#8217;s talk&lt;/a&gt; on doing continuous delivery for printer firmware at HP, and &lt;a href="http://www.youtube.com/watch?v=eMS97X5ZTGc"&gt;John Kordyback&amp;#8217;s talk&lt;/a&gt; on doing continuous delivery with mainframes in the financial services industry. Alternatively, if you want a vision of the state of the art of continuous delivery, it would be hard to beat &lt;a href="http://www.youtube.com/watch?v=wyWI3gLpB8o"&gt;Adrian Cockcroft&amp;#8217;s opening keynote&lt;/a&gt; (the most highly rated talk of the conference) on how Netflix approach building and running systems.&lt;/p&gt;
&lt;p&gt;Overall, both the individual quality of the talks and the vision they present in concert was incredibly inspiring. Gene Kim comments, &amp;#8220;The FlowCon program was amazing. In my mind, what was presented at FlowCon is what every IT practitioner will be required to know in 10 years time.&amp;#8221; Thank you again to all of our speakers.&lt;/p&gt;
&lt;h3&gt;Data on Gender Diversity&lt;/h3&gt;
&lt;p&gt;Part of representing the industry as we want it to look is changing its composition. Thus another personal goal for me was to gather data to support my hypothesis that &lt;a href="http://continuousdelivery.com/2013/09/how-we-got-40-female-speakers-at-flowcon/"&gt;taking steps to increase diversity&lt;/a&gt; at conferences doesn&amp;#8217;t mean reducing quality. FlowCon, like the excellent &lt;a href="http://gotocon.com/"&gt;GOTO conferences&lt;/a&gt; that Trifork produces, records feedback from participants. Everybody leaving a session can give feedback on whether they thought the talk was good, mediocre or poor by tapping a red, amber or green rectangle on an iPhone on their way out. We then calculate overall satisfaction as follows: satisfaction = (green votes) / (total votes).&lt;/p&gt;
&lt;p&gt;When we got back all the data, the first thing I did is look at the average (mean) satisfaction for male speakers versus female speakers. It turns out that in both cases the average is between 71% and 72%. First of all, this demonstrates that there was no statistically significant difference in satisfaction between male and female speakers. This is important because it means our steps to increase diversity &amp;#8212; including reaching out to a wide network to ensure that 50% of our invited speakers were women &amp;#8212; didn&amp;#8217;t &amp;#8220;lower the bar&amp;#8221;.&lt;/p&gt;
&lt;p&gt;There is also a deeper implication: any claim that the all-white-male conference programs that are so depressingly common in the tech industry are the result of some meritocratic process is BS. They are, rather, the result of not putting in enough effort to seek out high quality speakers from &lt;a href="http://martinfowler.com/bliki/HistoricallyDiscriminatedAgainst.html"&gt;historically discriminated against&lt;/a&gt; groups.&lt;/p&gt;
&lt;p&gt;If our industry were truly meritocratic, the speaker line-up and attendees would resemble the wider population, because we know that there is &lt;a href="http://martinfowler.com/bliki/DiversityImbalance.html"&gt;no biological explanation&lt;/a&gt; for the overwhelming proportion of white dudes in our industry. So let&amp;#8217;s not fool ourselves any more with claims that taking steps to improve diversity is &amp;#8220;reverse discrimination&amp;#8221;. Any time we don&amp;#8217;t take concrete, systematic steps forward we are silently complicit in perpetuating the status quo &amp;#8212; which is why it&amp;#8217;s not good enough when leaders in the tech community ignore the problem. If you ignore the problem, you&amp;#8217;re part of the problem.&lt;/p&gt;
&lt;p&gt;Finally, I want to emphasize that what the program committee achieved was not very hard, once we spent some time thinking the problem through, and also that it was insufficient. We had a reasonable level of gender diversity, but the speakers were still overwhelmingly white. I don&amp;#8217;t have data for the diversity of our audience, but based on observation, there were more white guys than I would see if I walked out of the door onto the streets (and this is in San Francisco, which is far from being representative of the wider population).&lt;/p&gt;
&lt;p&gt;If you want to educate yourself further on these issues, I suggest watching &lt;a href="http://www.youtube.com/watch?v=VafA2stfTUM"&gt;Ashe Dryden&amp;#8217;s talk&lt;/a&gt; on programming diversity. And if you&amp;#8217;d like to become more effective at creating change, check out &lt;a href="http://www.youtube.com/watch?v=PJWKvkfbPo0"&gt;Linda Rising&amp;#8217;s closing keynote&lt;/a&gt;. Here&amp;#8217;s to &lt;a href="http://geekfeminism.wikia.com/wiki/Resources_for_allies"&gt;taking small steps every day&lt;/a&gt; to make 2014 a marginally, incrementally, &lt;a href="http://geekfeminism.wikia.com/wiki/Timeline_of_incidents#2013"&gt;better year than 2013&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>The Science Behind the 2013 Puppet Labs DevOps Survey Of Practice</title><link href="http://www.ciandcd.com/the-science-behind-the-2013-puppet-labs-devops-survey-of-practice.html" rel="alternate"></link><updated>2015-06-27T08:31:12+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:the-science-behind-the-2013-puppet-labs-devops-survey-of-practice.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2013/12/the-science-behind-the-2013-puppet-labs-devops-survey-of-practice/"&gt;http://continuousdelivery.com/2013/12/the-science-behind-the-2013-puppet-labs-devops-survey-of-practice/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;The Science Behind the 2013 Puppet Labs DevOps Survey Of Practice&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;By &lt;a href="https://twitter.com/RealGeneKim"&gt;Gene Kim&lt;/a&gt; and Jez Humble&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Last year, we both had the privilege of working with Puppet Labs to develop the 2012 DevOps Survey Of Practice. It was especially exciting for Gene, because we were able to benchmark the performance of over 4000 IT organizations, and to gain an understanding what behaviors result in their incredible performance. This continues research that he has been doing of high performing IT organizations that started for him in 1999.&lt;/p&gt;
&lt;p&gt;In this blog post, Gene Kim and I will discuss the research hypotheses that we&amp;#8217;re setting out to test in the 2013 DevOps Survey Of Practice, explain the mechanics of how these types of cross-population studies actually work (so you help this research effort or even start your own), then describe the key findings that came out of the 2012 study.&lt;/p&gt;
&lt;p&gt;But first off, if you&amp;#8217;re even remotely interested in DevOps, &lt;a href="http://www.surveygizmo.com/s3/1483785/DevOps-Survey-2013"&gt;go take the 2013 Puppet Labs DevOps Survey here&lt;/a&gt;! The survey closes on January 15, 2014, so hurry! It only takes about ten minutes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h3 id="2013-devops-survey-research-goals"&gt;2013 DevOps Survey Research Goals&lt;/h3&gt;
&lt;p&gt;Last year&amp;#8217;s study (which we&amp;#8217;ll describe in more detail below) found that high performing organizations that were employing DevOps practices were massively outperforming their peers: they were doing 30x more frequent code deploys, and had deployment lead times measured in minutes or hours (versus lower performers, who required weeks, months or quarters to complete their deployments).&lt;/p&gt;
&lt;p&gt;The high performers also had far better deployment outcomes: their changes and deployments had twice the change success rates, and when the changes failed, they could restore service 12x faster.&lt;/p&gt;
&lt;p&gt;The goal of the 2013 study is to gain a better understanding of exactly what practices are required to achieve this high performance. Our hypothesis is that the following are required, and we&amp;#8217;ll be looking to independently evaluate the effect of each of these practices on performance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;small teams with high trust that span the entire value stream: Dev, QA, IT Operations and Infosec&lt;/li&gt;
&lt;li&gt;shared goals and shared pain that span the entire value stream&lt;/li&gt;
&lt;li&gt;small development batch sizes&lt;/li&gt;
&lt;li&gt;presence of continuous, automated integration and testing&lt;/li&gt;
&lt;li&gt;emphasis on creating a culture of learning, experimentation and innovation&lt;/li&gt;
&lt;li&gt;emphasis on creating resilient systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are also testing two other hypotheses that one of us (Gene) is especially excited about, because it&amp;#8217;s something he&amp;#8217;s wanted to do ever since 1999!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lead time&lt;/strong&gt;: In plant manufacturing, lead time is the time required to turn raw materials into finished goods. There is a deeply held belief in the Lean community that lead time is the single best predictor of quality, customer satisfaction and employee happiness. We are testing this hypothesis for the DevOps value stream in the 2013 survey instrument.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Organizational performance&lt;/strong&gt;: Last year, we confirmed that DevOps practices correlate with substantially improved IT performance (e.g., deploy frequencies, lead times, change success rates, MTTR). This year, we will be testing whether improved IT performance correlates with improved business performance. In this year&amp;#8217;s study, we&amp;#8217;ve added inserted three questions that are known to correlate with organizational performance, which is known to correlate with business performance (e.g., competitiveness in the marketplace, return on assets, etc.).&lt;/p&gt;
&lt;p&gt;Our dream headline would be, &amp;#8220;high performing organizations not only do 30x more frequent code deployments than their peers, but they also outperform the S&amp;amp;P 500 by 3x as measured by shareholder return and return on assets.&amp;#8221;&lt;/p&gt;
&lt;p&gt;Obviously, there are many other variables that contribute to business performance besides Dev and Ops performance (e.g., profitability, market segment, market share, etc.). However, in our minds, the reliance upon IT performance is obvious: as Chris Little said, &amp;#8220;Every organization is an IT business, regardless of what business they think they&amp;#8217;re in.&amp;#8221;&lt;/p&gt;
&lt;p&gt;When IT does poorly, the business will do poorly. And when IT helps the organization win, those organizations will out-perform their competitors in the marketplace.&lt;/p&gt;
&lt;p&gt;(This hypothesis forms the basis of the hedge fund that Erik wants to create in the last chapter of &lt;a href="http://www.amazon.com/The-Phoenix-Project-Business-ebook/dp/B00AZRBLHO/"&gt;&amp;#8220;The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win&amp;#8221;&lt;/a&gt;, where they would make long or short bets, based on the known operating characteristics of the IT organization.)&lt;/p&gt;
&lt;h3 id="the-theory-behind-cross-population-studies-and-survey-instruments"&gt;The Theory Behind Cross-Population Studies and Survey Instruments&lt;/h3&gt;
&lt;p&gt;Like last year, this year&amp;#8217;s DevOps survey is a cross-population study, designed to explore the link between organizational performance and organizational practices and cultural norms.&lt;/p&gt;
&lt;p&gt;What is a cross-population study? It&amp;#8217;s a statistical research technique designed to uncover what factors (e.g., practices, cultural norms, etc.) correlate with outcomes (e.g., IT performance). Cross-population studies are often used in medical research to answer questions like, &amp;#8220;is cigarette smoking a significant factor in early mortality?&amp;#8221;&lt;/p&gt;
&lt;p&gt;Properly designed cross-population studies are considered a much more rigorous approach of testing efficacy of what practices work than say, interviewing people about what they think worked, ROI stories from vendors, or collecting &amp;#8220;known, best practices.&amp;#8221;&lt;/p&gt;
&lt;p&gt;&lt;img class="alignnone" alt="" src="https://draftin.com:443/images/6464?token=JXI7N7uDAMybn5lduEANKdQhwmXNNkJoBYsb2fE4jeFS9KsliXjnALaa33oHlCOP0_nW8tviUZ8zYBdwzPIOPtQ" width="426" height="289"&gt;&lt;/p&gt;
&lt;p&gt;When doing survey design, we might state our hypotheses in the following form: &amp;#8220;we believe that IT organizations which have high trust have higher IT performance.&amp;#8221; In other words, the higher the trust levels in the IT organization, the higher the performance.&lt;/p&gt;
&lt;p&gt;We then put this question in the survey instrument, and then analyze the results. If we were to plot the results on a graph, we would put the dependent variable (i.e., performance) on the Y-axis, and the independent variable (i.e., presence of high trust) on the X-axis.&lt;/p&gt;
&lt;p&gt;We would then test to see if there is a correlation between the two. Shown below is an example of what it looks like when the two variables have low or no correlation, and one that has a significant positive correlation.&lt;/p&gt;
&lt;p&gt;&lt;img class="alignnone" alt="" src="https://draftin.com:443/images/6465?token=EVRyxLU4nXU9O19I5TKk_64PCVLbwzGFy9P3kEQKdMUo4Ceg6Yn-cC5jFw2_N9IQwEPkrSUBLmUA_cJKWm5YP3g" width="463" height="162"&gt;&lt;/p&gt;
&lt;p&gt;If we were to find a significant correlation, such as displayed on the right, we could then assert that &amp;#8220;the higher your organization&amp;#8217;s trust levels, in general, the higher your IT performance.&amp;#8221;&lt;/p&gt;
&lt;p&gt;(Graph adapted from &lt;a href="http://en.wikipedia.org/wiki/Correlation_and_dependence"&gt;Wikipedia entry on Correlation and Dependence&lt;/a&gt;.)&lt;/p&gt;
&lt;h3 id="key-2012-devops-survey-findings"&gt;The 2012 DevOps Survey&lt;/h3&gt;
&lt;p&gt;In this section, we will describe the the key findings that came out of the 2012 DevOps Survey, as well as a brief discussion of the research hypotheses that went into the survey design.&lt;/p&gt;
&lt;p&gt;In the DevOps community, we have long asserted that certain practices enables organizations simultaneously deliver fast flow of features to market, while providing world-class stability, reliability and security.&lt;/p&gt;
&lt;p&gt;We designed the survey to validate this, and tested a series of technical practices to determine which of them correlated with high performance.&lt;/p&gt;
&lt;p&gt;The survey ran for 30 days, and we had 4,039 completed respondents. (This is an astonishingly high number, by the way. When Kurt Milne and Gene Kim did similar studies in 2006, each study typically required $200K to do the survey design, gather responses from a couple hundred people, and then perform survey analysis.)&lt;/p&gt;
&lt;p&gt;You can find the &lt;a href="http://www.slideshare.net/realgenekim/2013-velocity-devops-metrics-its-not-just-for-webops-any-more"&gt;slides that Gene Kim, Jez Humble and James Turnbull presented at the 2013 Velocity Conference here&lt;/a&gt;, and the &lt;a href="https://puppetlabs.com/2013-state-of-devops-infographic"&gt;full Puppet Labs infographics and results here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;The first surprise was how much the high performing organizations were outperforming their non-high-performing peers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Agility metrics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;30x more frequent code deployments&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;8,000x faster lead time than their peers&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reliability metrics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;2x the change success rate&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;12x faster MTTR&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In other words, they were more agile: they were deploying code 30x more frequently, and the lead time required to go from &amp;#8220;code committed&amp;#8221; to &amp;#8220;successfully running in production&amp;#8221; was completed 8,000x faster &amp;#8212; high performers had lead times measured in minutes or hours, while lower performers had lead times measured in weeks, months or even quarters.&lt;/p&gt;
&lt;p&gt;Not only were the high performers doing more work, but they had far better outcomes: when the high performers deployed changes and code, they were twice as likely to be completed successfully (i.e., without causing a production outage or service impairment), and when the change failed and resulted in an incident, the time required to resolve the incident was 12x faster.&lt;/p&gt;
&lt;p&gt;We were astonished and delighted with this finding, as it showed not only that it was possible to break the core, chronic conflict, but that it seemed to confirm that just as in manufacturing, agility and reliability go hand in hand. In other words, lead time correlates with both both agility and reliability.&lt;/p&gt;
&lt;p&gt;(Gene will write more on his personal interpretations of the 2012 DevOps Survey Of Practice in a future post.)&lt;/p&gt;
&lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;We hope this gives you a good idea of why we&amp;#8217;ve worked so hard on the 2012 and 2013 DevOps Survey, as well as how to conduct your own cross-population studies. Please let us know if you have any questions or if there&amp;#8217;s anything we can do for you.&lt;/p&gt;
&lt;p&gt;And of course, help us understand what in DevOps and Continuous Delivery work by &lt;a href="http://www.surveygizmo.com/s3/1483785/DevOps-Survey-2013"&gt;taking 10 minutes to participate in the 2013 Puppet Labs DevOps Survey here by January 15, 2014&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Thank you! &amp;#8211;Gene Kim and Jez Humble&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>Visualizations of Continuous Delivery</title><link href="http://www.ciandcd.com/visualizations-of-continuous-delivery.html" rel="alternate"></link><updated>2015-06-27T08:31:10+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:visualizations-of-continuous-delivery.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2014/02/visualizations-of-continuous-delivery/"&gt;http://continuousdelivery.com/2014/02/visualizations-of-continuous-delivery/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Visualizations of Continuous Delivery&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://www.linkedin.com/pub/nhan-ngo/11/938/ba5"&gt;Nhan Ngo&lt;/a&gt;, a QA engineer at &lt;a href="http://spotify.com"&gt;Spotify&lt;/a&gt;, made four fabulous visualizations while reading &lt;a href="http://www.amazon.com/dp/0321601912?tag=contindelive-20"&gt;Continuous Delivery&lt;/a&gt;. She has very kindly agreed to make them available under a Creative Commons license so feel free to share them, download them, and print them out (click to get a higher resolution version). Thank you Nhan!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2014/02/01_CD_the_idea_low-res.jpg"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2014/02/01_CD_the_idea_low-res.jpg" alt="01_CD_the_idea_low-res" width="550" class="alignleft wp-image-1155"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2014/02/02_CD_test_strategy_low-res.jpg"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2014/02/02_CD_test_strategy_low-res.jpg" alt="02_CD_test_strategy_low-res" width="550" class="alignleft wp-image-1156"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2014/02/03_CD_automated_acceptance_test_low-res.jpg"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2014/02/03_CD_automated_acceptance_test_low-res.jpg" alt="03_CD_automated_acceptance_test_low-res" width="550" class="alignleft wp-image-1157"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2014/02/04_CD_managing_data_low-res.jpg"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2014/02/04_CD_managing_data_low-res.jpg" alt="04_CD_managing_data_low-res" width="550" class="alignleft wp-image-1158"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>The 2014 State of DevOps Report Is Here!</title><link href="http://www.ciandcd.com/the-2014-state-of-devops-report-is-here.html" rel="alternate"></link><updated>2015-06-27T08:31:09+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:the-2014-state-of-devops-report-is-here.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2014/06/the-2014-state-of-devops-report-is-here/"&gt;http://continuousdelivery.com/2014/06/the-2014-state-of-devops-report-is-here/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;The 2014 State of DevOps Report Is Here!&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;DevOps, a movement of people who care about developing and operating reliable, secure, high performance systems at scale, has always &amp;#8212; intentionally &amp;#8212; lacked a definition or manifesto. However (and this is fascinating in its own right) that doesn&amp;#8217;t mean that we can&amp;#8217;t measure the impact of DevOps, or how good people are at doing it. The proof of this, and also of the startling impact of the DevOps movement, is now available in the form of the 2014 State of DevOps report (which you can &lt;a href="http://puppetlabs.com/2014-devops-report"&gt;download for free&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The report, a collaboration between &lt;a href="http://nicolefv.com/"&gt;Nicole Forsgren Velasquez&lt;/a&gt;, &lt;a href="https://twitter.com/RealGeneKim"&gt;Gene Kim&lt;/a&gt;, &lt;a href="https://puppetlabs.com/"&gt;Puppet Labs&lt;/a&gt;, and &lt;a href="https://twitter.com/jezhumble"&gt;yours truly&lt;/a&gt;, surveyed over 9,200 people worldwide, covering a wide range of industries and types of organization. Our goal for the report was ambitious. We set out to measure IT performance, business performance, the impact of particular practices (such as continuous integration, test automation, and version control), and also culture, and then to discover to what extent they influenced each other. How, you might ask, do you measure these things like culture and organizational performance? Following Douglas Hubbard&amp;#8217;s definition of measurement as &amp;#8220;A quantitatively expressed reduction of uncertainty based on one or more observations,&amp;#8221; it turns out that you can &lt;a href="www.amazon.com/dp/B003MXI78Y?tag=contindelive-20"&gt;measure anything&lt;/a&gt; if you put your mind to it. The report describes both our methodology and the way we measured these apparent intangibles.&lt;/p&gt;
&lt;p&gt;Indeed we not only measured these things: we have sound, statistically significant data that shows that culture and DevOps practices impact both IT performance and organizational performance. In direct contradiction to a popular narrative of the last ten years, IT matters &amp;#8212; indeed, the results show it is a competitive advantage &amp;#8212; and DevOps culture and practices are instrumental in achieving both high IT performance and organizational performance. Readers of this blog will be especially interested to learn that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Trunk-based development, continuous integration, and automated testing measurably improve both IT performance and organizational performance.&lt;/li&gt;
&lt;li&gt;Having a high-trust culture has a strong impact on both IT performance and organizational performance.&lt;/li&gt;
&lt;li&gt;Using external change approval processes such as a change advisory board, as opposed to peer-based code review techniques, significantly impacts throughput while doing almost nothing to improve stability.&lt;/li&gt;
&lt;li&gt;Job satisfaction is the biggest predictor of organizational performance, and using DevOps practices are good predictors of job satisfaction.
&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;I&amp;#8217;m very excited by the report. We improved on &lt;a href="https://puppetlabs.com/2013-state-of-devops-infographic"&gt;last year&amp;#8217;s&lt;/a&gt; method for measuring IT performance. We showed how you can measure culture and organizational performance. Most important, the analysis of our enormous data set demonstrates definitively that the strategies championed by the DevOps movement work, and that they provide a competitive advantage to your business.&lt;/p&gt;
&lt;p&gt;Many thanks to my collaborators, the fabulous team at PuppetLabs, and to all of you who took the survey.&lt;/p&gt;
&lt;p&gt;You can &lt;a href="http://puppetlabs.com/2014-devops-report"&gt;download the 2014 State of Devops Report for free.&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>Building GitHub Pull Requests with Continua CI</title><link href="http://www.ciandcd.com/building-github-pull-requests-with-continua-ci.html" rel="alternate"></link><updated>2015-06-27T04:06:11+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:building-github-pull-requests-with-continua-ci.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/700/building-github-pull-requests-with-continua-ci"&gt;https://www.finalbuilder.com/resources/blogs/postid/700/building-github-pull-requests-with-continua-ci&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;GitHub makes it relatively simple to contribute to open source projects, just fork the repository, make your changes, submit a pull request. Couldn't be simpler.&amp;#160;&lt;/p&gt;
&lt;p&gt;Accepting those Pull requests, is dead simple too, most of the time. But what if you want to build and test the pull request first, before accepting the request. Fortunately the nature of GitHub Pull requests (or more to the point, Git itself) makes this possible.&amp;#160;&lt;/p&gt;
&lt;h4&gt;Git References&lt;br&gt;
&lt;br&gt;
&lt;/h4&gt;
&lt;p&gt;Git References are a complex topic all on it's own, but lets take a quick look at a typical cloned repository. In the .git folder, open config file in notepad and take a look at the [remote "origin"] section, here's what mine looks like :&lt;/p&gt;
&lt;pre class="brush:plain"&gt;[remote "origin"]
url = https://github.com/VSoftTechnologies/playground.git
fetch = +refs/heads/*:refs/remotes/origin/*
&lt;/pre&gt;
&lt;p&gt;The key entry here is the fetch. Quoting from the &lt;a href="http://git-scm.com/book/ch9-5.html" title="Git Internals - The Refspec"&gt;git documentation&lt;/a&gt;&amp;#160;:&lt;/p&gt;
&lt;p&gt;"The format of the refspec is an optional&amp;#160;&lt;code&gt;+&lt;/code&gt;, followed by&amp;#160;&lt;code&gt;&amp;lt;src&amp;gt;:&amp;lt;dst&amp;gt;&lt;/code&gt;, where&amp;#160;&lt;code&gt;&amp;lt;src&amp;gt;&lt;/code&gt;&amp;#160;is the pattern for references on the remote side and&amp;#160;&lt;code&gt;&amp;lt;dst&amp;gt;&lt;/code&gt;&amp;#160;is where those references will be written locally. The&amp;#160;&lt;code&gt;+&lt;/code&gt;&amp;#160;tells Git to update the reference even if it isn&amp;#8217;t a fast-forward."&lt;br&gt;
&lt;br&gt;
The default fetch refspec will pull any branches from the original repository to our clone. But where are our pull requests?&lt;/p&gt;
&lt;h4&gt;Anatomy of a pull request&lt;br&gt;
&lt;br&gt;
&lt;/h4&gt;
&lt;p&gt;When a pull request is submitted,&amp;#160;GitHub &amp;#160;make use of Git References to essentially "attach" your pull request to the original repository. But in my local clone, I won't see them because the default fetch refspec doesn't include them. You can see the pull requests by using the git ls-remote command on the origin :&lt;/p&gt;
&lt;pre class="brush:bash"&gt;$ git ls-remote origin
$ git ls-remote origin
27dfaaf83f60ac26a6fe465042f2ddb515667ff1        HEAD
654b98d6eb862e247e5c043460e9f9a64b2f0972        refs/heads/Test
27dfaaf83f60ac26a6fe465042f2ddb515667ff1        refs/heads/master
b333438310a56823f1938071af8c697b202bf855        refs/pull/1/head
95cb80af1330e73188ea32659d7744dcfe37ab43        refs/pull/2/head
90ba13b8edaab04505396dbcb1853f6f9bdaed64        refs/pull/2/merge
&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;Notice something odd there. There are two pull requests, but pull request 2 has two entries in the list, whilst pull request 1 has only 1 entry. &amp;#160;refs/pull/2/head is a reference to the head commit of your pull request, whilst refs/pull/2/merge is a reference to the result of the automatic merge that GitHub does. On pull request 1, there was a merge conflict, so the the /merge reference was not created, on pull request 2, the merge succeeded. On the pull request page, you would typically see something like this if the merge succeeded :&amp;#160;&lt;/p&gt;
&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/MergeResult.png"&gt;&lt;h4&gt;Getting Continua CI to see the Pull Requests&lt;br&gt;
&lt;br&gt;
&lt;/h4&gt;
&lt;p&gt;The main reason for building pull requests on your CI server is to see if they build, and to run your unit tests against that build. You can chose to build the original pull request, or the result of the automatic merge, or both. In reality, if the automatic merge failed, then the person who submitted the pull request has some more work to do, so there's really no point building/testing the original pull request. What you really want to know, is "if I accept this request, will it build and the tests pass", so it's generally best to only build the automatic merge version of the pull request. Continua CI makes this quite simple. On the Git Repository settings, check the "Fetch other Remote Refs" option. This will show the Other Refs text area, which already has a default RefSpec that will fetch the pull requests (the merged versions), and create local (to Continua CI) branches with the name pr/#number - so pull request 1 becomes branch pr/1.&amp;#160;&lt;/p&gt;
&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/GitRepository.png"&gt;&lt;p&gt;You can modify this to taste, for example if you are fetching both the merge and the head versions of the &amp;#160;pull requests, you might use a refespec like this :&lt;/p&gt;
&lt;pre class="brush:plain"&gt;+refs/pull/*/merge:refs/remotes/origin/pr-merge/*
+refs/pull/*/merge:refs/remotes/origin/pr-head/*
&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;Building the pull Requests&lt;/p&gt;
&lt;p&gt;Now we have gotten this far (which is to say, you enabled one option and clicked on save!) we can build the pull requests (it may take a few minutes to fetch the pull requests). If you manually start a build, you can select the pull request from the branch field for the github repository using the intellsense, just start typing pr/ and you will see a list :&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/SelectPR.png"&gt;&lt;/p&gt;
&lt;p&gt;Now we can add a trigger to build pull requests (we are talking continuous integration after all). Using the Pattern Matched Branch feature on &lt;a href="http://wiki.finalbuilder.com/display/continua/Repository+Trigger" title="Pattern Matched Branch"&gt;Continua CI Triggers&lt;/a&gt;&amp;#160;you can make your trigger start builds when a pull request changeset is fetched from Github. The pattern is a regular expression, so ^pr/.* would match our pull request branches (assuming you we use the default refspec)&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/PRTrigger.png"&gt;&lt;/p&gt;
&lt;p&gt;
Adding a trigger specific to the pull requests allows you to set variables differently from other branches, and you will then be able to tailor your stages according to whether you are building a pull request or not. For example, you probably don't want to run your deploy stage when building a pull request).&lt;/p&gt;
&lt;h4&gt;Updating GitHup Pull Request Status&lt;/h4&gt;
&lt;br&gt;
&lt;p&gt;One last thing you might like to add, is to update the &lt;a href="https://github.com/blog/1227-commit-status-api"&gt;Pull Request Status&lt;/a&gt;. This can be done using the Update GitHub Status Action in Continua CI (In a future update this will done via build event handlers, a new feature currently in development). This is what the pull request might look like after the status is updated by Continua CI :&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/PRStatus.png"&gt;&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>Adding custom reports to Continua CI Build Results</title><link href="http://www.ciandcd.com/adding-custom-reports-to-continua-ci-build-results.html" rel="alternate"></link><updated>2015-06-27T04:06:09+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:adding-custom-reports-to-continua-ci-build-results.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/701/adding-custom-reports-to-continua-ci-build-results"&gt;https://www.finalbuilder.com/resources/blogs/postid/701/adding-custom-reports-to-continua-ci-build-results&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;It's not uncommon for tools run during a build process to create log files, xml or html files etc that you might want to keep, in other words &lt;a href="http://wiki.finalbuilder.com/display/continua/Artifacts" title="Artifacts in Continua CI"&gt;Artifacts&lt;/a&gt;. Continua CI already has a mechanism for registering Artifacts, which enables them to be viewed/downloaded from the Build Artifacts page. Continua CI also has another way of viewing those files, Reports. Reports are viewed in an iframe, which allows you to stay within the Continua CI UI, but still naviate within the report files. A typical use of the Report feature is showing exported FinalBuilder html logs, or Code Coverate html reports (for example those produced by OpenCover).&amp;#160;&lt;/p&gt;
&lt;h4&gt;Defining a Report&lt;/h4&gt;
&lt;p&gt;Defining a report is relatively simple. Just point it at a file you expect to appear in the Builds Workspace on the Server.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/CI-Reports/DefineReport.png" alt="Define Report"&gt;&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;In this case we're expecting our build process to place a file named FinalBuilderReport.html in the $Workspace$\Reports folder. $Workspace$ will be replaced at run time with the builds workspace path on the server.&amp;#160;&lt;/p&gt;
&lt;p&gt;The next step is to make sure that the file actually gets copied to where we said it would be. We define a &lt;a href="http://wiki.finalbuilder.com/display/continua/Workspace+Rules" title="Workspace Rules Help"&gt;Workspace Rule&lt;/a&gt; to copy the file back to the build workspace on the server when the Stage completes.&amp;#160;If your tool generates .css and image files then don't forget to add rules to copy those files into place too.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/CI-Reports/WorkspaceRules.png" alt="Workspace Rules"&gt;&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;The final step is to make sure that the report file is actually produced. In this example, we are using an exported &amp;#160;FinalBuilder Log file, which is created in $Workspace$\Output\FB7 - we tell FinalBuilder where the workspace is by setting a FinalBuilder variable (along with a buch of other stuff like version numbering etc) in the &lt;a href="http://wiki.finalbuilder.com/display/continua/FinalBuilder+Action" title="FinalBuilder Action Help"&gt;FinalBuilder Action&lt;/a&gt;.&amp;#160;&lt;/p&gt;
&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/CI-Reports/FinalBuilderVariable.png" alt="Passing the Workspace folder to FinalBuilder"&gt;&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;h4&gt;Viewing the Report&lt;/h4&gt;
&lt;p&gt;All thats left to do now is run the build, and view the report, If everything went to plan, then when you click on the builds Report Tab, you should see something like this :&lt;/p&gt;
&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/CI-Reports/TheReport.png" alt="Viewing the Report"&gt;&lt;p&gt;Notice the Home/Back/Forward Buttons. If your report comprises of multiple pages, and all the links in the html files are relative, then you get full history support in the iframe. FWIW, Open Cover with ReportGenerator does just that. We'll take a look at using Open Cover with Continua CI in a future post.&amp;#160;
&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>DUnitX has a Wizard!</title><link href="http://www.ciandcd.com/dunitx-has-a-wizard.html" rel="alternate"></link><updated>2015-06-27T04:06:06+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:dunitx-has-a-wizard.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/702/dunitx-has-a-wizard"&gt;https://www.finalbuilder.com/resources/blogs/postid/702/dunitx-has-a-wizard&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Thanks to a contribution from Robert Love, DUnitX now sports a shiny new IDE Wizard for creating Test projects and Test Units.&amp;#160;&lt;/p&gt;
&lt;p&gt;Before you install and use the wizard, there is one thing I recommend you do. In your Delphi IDE, add and Environment variable DUNITX and point it at your copy of the DUnitX source. The reason for doing this, is that when the wizard creates a project, it adds $(DUNITX) to the project search path. This avoids hard coding the DUnitX folder in yhe project search path, and also avoids installing it in your global library path (I have nothing other than the defaults installed there, I always use the project search path, makes it easier to share projects with other devs).&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-environ.png"&gt;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;Once you have that done (I'm assuming you have pulled down the latest source from GitHub), open the project group (.grouproj) for your IDE version and build the project group. Then right click on the wizard project and click on install :&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-install-wizard.png"&gt;&lt;/p&gt;
&lt;p&gt;If the package installs successfully then we are ready to use the wizard. Close the project group, and invoke the File\New\Other dialog, you will see the DUnitX Project listed&amp;#160;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-project.png"&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-unit.png"&gt;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;You might like to Customize your File\New menu, I made DUnitX prominent on mine (in part to remind myself to create unit tests first!) :&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-filenew.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;Invoking the wizard will show a simple dialog :&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-project-wizard.png"&gt;&lt;/p&gt;
&lt;p&gt;The options are pretty self explainatory, so I won't go into them here. The wizard generates a console application, once we have a gui runner (being worked on) we'll update the wizard to add options for that.&lt;/p&gt;
&lt;p&gt;DUnitX is open source, get it from &lt;a href="https://github.com/VSoftTechnologies/DUnitX" target="_blank"&gt;GitHub&lt;/a&gt;&amp;#160;- contributions are welcome. We also have a &lt;a href="https://plus.google.com/communities/110602661860791972403" target="_blank"&gt;Google Plus Community&lt;/a&gt;&amp;#160;for DUnitX.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>Automated Builds vs Continuous Integration</title><link href="http://www.ciandcd.com/automated-builds-vs-continuous-integration.html" rel="alternate"></link><updated>2015-06-27T04:06:03+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:automated-builds-vs-continuous-integration.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/703/automated-builds-vs-continuous-integration"&gt;https://www.finalbuilder.com/resources/blogs/postid/703/automated-builds-vs-continuous-integration&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;
&lt;a href="http://osherove.com/"&gt;Roy Osherove&lt;/a&gt; posted an interesting video on youtube recently, talking about the difference between Automated Builds and Continuous Integration.&lt;/p&gt;
&lt;p&gt;This is a subject that comes up often in emails from existing and potential customers. Why do I need FinalBuilder if I have Continua CI, or, why haven't we added all the functionality of FinalBuilder to Continua CI?&lt;/p&gt;
&lt;p&gt;Roy sums up the differences and reasoning in this video quite nicely.&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;Roy goes into more detail in his "newish" book , &lt;a href="https://leanpub.com/build"&gt;Beautiful Builds&lt;/a&gt;. Lots of interesting food for thought. Lets face it, most developers probably don't spend too much time "deep thinking" how the build side of things
should be done. Roy's book is full of "deep thinking", but Roy sums it all up quite nicely! It's not a long book, around 40 pages and definitely worth a read. &lt;/p&gt;
&lt;h4&gt;FinalBuilder and Continua CI&lt;/h4&gt;
&lt;p&gt;The workflow functionality in Continua CI is inspired by FinalBuilder (which is probably stating the obvious to FinalBuilder users), but the functionality that is there is fairly high level. Your Continua CI Stage workflow can be as simple as a
single action (for example a FinalBuilder Action or MSBuild, or Rake or Powershell....), or you can make use of the flow control, logic, file operation actions etc and keep your build scripts as simple as your .sln file (or .dproj for delphi developers). That's for you to decide.
Of course our recommendation is to use FinalBuilder (and I say "of course" because I have wages to pay!) but there are obvious benefits to using FinalBuilder for your automated build scripts.&lt;/p&gt;
&lt;h4&gt;Develop and debug your build scripts on your machine&lt;/h4&gt;
&lt;p&gt;Using FinalBuilder, you can develop and debug your build script on your machine. FinalBuilder allows you to step through the build, set breakpoints, see what is happening, how variables are changing etc. The value of this shouldn't be underestimated; developing a FinalBuilder script is fast, easy and provides immediate feedback. No Web based CI Server (is there any other kind?) can give you this level of immediate feedback.&amp;#160;&lt;/p&gt;
&lt;p&gt;This also has the added benefit in that the FinalBuilder project will be runnable on other developers machines (assuming they have the required tools installed)&lt;/p&gt;
&lt;h4&gt;All of your build script is versioned with your source code.&lt;/h4&gt;
&lt;p&gt;If all of your build script functionality is in a FinalBuilder script, and that script is checked into version control (alongside your source code), then if the structure of your source code changes, so can your FinalBuilder script. The CI server will checkout the correct version of the build script for the version of source code it's checking out.&amp;#160;&lt;/p&gt;
&lt;h4&gt;Better Integration&lt;/h4&gt;
&lt;p&gt;We're currently working on better integration between Continua CI and FinalBuilder. Some of our FinalBuilder Server customers have complained that they lose functionality when moving to Continua CI. We understand that, FinalBuilder Server and FinalBuilder are tightly coupled. When we started
working on Continua CI, we made a conscious decision to not do that. That means Continua CI doesn't know about the internals of a FinalBuilder project, doesn't know what variables are declared. I still stand by that decision; it made Continua CI a better product. That said, there is more we can do
to improve how the two products work together. This work will show up in an update over the coming weeks (when it's ready!).
&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>FinalBuilder and Team Foundation Server 2013</title><link href="http://www.ciandcd.com/finalbuilder-and-team-foundation-server-2013.html" rel="alternate"></link><updated>2015-06-27T04:06:01+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:finalbuilder-and-team-foundation-server-2013.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/705/finalbuilder-and-team-foundation-server-2013"&gt;https://www.finalbuilder.com/resources/blogs/postid/705/finalbuilder-and-team-foundation-server-2013&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;FinalBuilder offers you tight integration into TFS with an easy to understand IDE. In this post I will go into how to integrate FinalBuilder into your TFS build process. The post will cover;&lt;/p&gt;
 
&lt;br&gt;
&lt;p&gt;To make sure this post doesn't rival "war and peace" in size, I will assume a few things during the post. Namely that you have used TFS in some fashion, and/or have gotten a solution building under TFS with the default TFS template. For more information on getting up and running with TFS and common issues with TFS I suggest taking a look at the TFS ranger &lt;a href="http://blogs.msdn.com/b/willy-peter_schaub/archive/2013/05/16/visual-studio-alm-ranger-solutions-catalog.aspx" class="vt-p"&gt;books&lt;/a&gt; and &lt;a href="http://vsarbuildguide.codeplex.com/" class="vt-p"&gt;blog&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;
Prerequisites&lt;/h4&gt;
&lt;p&gt;To follow along with this post you will need the following installed:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Team Foundation Server 2013, with build agent (12.0.21005.1 or later)&lt;/li&gt;
    &lt;li&gt;FinalBuilder 7 (7.0.0.2745 or later)&lt;/li&gt;
    &lt;li&gt;Required Visual Studio or MSBuild version available on agent&lt;/li&gt;
    &lt;li&gt;&lt;a href="http://www.microsoft.com/en-us/download/confirmation.aspx?id=40750" class="vt-p"&gt;Agents for Microsoft Visual Studio 2013&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="http://www.visualstudio.com/downloads/download-visual-studio-vs" class="vt-p"&gt;Team Explorer 2013&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;The Team Foundation Server can be of any configuration as long as it has at least one agent and a reporting service. FinalBuilder 7 is required on the agent machine, and could also be installed on the developer&amp;#8217;s machine for editing of scripts. Agents for Microsoft Visual Studio 2013 will provide access to VSTest.Console which we require for testing on the build agent. Lastly, Team Explorer is required for interaction with source control from FinalBuilder&amp;#8217;s IDE. Without this installed source control will need to be done manually.&lt;/p&gt;
 
&lt;p&gt;To start I have a solution under source control on a TFS 2013 collection. The solution I will be using is under a team project called VSoftSFTPLibrary &amp;#160;under the collection &amp;#8220;TFS2013\DefaultCollection&amp;#8221;. &amp;#160;The layouts of the team project looks like the following:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/SourceControlExplorerLayout.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;I have a directory for the SFTP projects source, library files and its tests. The layout of your source control may vary from mine, however the main point to note here is that separating out directories isn&amp;#8217;t an issue. With the solution, all related files, and binaries under source control I now add a build definition to the team project.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildName.png" alt="Build Name"&gt;&lt;/p&gt;
&lt;p&gt;Next the folders to be used in the FinalBuilder script need to be mapped from the server to an agent location. It&amp;#8217;s important to map all folders which contain files required for the build process. At this stage we only really know of the Source directory we are going to be build and the Library folder which the source relies on. Note that if your solution relies on a certain structure of folders this structure should be the same when it arrives on the agent. In the example the source and library paths are at the same folder depth, therefore this is reflected on the agent side.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildSourceSettings.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;When the build is finished usually we want them &amp;#8220;dropped&amp;#8221; somewhere on the network. A FinalBuilder script can use this drop location, which we will go into later on in the artcile. For now I set this to a server location accessible by the build agent service user.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildDropFolder.png" alt="Drop Folder"&gt;&lt;/p&gt;
 
&lt;p&gt;By default the build process is set to the default build process which comes with TFS2013. The template is called &amp;#8220;TfvcTemplate.12.xaml&amp;#8221;. When used the default template will enable the building, testing, impact testing, and deployment of a solution and its projects. Our aim is to perform all the same build activities with the additon of a FinalBuilder project.&amp;#160;&lt;/p&gt;
&lt;p&gt;To this end, the build process template needs to be changed over to one of the two supplied with FinalBuilder. In the [%ProgramFiles(x86)%\FinalBuilder &amp;#160;7\TFS Templates\2013] folder there are two TFS 2013 build workflow templates. &amp;#8220;FinalBuilderTFS2013Build.xaml&amp;#8221; performs all the same steps as the default build workflow and adds a FinalBuilder step just after the MSBuild activity and just before the optional &amp;#8220;after MSBuild script&amp;#8221;. This script is typically used by those looking to convert current default script builds to FinalBuilder in a simple and piece-meal fashion.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderTFS2013Templates.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;The &amp;#8220;FinalBuilderOnlyTFS2013Build.xaml&amp;#8221; template is used when the FinalBuilder script is to take over the entire build process. For the moment I will use the &amp;#8220;FinalBuilderTFS2013Build.xaml&amp;#8221; script. Add these two scripts to the team project, typically under a BuildTemplates folder to separate them from the source and library code.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildAddFBTemplates.png" alt="Add FB Template"&gt;&lt;/p&gt;
&lt;p&gt;Copy these templates into the local mapped location for this team project, and check them into source control. Now the &amp;#8220;FinalBuilderTFS2013Build.xaml&amp;#8221; template can be selected as the build process template. To do this add a new new build in the process section of the build definition. Navigate to the source control location where the template is stored and select it.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildNewTemplateForBuild.png" alt="New Template For Build"&gt;&lt;/p&gt;
 
&lt;p&gt;The next step is to fill in the parameters for the build process. The majority of these are the exact same as the default TFS 2013 template with the addition of some FinalBuilder specific settings. The FinalBuilder section of settings allow for the specification of the project file, and custom arguments for the FinalBuilder project.&amp;#160;Note that the &amp;#8220;2. Build | Projects&amp;#8221;, and the &amp;#8220;6. FinalBuilder | Project File&amp;#8221; are both required by the build template. These are used to determine what should be built and what FinalBuilder project should be run.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildTemplateArguments.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;To run a FinalBuilder project we need to create one. Therefore create a FinalBuilder project with just an [Action Group] action for the moment. Save this project to the team projects FinalBuilderScripts folder and check it into source control.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildInitialFBProjectAddToSourceControl.png" alt="Project Added To Source Control"&gt;&lt;/p&gt;
&lt;p&gt;Once the FinalBuilder project is in source control select it in the build process using the file selector provided through the ellipse selector. You should end up with something reading like this &amp;#8220;$/VSoftSFTPLibrary/FinalBuilderScripts/BuildVSoftSFTPLibrary.fbp7&amp;#8221;&lt;/p&gt;
&lt;p&gt;Now that we have included the FinalBuilder project into our build process we need to make sure its folder is mapped to the agent. Open the source settings section, and add a mapping for the folder in which the FinalBuilder project resides. Something like the following should be what results.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildSourceSettingsWithFinalBuilderFolderMapped.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;Queue the build and the log should read like the following excerpt. The [Action Group] line is the action group you added in the FinalBuilder project.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildFinalBuilderRunSuccessfullyJustActionGroup.png" alt="Successful Run With Just an Action Group"&gt;&lt;/p&gt;
&lt;p&gt;So now we have a TFS build process which is able to call a FinalBuilder script. In the next section we will delve more into how to extract information from TFS about the build inside our FinalBuilder script.&amp;#160;&lt;/p&gt;
&lt;h4&gt;Retrieving information from TFS in a FinalBuilder Script&lt;/h4&gt;
&lt;p&gt;For the FinalBuilder script to be of use in the TFS build process, it requires information about the TFS build currently running. To provide this we offer a number of actions that can extract this information during the TFS build run.&amp;#160;To get you started, there is an example project in &amp;lt;FinalBuilderInstallDir&amp;gt;\TFS Templates called TFSExample.fbp7. This sample project contains examples of the actions to use during a TFS build process. &amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderTFSExampleProject.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;The [Get Team Foundataion Build Parameters] action is a special action that is only useful when a project is launched from TFS. It assigns TFS data to the specified project variables.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderGetTeamFoundationBuildParams.png" alt="Foundation Build Params"&gt;&lt;/p&gt;
&lt;p&gt;Each of the variables in the [Get Team Foundation Build Parameters] action are as follows:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Team Server URL: This is the URL of the team foundation server that queued the build.&lt;/li&gt;
    &lt;li&gt;Team Project: Is the name of the team project the build belongs to.&lt;/li&gt;
    &lt;li&gt;Build Id: Is the unique number allocated to this build.&lt;/li&gt;
    &lt;li&gt;Platform/Flavor: These are the build parameters for the compilation of the solution to be built.&lt;/li&gt;
    &lt;li&gt;Default Solution File: The solution file listed as the primary for the team project.&lt;/li&gt;
    &lt;li&gt;Solution File List: The list of solutions to be built by the build process.&lt;/li&gt;
    &lt;li&gt;Deployment Folder: The drop folder configured for the build process. It is blank if it is not set.&lt;/li&gt;
    &lt;li&gt;Source Root: The first listed solutions root folder.&lt;/li&gt;
    &lt;li&gt;Working Directory: A working directory on the agent for the current build definition. Typically space which is shared between builds made on the same agent.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;On the Custom Arguments tab is a list of ten variables which can be passed from the TFS build process to FinalBuilder. These are passed as plain text and converted to the variable types used to read them in the FinalBuilder script.&lt;/p&gt;
&lt;p&gt;For my script I only wanted to get the Team Foundation Build Parameters, and the variables that it used. So first I checked out the &amp;#8220;BuildVSoftSFTPLibrary.fbp7&amp;#8221; project using the built in source control features of FinalBuilder.&lt;/p&gt;
&lt;p&gt;First I need to make sure that it is indeed added to source control. If it hasn&amp;#8217;t detected that it is part of the TFS source control at this stage I add it to source control. I make sure to select the &amp;#8220;Microsoft Team Foundation Server MSSCCI provider&amp;#8221; which will use the Team Explorer 2013 installed on the machine. I select the TFS 2013 server and collection I am working with, also making sure the team project is correct. Once this is done I am then able to use the file menu to check the project out ready for editing.&amp;#160;&lt;/p&gt;
&lt;p&gt;Next I copy all the variables I want from the TFSExample project, and paste them into my BuildVSoftSFTPLibrary.fbp7 project. To paste the variables I open the Variables Editor, right click and select paste.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderCopyVariables.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;Last I copy over the [Get Team Foundation Build Parameters] and [Trigger Files Iterator] actions. These use the variables we just copied over and will hook themselves up as they appeared in the example project.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderProjectWithGetTFSBuildParamsAndIterateTiggerFiles.png"&gt;&lt;/p&gt;
&lt;p&gt;Now we can check in these changes and queue the build.&amp;#160;&lt;/p&gt;
&lt;p&gt;In the log for the build you will see the following:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderGetTeamFoundationBuildParamsAndLog.png"&gt;&lt;/p&gt;
&lt;p&gt;By default the [Get Team Foundation Build Parameters] action will write what it has retrieved from TFS to the build log. Something to keep in mind when debugging a FinalBuilder script in TFS.&lt;/p&gt;
 
&lt;p&gt;So now we want to make the FinalBuilder process take over the build completely. The first thing to do here is to stop the TFS build process from building, testing, and publishing results of the build. This requires changing the build workflow to remove the activities which do this (otherwise we would be doing things twice), and updating the FinalBuilder script to perform these tasks.&amp;#160;&lt;/p&gt;
&lt;p&gt;Instead of working out which activities to remove from the build template we provide a build template with all the build and testing activities removed. The &amp;#8220;FinalBuilderOnlyTFS2013Build.xaml&amp;#8221; template which was copied into the BuildTemplates folder is this template.&amp;#160;&lt;/p&gt;
&lt;p&gt;In the process section of the build definition, create a new build process using the &amp;#8220;FinalBuilderOnlyTFS2013Build.xaml&amp;#8221; file. You will notice that nearly everything in the build parameters is the same except now the before and after script events have been removed. Also the testing section is no longer present. All of this will be handled by the FinalBuilder script.&lt;/p&gt;
&lt;p&gt;Once again open your FinalBuilder project for this build and check it out. Also open up the TFSExample.fbp7 project and take a look at the [Build VS.Net Solution] action. Copy this action to the project used to build your solution.&amp;#160;&lt;/p&gt;
&lt;p&gt;The [Build VS.NET Solution] action builds a Visual Studio.NET solution. On the [Solution] tab you will see that the Solution File is set to &amp;#8220;%SourceRoot%\&amp;lt;YourSolution&amp;gt;.sln&amp;#8221;. Replace &amp;lt;YourSolution&amp;gt; with the name of the solution that you wish to build. Note that &amp;#8220;%SourceRoot%&amp;#8221; will be the directory of only the first solution in the list of projects to build. In my project I ended up with a Solution File value of &amp;#8220;%SourceRoot%\VSoftSFTPLibrary.sln&amp;#8221; for the [Build VS.NET Solution] action.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderBuildVSSolution.png"&gt;&lt;/p&gt;
&lt;p&gt;On the [Paths] tab you will see that the Output Directory is set to %SourceRoot%\Binaries. You may change this if you wish, but it's it not necessary. Note because the drop location may be on a different server to the build agent, it is important that VSTest runs on files located on the build agent machine. Unless you explicitly set up the trust relationship, .NET will not allow executing of assemblies on remote machines. This is why we build and test in a directory under %SourcesRoot% and then move the files to the drop location after testing. This will be covered more in the next section.&amp;#160;&lt;/p&gt;
&lt;p&gt;On the agent the TFS agent the FinalBuilder options for Visual Studio will need to be set. If not and DEVENV.COM is required, the build will fail about the build tool location being unknown. &lt;/p&gt;
&lt;p&gt;Now are right to run the build with using just FinalBuilder. Queue the build again and now the project will build, not from a template activity but from the FinalBuilder script it is running.&amp;#160;
&lt;/p&gt;
 
&lt;p&gt;To perform testing we need to add a [Run VSTest.Console] action to the FinalBuilder project. The [Run VSTest.Console] uses VSTest.Console to run your test assemblies. On the [Settings] tab add the name of your test assembly to the list. You should end up with something along the lines of &amp;#8220;%SourceRoot%\Binaries\&amp;lt;YourTestAssembly&amp;gt;.dll&amp;#8221;. On the [Publish Results] tab the action should be set to automatically publish the results to the TFS server. This means that after the tests are run they will automatically be stored with the build on the TFS Server.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderVSTestConsoleSettings.png"&gt;&lt;/p&gt;
&lt;p&gt;Note that the [Ignore Failure] option, located on the [Options] tab, is important. If any unit tests fail, the [Run VSTest.Console] action will fail, and setting [Ignore Failure] allows the FinalBuilder and TFS builds to continue. Un-check [Ignore Failure] if you would prefer the build to stop on failed tests. In either case, test failures will appear in the TFS build log and in TFS reports.&lt;/p&gt;
&lt;p&gt;On the agent the TFS agent the FinalBuilder options for VSTest.Console will need to be set. If not, the build will fail with an error about the VSTest.Console location being unknown. &lt;/p&gt;
 
&lt;p&gt;The last step to complete the process is to move all the files from the agent to your drop location. The simplest way to achieve this is by a [Move File(s)] action. We already have the drop folder location stored in the %DropShare% variable. It is this value which we then use in the [Move File(s)] action. &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderMoveFilesToDropFolder.png"&gt;&lt;/p&gt;
&lt;p&gt;Once this is run we will have a built solution, with tests run, and the binaries copied into the specified drop folder.&amp;#160;&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>Refuge for Automated Build Studio Users</title><link href="http://www.ciandcd.com/refuge-for-automated-build-studio-users.html" rel="alternate"></link><updated>2015-06-27T04:04:55+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:refuge-for-automated-build-studio-users.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/708/refuge-for-automated-build-studio-users"&gt;https://www.finalbuilder.com/resources/blogs/postid/708/refuge-for-automated-build-studio-users&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h1 class="heading"&gt;Refuge for Automated Build Studio Users&lt;/h1&gt; &amp;#13;
					&lt;p&gt;&lt;a href="https://www.finalbuilder.com/resources/blogs/author/vincent-parrett/aid/5"&gt;&amp;#13;
								&lt;img src="https://www.finalbuilder.com/profilepic.ashx?userId=5&amp;amp;h=75&amp;amp;w=75" alt="[Author:displayname]"&gt;By Vincent Parrett&lt;/a&gt;&lt;br&gt;On April 13, 2014&lt;/p&gt;&amp;#13;
							&amp;#13;
						&lt;br&gt;&amp;#13;
                    &lt;p class="content"&gt;&amp;#13;
                        SmartBear recently discontinued development of Automated Build Studio and deleted pretty much all references to it from their website. &lt;br&gt;
&lt;br&gt;
Within hours of the smartbear email going out to ABS users, we started getting questions about crossgrade discounts, and we're more than happy to help. &amp;#160;&lt;br&gt;
&lt;br&gt;
If you are an ABS user, contact us (sales @ finalbuilder.com ) with proof of purchase (invoice) for ABS and we'll provide you with a 50% off discount coupon for FinalBuilder 7 Professional Edition.&amp;#160;&lt;br&gt;
&lt;br&gt;
This is a limited time once only offer, valid until May 15th 2014. &amp;#160;Spread the word to your fellow ABS users.&amp;#160;&lt;br&gt;
&lt;br&gt;
While you you are checking out FinalBuilder, be sure to take a look at our Continuous Integration Server product, Continua CI. It's vastly superior to the CI features in ABS, but still allows you to create your build process using a visual build tool (FinalBuilder). &amp;#160;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/p&gt;&amp;#13;
                &lt;/div&gt;</summary></entry><entry><title>Automated UI Testing Done Right with ContinuaCI</title><link href="http://www.ciandcd.com/automated-ui-testing-done-right-with-continuaci.html" rel="alternate"></link><updated>2015-06-27T04:04:53+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:automated-ui-testing-done-right-with-continuaci.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/709/automated-ui-testing-done-right-with-continuaci"&gt;https://www.finalbuilder.com/resources/blogs/postid/709/automated-ui-testing-done-right-with-continuaci&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h1&gt;
Automated UI Testing Done Right with ContinuaCI&lt;/h1&gt;
You have just completed an awesomely complex change to your shinny new webapp! &amp;#160;After
running all your unit tests things are in the green and looking clean.&lt;br&gt;
&lt;br&gt;
Very satisfied at the quality of your work you fire up the application to verify
that everything is still working as advertised. &amp;#160;Below is what greets you on
the root path of your app:&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/404-notfound-ie5.gif" alt="Funny error"&gt;&lt;br&gt;
&lt;br&gt;
We have all been here at some time or another! &amp;#160;What happened! &amp;#160;Perhaps
it was not your code that broke it! &amp;#160;Maybe the issue originated from another
part of your organisation, or maybe it came from somewhere on the "inter-webs".
&amp;#160;&lt;br&gt;
&lt;br&gt;
Its time to look at the underlying problem however ..... &amp;#160;testing web user
interfaces is hard! &amp;#160;Its time consuming and difficult to get right. &amp;#160;Manual
clicks, much typing, cross referencing client specifications etc, surely there must
be an easier way. &amp;#160;At the end of the day we DO need to test our user interfaces
&lt;img alt="" src="/Providers/HtmlEditorProviders/Telerik/images/Emoticons/wink_smile.gif" title="wink_smile"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Automated Web UI Testing&lt;/h4&gt;
&lt;br&gt;
Thankfully UI testing today can be Automated, running real browsers in real end
to end functional tests, to ensure our results meet (and continue to meet) expectations.
&amp;#160; &amp;#160;&amp;#160;&lt;br&gt;
&lt;p&gt;You have just completed an awesomely complex change to your shinny new webapp! After running all your unit tests things are in the green and looking clean.Very satisfied at the quality of your work you fire up the application to verify that everything is still working as advertised. Below is what greets you on the root path of your app:We have all been here at some time or another! What happened! Perhaps it was not your code that broke it! Maybe the issue originated from another part of your organisation, or maybe it came from somewhere on the "inter-webs".Its time to look at the underlying problem however ..... testing web user interfaces is hard! Its time consuming and difficult to get right. Manual clicks, much typing, cross referencing client specifications etc, surely there must be an easier way. At the end of the day we DO need to test our user interfacesThankfully UI testing today can be Automated, running real browsers in real end to end functional tests, to ensure our results meet (and continue to meet) expectations.&lt;/p&gt;&lt;p&gt;
For the sake of brevity and clarity in this demonstration we will focus on testing
an existing endpoint. &amp;#160;It is considered common place to find functional tests
included as part of a wider build pipeline, which may consist of such steps as:&amp;#160;&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Build&lt;/li&gt;
    &lt;li&gt;Unit Test&lt;/li&gt;
    &lt;li&gt;Deploy to Test Environment&lt;/li&gt;
    &lt;li&gt;Perform Functional Tests&lt;/li&gt;
    &lt;li&gt;Deploy to Production&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
In this article we will be focusing on the functional testing component of this
pipeline. &amp;#160;We will proceed on the assumption that your code has already been,
built unit tested and deployed to a Functional Test environment.  Today we
will;&lt;br&gt;
&lt;br&gt;
&lt;p&gt;Add Automated UI testing to an existing endpoint google.com&lt;/p&gt;&lt;br&gt;
&lt;p&gt;Configure ContinuaCI to automatically build our project, and perform the tests&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Software Requirements:&amp;#160;&lt;/h4&gt;
&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;Visual Studio 2010 Express Edition SP1 or greater (&lt;a href="http://visualstudio.com/"&gt;visualstudio.com&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;Microsoft Dot Net Framework version 4 or greater&lt;/li&gt;
    &lt;li&gt;Java JRE (&lt;a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html"&gt;http://www.oracle.com/technetwork/java/javase/downloads/index.html&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;Mercurial (&lt;a href="http://mercurial.selenic.com/"&gt;mercurial.selenic.com&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;Mozilla Firefox (&lt;a href="http://getfirefox.com/"&gt;getfirefox.com&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;Nuget (&lt;a href="http://docs.nuget.org/docs/start-here/installing-nuget"&gt;docs.nuget.org/docs/start-here/installing-nuget&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;
Step1: Prepare a Selenium endpoint&lt;/h2&gt;
Firstly we will prepare for our UI tests by setting up a Selenium server. &amp;#160;&lt;span&gt;&lt;a&gt;&lt;/a&gt;&lt;span&gt;&lt;a href="http://docs.seleniumhq.org/"&gt;Selenium&lt;/a&gt; is a browser automation framework which will be used to 'remote control' a real browser.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;br&gt;
Log into the machine you have chosen for the Selenium server with administrator
privileges&lt;br&gt;
Download and install Mozilla Firefox (getfirefox.com), this will be the browser
that we target as part of this example, however Selenium can target lots of other
browsers. &amp;#160;For a full breakdown please &lt;a&gt;&lt;/a&gt;&lt;br&gt;
Download Selenium Server (&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
Place it into a permanent
location of you choosing, in our example ("C:\Program Files (x86)\SeleniumServer")
&amp;#160; &amp;#160;&amp;#160;&lt;br&gt;
Download NSSM (&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
Ensure that port 4444 is set to allow traffic (this is the default communications&amp;#160;port
for Selenium)&amp;#160;&lt;br&gt;
&lt;br&gt;
Open a console and run the following commands:&amp;#160;&lt;br&gt;
&lt;p&gt;"C:\Program Files (x86)\nssm-2.22\win64\nssm.exe"
install Selenium-Server "java" "-jar \"C:\Program Files (x86)\SeleniumServer\selenium-server-standalone-2.41.0.jar\""&lt;br&gt;
net start Selenium-Server&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/install-sel-1.png" alt="name project"&gt;
&lt;br&gt;
&amp;#160;&lt;br&gt;
In order to uninstall the Selenium server service, the following commands can be
run:&amp;#160;&lt;br&gt;
&lt;p&gt;net stop Selenium-Server&lt;br&gt;
"C:\Program Files (x86)\nssm-2.22\win64\nssm.exe" remove Selenium-Server &lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/install-sel-2.png" alt="name project"&gt;
&lt;br&gt;
&lt;h2&gt;
Step2: Create a test class and add it to source control&lt;/h2&gt;
Create a new class library project in Visual Studio, &amp;#160;lets call it 'tests'&lt;br&gt;
Open the Nuget Package Manager Console window (tools menu-&amp;gt; library package manager
-&amp;gt; package manager console), select the test project as the default project and
run the following script:&amp;#160;&lt;br&gt;
&lt;br&gt;
Install-Package Selenium.Automation.Framework&lt;br&gt;
Install-Package Selenium.WebDriver&lt;br&gt;
Install-Package Selenium.Support&lt;br&gt;
Install-Package NUnit&lt;br&gt;
Install-Package NUnit.Runners&lt;br&gt;
&lt;br&gt;
Create a new class called within the tests project (lets call it tests) and place
the below code (Note: line 23 should be changed with location to the Selenium-Server
we setup in the previous step):&lt;br&gt;
&lt;br&gt;
&lt;pre class="brush: c#; toolbar:true"&gt;using System;
using System.Text;
using NUnit.Framework;
using OpenQA.Selenium.Firefox;
using OpenQA.Selenium;
using OpenQA.Selenium.Remote;
using OpenQA.Selenium.Support.UI;

namespace SeleniumTests
{
    [TestFixture]
    public class test
    {
        private RemoteWebDriver driver;
       

        [SetUp]
        public void SetupTest()
        {

            // Look for an environment variable
            string server = null;
            server = System.Environment.GetEnvironmentVariable("SELENIUM_SERVER");
            if (server == null)
            {
                server = "http:// *** PUT THE NAME OF YOUR SERVER HERE ***:4444/wd/hub";
            }
            
            // Remote testing
            driver = new RemoteWebDriver(new Uri(server), DesiredCapabilities.Firefox());
        }

        [TearDown]
        public void TeardownTest()
        {
            try
            {
                driver.Quit();
            }
            catch (Exception)
            {
                // Ignore errors if unable to close the browser
            }
        }

        [Test]
        public void FirstSeleniumTest()
        {
            driver.Navigate().GoToUrl("http://www.google.com/");
            IWebElement query = driver.FindElement(By.Name("q"));
            query.SendKeys("a test");
            Assert.AreEqual(driver.Title, "Google"); 
        }
       
    }
}
&lt;/pre&gt;
&lt;h2&gt;Step3: Test the test!&lt;/h2&gt;
Build the solution&amp;#160;&lt;br&gt;
Open NUnit build runner (by default this is located at ~\packages\NUnit.Runners.2.6.3\tools\nunit.exe)
, Select file -&amp;gt; Open Project, and locate the tests dll that you have build in
the previous step&lt;br&gt;
click the run button&lt;br&gt;
~ 15 seconds or so you should have one green test!&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-17.png" alt="name project"&gt;
&lt;br&gt;
&lt;br&gt;
So what just happened? &amp;#160;Behind the scenes an instance of firefox was opened
(on the Selenium Server), perform a simple google search query and undertook a simple
Nunit assertion has verified the name of the window was equal to "Google", very
cool!. &amp;#160;&lt;br&gt;
&lt;br&gt;
Now lets make the test fail, go ahead and change line 78, lets say "zzGoogle", build,
and rerun the test. &amp;#160;We now have a failing test. &amp;#160;Go ahead and change
it back so that we have a single passing test.&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-18.png" alt="name project"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;Create a source control repository&lt;/h4&gt;
&lt;p&gt;In this article we will be focusing on the functional testing component of this pipeline. We will proceed on the assumption that your code has already been, built unit tested and deployed to a Functional Test environment. Today we will;Firstly we will prepare for our UI tests by setting up a Selenium server.This machine will be designated for performing the UI tests against, preferably this will be a machine separate from your ContinuaCI server.Log into the machine you have chosen for the Selenium server with administrator privilegesDownload and install Mozilla Firefox (getfirefox.com), this will be the browser that we target as part of this example, however Selenium can target lots of other browsers. For a full breakdown please &lt;a href="http://docs.seleniumhq.org/about/platforms.jsp"&gt;
see the docs page&lt;/a&gt; : .Download Selenium Server ( &lt;a href="http://docs.seleniumhq.org/download"&gt;docs.seleniumhq.org/download&lt;/a&gt; ), at the time of writing the latest version is 2.41.0.Place it into a permanent location of you choosing, in our example ("C:\Program Files (x86)\SeleniumServer")Download NSSM ( &lt;a href="http://nssm.cc/download"&gt;nssm.cc/download&lt;/a&gt; ), unzip it and place into a permanent location of you choosing "C:\Program Files (x86)\nssm-2.22\"Ensure that port 4444 is set to allow traffic (this is the default communications port for Selenium)Open a console and run the following commands:In order to uninstall the Selenium server service, the following commands can be run:Create a new class library project in Visual Studio, lets call it 'tests'Open the Nuget Package Manager Console window (tools menu-&amp;gt; library package manager -&amp;gt; package manager console), select the test project as the default project and run the following script:Install-Package Selenium.Automation.FrameworkInstall-Package Selenium.WebDriverInstall-Package Selenium.SupportInstall-Package NUnitInstall-Package NUnit.RunnersCreate a new class called within the tests project (lets call it tests) and place the below code (Note: line 23 should be changed with location to the Selenium-Server we setup in the previous step):Build the solutionOpen NUnit build runner (by default this is located at ~\packages\NUnit.Runners.2.6.3\tools\nunit.exe) , Select file -&amp;gt; Open Project, and locate the tests dll that you have build in the previous stepclick the run button~ 15 seconds or so you should have one green test!So what just happened? Behind the scenes an instance of firefox was opened (on the Selenium Server), perform a simple google search query and undertook a simple Nunit assertion has verified the name of the window was equal to "Google", very cool!.Now lets make the test fail, go ahead and change line 78, lets say "zzGoogle", build, and rerun the test. We now have a failing test. Go ahead and change it back so that we have a single passing test.&lt;/p&gt;&lt;p&gt;In this example, we're using mercurial&lt;/p&gt;
&lt;p&gt;open a command prompt at ~\&lt;/p&gt;&lt;br&gt;
&lt;p&gt;type "hg init"&lt;/p&gt;&lt;br&gt;
&lt;p&gt;add a .hgignore file into the directory. &amp;#160;For&amp;#160;convenience&amp;#160;we have
prepared one for you&amp;#160;&lt;/p&gt;&lt;a https: www.finalbuilder.com portals 0 articleimages blogimages peter .hgignore.txt&gt;here&lt;/a&gt;&amp;#160;&lt;br&gt;
&lt;p&gt;type "hg add"&lt;/p&gt;&lt;br&gt;
&lt;p&gt;type "hg commit -m "initial commit""&lt;/p&gt;
&lt;br&gt;
&lt;h2&gt;Step 4: Setting up Automated UI testing in ContinuaCI&lt;/h2&gt;
Navigate to the ContinuaCI web interface
&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Create a project&lt;/h4&gt;
&lt;br&gt;
Open ContinuaCI&lt;br&gt;
Select "Create Project" from the top tasks dropdown menu&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-1.png" alt="create project"&gt;&lt;br&gt;
&lt;br&gt;
Name the project something memerable; &amp;#160;In our case: "pete sel test 1"&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-3.png" alt="name project"&gt;&lt;br&gt;
Click the "Save &amp;amp; Complete Wizard" button&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Create a configuration for this project&lt;/h4&gt;
&lt;br&gt;
Click "Create a Configuration"&lt;br&gt;
Name the config something memorable; in our case "sel-testconfig-1"&lt;br&gt;
Click save &amp;amp; Continue&lt;br&gt;
Click the 'Enable now' link at the bottom of the page to enable this configuration&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Point to our Repository&lt;/h4&gt;
&lt;br&gt;
under the section "Configuration Repositories", select the "Create" link&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-4.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Name the repository "test_repo"&lt;br&gt;
Select "Mercurial" from the "type" dropdown list&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-6.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Select the Mercurial" tab from the top of the dialogue box&lt;br&gt;
Enter the repository location under "source path" &amp;#160;in our case '\\machinename\c$\sel-blog-final'&lt;br&gt;
Click validate to ensure all is well&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-8.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Click save, your repository is now ready to go!&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-9.png" alt="name project"&gt;&lt;br&gt;
&lt;h4&gt;
Add actions to our build&lt;/h4&gt;
&lt;br&gt;
Click on the Stages tab&lt;br&gt;
We will add a nuget restore action, click on the "Nuget" section from the categories
on the left&lt;br&gt;
Drag and drop the action "Nuget Restore" onto the design surface&lt;br&gt;
Enter the location of the solution file: "$Source.test_repo$\tests.sln"&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-11.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Click Save&lt;br&gt;
&amp;#160;&lt;br&gt;
&lt;h4&gt;
Build our tests&lt;/h4&gt;
&lt;br&gt;
Click on the "Build runners" category from the categories on the left hand menu&lt;br&gt;
Drag and drop a Visual Studio action onto the design surface (note that the same
outcome can be achieved here with an MSBuild action).&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-19.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-13.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Enter the name of the solution file: "$Source.test_repo$\tests.sln"&lt;br&gt;
Specify that this should be a 'Release' build under the configuration option&lt;br&gt;
Click save&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Setup ContinuaCI to run our Nunit tests&lt;/h4&gt;
&lt;br&gt;
Select the 'unit testing' category from the left hand menu&lt;br&gt;
Drag and drop an NUnit action onto the design surface&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-20.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Name our action 'run UI tests'&lt;br&gt;
Within the files: option, specify the name of the tests project '$Source.test_repo$\tests\tests.csproj'&lt;br&gt;
Within the Project Configuration section specify 'Release'&lt;br&gt;
Specify which version of NUnit&lt;br&gt;
In order to provide greater configuration flexibility &amp;#160;we can pass in the location
of our Selenium server to the tests at runtime.&amp;#160; This is done within the 'Environments'
tab. &amp;#160;In our case the location of the Selenium server is&lt;p&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;http://SELSERVER:4444/wd/hub&lt;/p&gt;&lt;p&gt;.&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-24.png" alt="environment tab"&gt;&lt;br&gt;
&lt;br&gt;
Click Save&lt;br&gt;
&lt;br&gt;
Click save and complete Wizard
&lt;br&gt;
We are now ready to build!&lt;br&gt;
&lt;br&gt;
Start a build immediately by clicking the top right hand side fast forward icon&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-14.png" alt="name project"&gt;&lt;br&gt;
A build will start, and complete!&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-15.png" alt="name project"&gt;&lt;br&gt;
When viewing the build log (this can be done by clicking on the green build number,
then selecting the log tab) we can see that our UI tests have been run successfully.
&amp;#160;They are also visible within the 'Unit Tests' tab which displays further metrics
around the tests.&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-23.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-22.png" alt="name project"&gt;
&lt;h2&gt;
Step 5: Getting more advanced&lt;/h2&gt;
&lt;p&gt;Navigate to the ContinuaCI web interfaceOpen ContinuaCISelect "Create Project" from the top tasks dropdown menuName the project something memerable; In our case: "pete sel test 1"Click the "Save &amp;amp; Complete Wizard" buttonClick "Create a Configuration"Name the config something memorable; in our case "sel-testconfig-1"Click save &amp;amp; ContinueClick the 'Enable now' link at the bottom of the page to enable this configurationunder the section "Configuration Repositories", select the "Create" linkName the repository "test_repo"Select "Mercurial" from the "type" dropdown listSelect the Mercurial" tab from the top of the dialogue boxEnter the repository location under "source path" in our case '\\machinename\c$\sel-blog-final'Click validate to ensure all is wellClick save, your repository is now ready to go!Click on the Stages tabWe will add a nuget restore action, click on the "Nuget" section from the categories on the leftDrag and drop the action "Nuget Restore" onto the design surfaceEnter the location of the solution file: "$Source.test_repo$\tests.sln"Click SaveClick on the "Build runners" category from the categories on the left hand menuDrag and drop a Visual Studio action onto the design surface (note that the same outcome can be achieved here with an MSBuild action).Enter the name of the solution file: "$Source.test_repo$\tests.sln"Specify that this should be a 'Release' build under the configuration optionClick saveSelect the 'unit testing' category from the left hand menuDrag and drop an NUnit action onto the design surfaceName our action 'run UI tests'Within the files: option, specify the name of the tests project '$Source.test_repo$\tests\tests.csproj'Within the Project Configuration section specify 'Release'Specify which version of NUnitIn order to provide greater configuration flexibility we can pass in the location of our Selenium server to the tests at runtime. This is done within the 'Environments' tab. In our case the location of the Selenium server isClick SaveClick save and complete WizardWe are now ready to build!Start a build immediately by clicking the top right hand side fast forward iconA build will start, and complete!When viewing the build log (this can be done by clicking on the green build number, then selecting the log tab) we can see that our UI tests have been run successfully. They are also visible within the 'Unit Tests' tab which displays further metrics around the tests.&lt;/p&gt;&lt;p&gt;
Lets try a slightly more advanced example. &amp;#160;This time we will examine a common
use case. &amp;#160;A physical visual inspection test needs to be conducted before a
release can progress in the pipeline.&lt;br&gt;
&lt;br&gt;
Place the following code within our test class.&lt;br&gt;
&lt;br&gt;
&lt;/p&gt;
&lt;pre class="brush: c#; toolbar:true"&gt;using System;
using System.Text;
using NUnit.Framework;
using OpenQA.Selenium.Firefox;
using OpenQA.Selenium;
using OpenQA.Selenium.Remote;
using OpenQA.Selenium.Support.UI;

namespace SeleniumTests
{
    [TestFixture]
    public class test
    {
        private RemoteWebDriver driver;
       

        [SetUp]
        public void SetupTest()
        {

            // Look for an environment variable
            string server = null;
            server = System.Environment.GetEnvironmentVariable("SELENIUM_SERVER");
            if (server == null)
            {
                server = "http:// *** PUT THE NAME OF YOUR SERVER HERE ***:4444/wd/hub";
            }
            
            // Remote testing
            driver = new RemoteWebDriver(new Uri(server), DesiredCapabilities.Firefox());
        }

        [TearDown]
        public void TeardownTest()
        {
            try
            {
                driver.Quit();
            }
            catch (Exception)
            {
                // Ignore errors if unable to close the browser
            }
        }

        [Test]
        public void FirstSeleniumTest()
        {
            driver.Navigate().GoToUrl("http://www.google.com/");
            IWebElement query = driver.FindElement(By.Name("q"));
            query.SendKeys("a test");
            Assert.AreEqual(driver.Title, "Google"); 
        }
        [Test]
        public void MySecondSeleniumTest()
        {
            // Navigate to google
            driver.Navigate().GoToUrl("http://www.google.com/");
            IWebElement query = driver.FindElement(By.Name("q"));
            
            // Write a query into the window
            query.SendKeys("a test");

            // wait at maximum ten seconds for results to display
            var wait = new WebDriverWait(driver, TimeSpan.FromSeconds(10));
            IWebElement myDynamicElement = wait.Until&amp;lt; IWebElement &amp;gt;((d) =&amp;gt;
            {
                return d.FindElement(By.Id("ires"));
            });

            // take a screenshot of the result for visual verification
            var fileName = TestContext.CurrentContext.Test.Name + "-" + string.Format("{0:yyyyMMddHHmmss}", DateTime.Now) + ".png";
            driver.GetScreenshot().SaveAsFile(fileName, System.Drawing.Imaging.ImageFormat.Png);

            // perform an code assertion
            Assert.AreEqual(driver.Title, "Google");          
        }
    }
}
&lt;/pre&gt;
&lt;br&gt;
&lt;br&gt;
Build, and run the test. &amp;#160;&lt;br&gt;
&lt;br&gt;
In this example we added an additional test to perform a google search, wait at
maximum 10 seconds for &amp;#160;results to display, take a screenshot (stored it to
disk), and perform an NUnit assertion. &amp;#160;The screenshot output from the test
can be made available as an artifact within Continua!
&lt;br&gt;
&lt;br&gt;
Firstly lets commit our changes; "hg commit -m "added a more advanced test""&lt;br&gt;
&lt;br&gt;
Open the configuration in Continua CI (clicking the pencil icon)&lt;br&gt;
Navigate to the stages section&amp;#160;&lt;br&gt;
Double click on the stage name (which will bring up the edit stage Dialogue box)&amp;#160;&lt;br&gt;
Click on the Workspace rules tab&lt;br&gt;
Add the following line to the bottom of the text area: "/ &amp;lt; $Source.test_repo$/tests/bin/Release/**.png".
&amp;#160;This will tell Continua to return any .png files that we produced from this
test back to the ContinuaCI Server.&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-25.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Click on the artifacts tab.&lt;br&gt;
Add the following line : **.png" &amp;#160;This will enable any .png files within
the workspace to be picked up and displayed within the Artifacts tab.&lt;br&gt;
**.png&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-26.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Click save&lt;br&gt;
Click Save &amp;amp; Complete Wizard&lt;br&gt;
Start a new build&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-14.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Sweet! &amp;#160;A screenshot of our test was produced, and can be seen within the Artifacts
tab! &amp;#160; &amp;#160;&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-27.png" alt="name project"&gt;&lt;br&gt;
Clicking on 'View' will display the image: &amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-28.png" alt="name project"&gt;&lt;br&gt;
&amp;#160;&lt;br&gt;
&lt;p&gt;We have put the sourcecode of this article up on&amp;#160;&lt;/p&gt;&lt;a href="https://github.com/VSoftTechnologies/Automated-UI-Testing"&gt;Github&lt;/a&gt;&lt;p&gt;.&lt;br&gt;
&lt;/p&gt;
&lt;br&gt;
Please subscribe and comment! &amp;#160;We are very excited to see what you guys come
up with on Continua, happy testing!
&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Some additional considerations:&lt;/h4&gt;
&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;
    &lt;li&gt;The user which the Selenium service runs under should have correct privileges&lt;/li&gt;
    &lt;li&gt;The machine designated as the Selenium server may require access to the internet
    if your webapp has upstream dependencies (eg third party API's like github)&lt;/li&gt;
    &lt;li&gt;
    &lt;li&gt;
    &lt;li&gt;&amp;#160;&amp;#160;&lt;/li&gt;
&lt;/ul&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;Build, and run the test.In this example we added an additional test to perform a google search, wait at maximum 10 seconds for results to display, take a screenshot (stored it to disk), and perform an NUnit assertion. The screenshot output from the test can be made available as an artifact within Continua!Firstly lets commit our changes; "hg commit -m "added a more advanced test""Open the configuration in Continua CI (clicking the pencil icon)Navigate to the stages sectionDouble click on the stage name (which will bring up the edit stage Dialogue box)Click on the Workspace rules tabAdd the following line to the bottom of the text area: "/ &lt;/p&gt;&lt;/div&gt;</summary></entry><entry><title>ContinuaCI Version 1.5</title><link href="http://www.ciandcd.com/continuaci-version-15.html" rel="alternate"></link><updated>2015-06-27T04:04:48+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:continuaci-version-15.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/711/continua-15-new-dashboards"&gt;https://www.finalbuilder.com/resources/blogs/postid/711/continua-15-new-dashboards&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
With the upcoming 1.5 release of ContinuaCI &amp;#160;we have made a number of enhancements to the dashboards, we think you'll love them! &amp;#160;Here is a peek at what's coming soon.&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;The New List View&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/all-projects.png" alt="all-projects-listview"&gt;&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Improvements:&lt;/strong&gt;&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;-  Stage indicator blocks provide quick drill-down into the build log.&lt;/li&gt;
    &lt;li&gt;-  Improved viability and responsiveness of build actions buttons.&lt;/li&gt;
    &lt;li&gt;-  Build action buttons moved to the left for easier access.&lt;/li&gt;
    &lt;li&gt;-  Viability enhancements around projects.&lt;/li&gt;
    &lt;li&gt;-  Improved Responsiveness and performance tweeks.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h4&gt;List View: With Builds Completed&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/all-projects-completed-build.png" alt="all-projects-listview-completed-builds"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;List View: With Builds Running&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/all-projects-multibuild.png" alt="all-projects-listview-completed-multibuilds"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;The New Details View&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/detail-view.png" alt="details-view"&gt;&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Improvements:&lt;/strong&gt;&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;-  Build and Queue times now have graphs!&lt;/li&gt;
    &lt;li&gt;-  Build status card on the left hand side displays the status of the build as it progresses.&lt;/li&gt;
    &lt;li&gt;-  Build action buttons are more obvious and responsive.&lt;/li&gt;
    &lt;li&gt;-  Stage indicator blocks (present on the build status cards) provide quick drill-down into the build log.&lt;/li&gt;
    &lt;li&gt;-  Improved Responsiveness and performance tweeks.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h4&gt;Details View: with Builds Queued&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/detail-view-queued.png" alt="details-view-queued"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;Details View: with Builds Executing&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/detail-view-building.png" alt="details-view-building"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;Details View: with Builds Finished&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/detail-view-finished.png" alt="details-view-finished"&gt;&lt;br&gt;
&lt;br&gt;
Stay tuned for more exciting details regarding the version 1.5 release!&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;With the upcoming 1.5 release of ContinuaCI we have made a number of enhancements to the dashboards, we think you'll love them! Here is a peek at what's coming soon.Stay tuned for more exciting details regarding the version 1.5 release!&lt;/p&gt;&lt;/div&gt;</summary></entry><entry><title>Deployment with Continua CI 1.5 and Octopus Deploy</title><link href="http://www.ciandcd.com/deployment-with-continua-ci-15-and-octopus-deploy.html" rel="alternate"></link><updated>2015-06-27T04:04:35+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:deployment-with-continua-ci-15-and-octopus-deploy.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/712/deployment-with-continua-ci-and-octopus-deploy"&gt;https://www.finalbuilder.com/resources/blogs/postid/712/deployment-with-continua-ci-and-octopus-deploy&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;/h2&gt;
So you've got your Continua CI server set up to automatically build, run unit tests and produce reports for your awesome new web application. Now you're ready to try out your project in its natural environment and then eventually release it to the wild for well-deserved public applause.&lt;br&gt;
&lt;br&gt;
Up until now, your options were either to use a Copy action to push the files up to test server and a PowerShell action to set up web services, or preferably run a FinalBuilder script utilising the plethora of actions available for transferring files and interacting with web servers.&lt;br&gt;
&lt;br&gt;
As of version 1.5, Continua CI can also work together with &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
This post will walk through the steps required to push a .Net web application built in Continua to Octopus Deploy and trigger a deployment process to effortlessly get your application running on your test and production servers.&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Preparing your solution&lt;/h3&gt;
&lt;br&gt;
Octopus Deploy requires that you provide your applications as &lt;a&gt;&lt;/a&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
Lets go with the recommended OctoPack option. First prepare your Visual Studio solution - use the NuGet package manager to install the OctoPack package into the projects you want to deploy. This will include web application projects, console application projects and Windows service projects but not class libraries and unit test projects.&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/octopack.png"&gt;
&lt;br&gt;
&lt;br&gt;
You can now optionally add a &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/nuspec.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Setting up the deployment process&lt;/h3&gt;
&lt;br&gt;
Next head over to your Octopus server and set up a deployment project. This should include a &amp;#8220;Deploy a NuGet package&amp;#8221; process step as below.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeploymentStep.png"&gt;
&lt;br&gt;
&lt;br&gt;
We will set this to retrieve the application package from the built-in NuGet feed. Note that the NuGet package id should match the id element in your .nuspec file - this will default to the name of your assembly.&lt;br&gt;
&lt;br&gt;
We added a few more steps:&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeploymentProcess.png"&gt;
&lt;br&gt;
&lt;br&gt;
And some variables:&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeploymentVariables.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Setting up the build process&lt;/h3&gt;
&lt;br&gt;
You can now get back to Continua and set up a configuration for building your project. Once you have entered the configuration details and linked up the repository containing your project, move on over to the Stages page:&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/BuildStage.png"&gt;
&lt;br&gt;
&lt;br&gt;
For this simple example you'll need two actions: a NuGet Restore action to ensure that the OctoPack package is available for the build and an MSBuild action to build and push the application to your Octopus Deploy server.&lt;br&gt;
Just enter the path to your solution for the NuGet Restore action (the other fields can be left as is) and complete the main tab of the MSBuild action as required for your project.&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/MSBuildAction.png"&gt;
&lt;br&gt;
&lt;br&gt;
You then need to enter some additional properties to tell MSBuild to run OctoPack and tell it where to send your package.&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/MSBuildProperties.png"&gt;
&lt;br&gt;
&lt;br&gt;
Set the RunOctoPack property to true and the OctoPackPublishPackageToHttp property to the URL for the NuGet feed on the Octopus Deploy server e.g. &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
You will also need to provide an OctoPackPublishAPIKey property &amp;#8211; you can generate an API key on your profile page on the Octopus Deploy server. &lt;br&gt;
&lt;br&gt;
&lt;p&gt;Optionally, y&lt;/p&gt;ou can &amp;#160;use the OctoPackPackageVersion to specify up the package version. Here we use Continua expressions to set this based on the build version. If you leave this out then OctoPack will get this value from the AssemblyVersion property&amp;#160;in your AssemblyInfo.cs file.&lt;br&gt;
&lt;br&gt;
Once the actions are set up and saved, run a build and check that your package gets uploaded to the Octopus Deploy server. Then create a release for your deployment project and test that it deploys ok. Now we are ready to look into how to run this process automatically from Continua CI.&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Build event handler&lt;/h3&gt;
&lt;br&gt;
On the Continua CI configuration wizard after Stages, we have a new area titled Events. Here you can add &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
Create a new build event handler, give it a name and select the Octopus Deploy as the Type.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/NewEventHandler.png"&gt;
&lt;br&gt;
&lt;br&gt;
You can now provide general project details under the Octopus Deploy tab.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/OctopusDeployDetails.png"&gt;
&lt;br&gt;
&lt;br&gt;
The Octopus Deploy URL should end with '/api' e.g.  http://octopusserver/api. Enter the API key generated under your Octopus Deploy profile and the name of your deployment project.&lt;br&gt;
&amp;#160;&amp;#160;&lt;br&gt;
You can then choose one or more actions to run. The available options are &lt;strong&gt;Create&lt;/strong&gt;, &lt;strong&gt;Deploy&lt;/strong&gt; and &lt;strong&gt;Promote&lt;/strong&gt; and are used to create a new deployment release, deploy a release to an environment and promote a release from one environment to another. As you select each action, new tabs open so you can provide further details and hook the action to a build event.
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Creating a release&lt;/h3&gt;
&lt;br&gt;
Before you can deploy an application you need to create a Octopus Deploy release&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/CreateRelease.png"&gt;
&lt;br&gt;
&lt;br&gt;
When creating a release you can specify the Release Version or leave this blank to automatically create a number based on the highest package version. You must provide either a Default Package Version or Step Package Versions for each step which requires one e.g.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/StepPackageVersions.png"&gt;
&lt;br&gt;
&lt;br&gt;
Flip over to the Create Options tab to tell Continua when to create the release.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/CreateOptions.png"&gt;
&lt;br&gt;
&lt;br&gt;
There are six &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt; On Before Stage Start&lt;/li&gt;
    &lt;li&gt;    On Sending Stage To Agent&lt;/li&gt;
    &lt;li&gt;    On Stage Completed&lt;/li&gt;
    &lt;li&gt;    On Build Pending Promotion&lt;/li&gt;
    &lt;li&gt;    On After Build Continued&lt;/li&gt;
    &lt;li&gt;    On Build Completed&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
Generally we want to create the release at the start of the build before the first stage starts.&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;    Deploying to an environment&lt;/h3&gt;
&lt;br&gt;
Now on to the crux of this whole process - deploying your application. We generally deploy to a Test environment first and then, once we are happy with the outcome, promote to a User Acceptance environment or directly to Production. Continua CI allows you to deploy a release previously created by a Create action in the same build event handler, the highest release version in the project or a specific release version. It's up to you to ensure that the release version exists before the deploy action is run. An environment can consist of multiple machines - you can specify which machines you want to deploy to. If no machines are specified then the release will be deployed to all machines in the environment.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeployRelease.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
When selecting the Build Event for deployment, ensure that it is triggerred after the package has been built and pushed to the Octopus Deploy server. Here we have set this to be run once the Build stage has completed successfully.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeployOptions.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Promoting a release&lt;/h3&gt;
&lt;br&gt;
You can promote the latest release from one environment to another. Ideally this would be linked to the promotion of a stage e.g. a testing stage, so that the application can be promoted from a test environment to production environment.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/PromoteRelease.png"&gt;
&lt;br&gt;
&lt;br&gt;
We have set our test stage to require manual promotion;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/StagePromoteOptions.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
and set our promote action to run when a build is continued after waiting for promotion.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/PromoteOptions.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;h3&gt;Variables&lt;/h3&gt;
&lt;br&gt;
You can also pass variables from Continua CI to your deployment, these will be sent to the Octopus Deploy server before each action is run, updating the variables for the deployment project. We have used expressions is this example to send the build versions number and branch name. These variables can then be used to update project files with details for display or configure services differently depending on the source of the project.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/Variables.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Running the configuration&lt;/h3&gt;
&lt;br&gt;
Once your build event handler dialog has been completed and saved, its time to start running the configuration. As the build processes Continua CI will display status information mirroring the process running on Octopus Deploy.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/Status.png"&gt;
&lt;br&gt;
&lt;br&gt;
You can also see full details of the deployment process in the build log.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/BuildLog.png"&gt;
&lt;br&gt;
&lt;br&gt;
And all going well you will now see a successful deployment on your Octopus Deploy server!
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/Success.png"&gt;
&lt;br&gt;
&lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;So you've got your Continua CI server set up to automatically build, run unit tests and produce reports for your awesome new web application. Now you're ready to try out your project in its natural environment and then eventually release it to the wild for well-deserved public applause.Up until now, your options were either to use a Copy action to push the files up to test server and a PowerShell action to set up web services, or preferably run a FinalBuilder script utilising the plethora of actions available for transferring files and interacting with web servers.As of version 1.5, Continua CI can also work together with &lt;a href="https://octopusdeploy.com"&gt;Octopus Deploy&lt;/a&gt; server to provide an end-to-end continuous delivery mechanism. Using the new build event handlers feature, Continua CI builds can now be set up to create Octopus Deploy releases and initiate deployment to test and production environments, at key points in the build process.This post will walk through the steps required to push a .Net web application built in Continua to Octopus Deploy and trigger a deployment process to effortlessly get your application running on your test and production servers.Octopus Deploy requires that you provide your applications as &lt;a href="https://www.nuget.org"&gt;NuGet packages&lt;/a&gt; . You can create and push the package to the Octopus Deploy server using Nuget Pack and Push actions, or create and push an &lt;a href="http://docs.octopusdeploy.com/display/OD/Using+OctoPack"&gt;OctoPack&lt;/a&gt; from MSBuild or VisualStudio build runner actions.Lets go with the recommended OctoPack option. First prepare your Visual Studio solution - use the NuGet package manager to install the OctoPack package into the projects you want to deploy. This will include web application projects, console application projects and Windows service projects but not class libraries and unit test projects.You can now optionally add a &lt;a href="http://docs.nuget.org/docs/reference/nuspec-reference"&gt;.nuspec file&lt;/a&gt; to the root folder of your project to describe the contents of your package. If you don't provide a .nuspec file, OctoPack will automatically create one based on your project settings.Next head over to your Octopus server and set up a deployment project. This should include a &amp;#8220;Deploy a NuGet package&amp;#8221; process step as below.We will set this to retrieve the application package from the built-in NuGet feed. Note that the NuGet package id should match the id element in your .nuspec file - this will default to the name of your assembly.We added a few more steps:And some variables:You can now get back to Continua and set up a configuration for building your project. Once you have entered the configuration details and linked up the repository containing your project, move on over to the Stages page:For this simple example you'll need two actions: a NuGet Restore action to ensure that the OctoPack package is available for the build and an MSBuild action to build and push the application to your Octopus Deploy server.Just enter the path to your solution for the NuGet Restore action (the other fields can be left as is) and complete the main tab of the MSBuild action as required for your project.You then need to enter some additional properties to tell MSBuild to run OctoPack and tell it where to send your package.Set the RunOctoPack property to true and the OctoPackPublishPackageToHttp property to the URL for the NuGet feed on the Octopus Deploy server e.g. &lt;a href="http://octopusserver/nuget/packages"&gt;http://octopusserver/nuget/packages&lt;/a&gt; You will also need to provide an OctoPackPublishAPIKey property &amp;#8211; you can generate an API key on your profile page on the Octopus Deploy server.ou can use the OctoPackPackageVersion to specify up the package version. Here we use Continua expressions to set this based on the build version. If you leave this out then OctoPack will get this value from the AssemblyVersion property in your AssemblyInfo.cs file.Once the actions are set up and saved, run a build and check that your package gets uploaded to the Octopus Deploy server. Then create a release for your deployment project and test that it deploys ok. Now we are ready to look into how to run this process automatically from Continua CI.On the Continua CI configuration wizard after Stages, we have a new area titled Events. Here you can add &lt;a href="http://wiki.finalbuilder.com/x/BgB4"&gt;Build Event Handlers&lt;/a&gt; for tagging repository changesets, updating the GitHub status and interacting with Octopus Deploy.Create a new build event handler, give it a name and select the Octopus Deploy as the Type.You can now provide general project details under the Octopus Deploy tab.The Octopus Deploy URL should end with '/api' e.g. http://octopusserver/api. Enter the API key generated under your Octopus Deploy profile and the name of your deployment project.You can then choose one or more actions to run. The available options areandand are used to create a new deployment release, deploy a release to an environment and promote a release from one environment to another. As you select each action, new tabs open so you can provide further details and hook the action to a build event.Before you can deploy an application you need to create a Octopus Deploy releaseWhen creating a release you can specify the Release Version or leave this blank to automatically create a number based on the highest package version. You must provide either a Default Package Version or Step Package Versions for each step which requires one e.g.Flip over to the Create Options tab to tell Continua when to create the release.There are six &lt;a href="http://wiki.finalbuilder.com/x/GQB4"&gt;Build Events&lt;/a&gt; available to choose from. Some allow you to select a Stage and some allow you to select a successful or failed Build StatusGenerally we want to create the release at the start of the build before the first stage starts.Now on to the crux of this whole process - deploying your application. We generally deploy to a Test environment first and then, once we are happy with the outcome, promote to a User Acceptance environment or directly to Production. Continua CI allows you to deploy a release previously created by a Create action in the same build event handler, the highest release version in the project or a specific release version. It's up to you to ensure that the release version exists before the deploy action is run. An environment can consist of multiple machines - you can specify which machines you want to deploy to. If no machines are specified then the release will be deployed to all machines in the environment.When selecting the Build Event for deployment, ensure that it is triggerred after the package has been built and pushed to the Octopus Deploy server. Here we have set this to be run once the Build stage has completed successfully.You can promote the latest release from one environment to another. Ideally this would be linked to the promotion of a stage e.g. a testing stage, so that the application can be promoted from a test environment to production environment.We have set our test stage to require manual promotion;and set our promote action to run when a build is continued after waiting for promotion.You can also pass variables from Continua CI to your deployment, these will be sent to the Octopus Deploy server before each action is run, updating the variables for the deployment project. We have used expressions is this example to send the build versions number and branch name. These variables can then be used to update project files with details for display or configure services differently depending on the source of the project.Once your build event handler dialog has been completed and saved, its time to start running the configuration. As the build processes Continua CI will display status information mirroring the process running on Octopus Deploy.You can also see full details of the deployment process in the build log.And all going well you will now see a successful deployment on your Octopus Deploy server!&lt;/p&gt;&lt;/div&gt;</summary></entry><entry><title>Using Skip and Promote Conditions in Continua CI 1.5</title><link href="http://www.ciandcd.com/using-skip-and-promote-conditions-in-continua-ci-15.html" rel="alternate"></link><updated>2015-06-27T04:04:32+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:using-skip-and-promote-conditions-in-continua-ci-15.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/713/using-skip-and-promote-conditions-in-continua-ci-15"&gt;https://www.finalbuilder.com/resources/blogs/postid/713/using-skip-and-promote-conditions-in-continua-ci-15&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;
&lt;h2&gt;Skip Conditions&lt;/h2&gt;
Skip Conditions allow you to controll whether a Stage is skipped or run based on expressions. All the expressions must evaluate to true for the stage to run (if there are no expressions then the stage will not be skipped).&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/blogimages/vincent/Continua-skip-conditions/skipconditions.png" alt="Skip Conditions"&gt;&lt;br&gt;
&lt;br&gt;
In the above example, we have a Stage called Obfuscate, and we want it to be skipped if you turn off obfuscation (by setting a variable) or if we are not deploying a build (again, controlled by a variable). You can also disable a stage completely so it is always skipped.&lt;br&gt;
&lt;h2&gt;Promote Conditions&lt;/h2&gt;
In Continua CI 1.0, you can chose if the next Stage is automatically run, or the builds stops and requires a manual promotion to continue to the next Stage. In Continua CI 1.5, Promote Conditions allow you control whether to automatically promote or not, based on expressions. &lt;p&gt;&amp;#160;All the expressions must evaluate to true for the build to continue to the next stage (if there are no expressions then the build will stop with a status of waiting for promotion).&amp;#160;&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/blogimages/vincent/Continua-skip-conditions/promoteconditions.png" alt="Skip Conditions"&gt;&lt;br&gt;
&lt;br&gt;
In the above example, our build will continue on to the next Stage if the Deploy variable is set to true.&amp;#160;&lt;br&gt;
&lt;br&gt;
Continua CI 1.5 is currently in Beta - you can get it here :&lt;br&gt;
&lt;a https: www.finalbuilder.com downloads continuaci continuaci-beta-version-history title="Get the Continua CI 1.5 Beta"&gt;http://www.finalbuilder.com/downloads/continuaci/continuaci-beta-version-history&lt;/a&gt;&amp;#160;&lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;One of the most asked for features in Continua CI 1.0 was the ability to control which stages run, ie the ability to skip stages dynamically, based on what happened earlier in the build, and to be able to control whether the build should continue on to the next stage or wait for user intervention. In Continua CI 1.5, we made this possible with Skip and Promote Conditions.Skip Conditions allow you to controll whether a Stage is skipped or run based on expressions. All the expressions must evaluate to true for the stage to run (if there are no expressions then the stage will not be skipped).In the above example, we have a Stage called Obfuscate, and we want it to be skipped if you turn off obfuscation (by setting a variable) or if we are not deploying a build (again, controlled by a variable). You can also disable a stage completely so it is always skipped.In Continua CI 1.0, you can chose if the next Stage is automatically run, or the builds stops and requires a manual promotion to continue to the next Stage. In Continua CI 1.5, Promote Conditions allow you control whether to automatically promote or not, based on expressions.In the above example, our build will continue on to the next Stage if the Deploy variable is set to true.Continua CI 1.5 is currently in Beta - you can get it here :&lt;/p&gt;&lt;/div&gt;</summary></entry><entry><title>Mocking Multiple Interfaces</title><link href="http://www.ciandcd.com/mocking-multiple-interfaces.html" rel="alternate"></link><updated>2015-06-27T04:04:26+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:mocking-multiple-interfaces.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/716/mocking-multiple-interfaces-delphi-mocks"&gt;https://www.finalbuilder.com/resources/blogs/postid/716/mocking-multiple-interfaces-delphi-mocks&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Today we updated Delphi Mocks to enable the Mocking of multiple interfaces. This is useful when the interface you wish to Mock is cast to another interface during testing.
For example you could have the following system you wish to test.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;type
  {$M+}
  IVisitor = interface;

  IElement = interface
    ['{A2F4744E-7ED3-4DE3-B1E4-5D6C256ACBF0}']
    procedure Accept(const AVisitor : IVisitor);
  end;

  IVisitor = interface
    ['{0D150F9C-909A-413E-B29E-4B869C6BC309}']
    procedure Visit(const AElement : IElement);
  end;

  IProject = interface
    ['{807AF964-E937-4A8A-A3D2-34074EF66EE8}']
    procedure Save;
    function IsDirty : boolean;
  end;

  TProject = class(TInterfacedObject, IProject, IElement)
  protected
    function IsDirty : boolean;
    procedure Accept(const AVisitor : IVisitor);
  public
    procedure Save;
  end;

  TProjectSaveCheck = class(TInterfacedObject, IVisitor)
  public
    procedure Visit(const AElement : IElement);
  end;
  {$M-}

implementation

  { TProjectSaveCheck }

  procedure TProjectSaveCheck.Visit(const AElement: IElement);
  var
    project : IProject;
  begin
    if not Supports(AElement, IProject, project) then
      raise Exception.Create('Element passed to Visit was not an IProject.');

    if project.IsDirty then
      project.Save;
  end;

&lt;/pre&gt;
&lt;p&gt;The trouble previously was that when testing TProjectSaveCheck a TMock&amp;lt;IElement&amp;gt; would be required, as well as a TMock&amp;lt;IProject&amp;gt;. This is brought about by the Visit procedure requiring the IElement its passed to be an IProject for the work its going to perform.&lt;/p&gt;
&lt;p&gt;This is now very simple with the Implement&amp;lt;I&amp;gt; method available off TMock&amp;lt;T&amp;gt;. For example to test that Save is called when IsDirty returns true, the following test could be written;&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;procedure TExample_InterfaceImplementTests.Implement_Multiple_Interfaces;
var
  visitorSUT : IVisitor;
  mockElement : TMock&amp;lt;IElement&amp;gt;;
begin
  //Test that when we visit a project, and its dirty, we save.

  //CREATE - The visitor system under test.
  visitorSUT := TProjectSaveCheck.Create;

  //CREATE - Element mock we require.
  mockElement := TMock&amp;lt;IElement&amp;gt;.Create;

  //SETUP - Add the IProject interface as an implementation for the mock
  mockElement.Implement&amp;lt;IProject&amp;gt;;

  //SETUP - Mock project will show as dirty and will expect to be saved.
  mockElement.Setup&amp;lt;IProject&amp;gt;.WillReturn(true).When.IsDirty;
  mockElement.Setup&amp;lt;IProject&amp;gt;.Expect.Once.When.Save;

  //TEST - Visit the mock element to see if our test works.
  visitorSUT.Visit(mockElement);

  //VERIFY - Make sure that save was indeed called.
  mockElement.VerifyAll;
end;
&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;The Mock mockElement  "implements" two interfaces IElement, and IProject. IElement is done via the constructor, and IProject is added through the Implement&amp;lt;I&amp;gt; call. The Implement&amp;lt;I&amp;gt; call adds another sub proxy to the mock object. This sub proxy then allows all the mocking functionality to be performed with the IProject interface.&lt;/p&gt;
&lt;p&gt;To access the Setup, and Expects behaviour there are overloaded generic calls on TMock. These return the correct proxy to interact with, and generic type ISetup&amp;lt;I&amp;gt; and IExpect&amp;lt;I&amp;gt;. This is seen in the call to mockElement.Setup&amp;lt;IProject&amp;gt;. This returns a ISetup&amp;lt;IProject&amp;gt; which allows definition of what should occur when IProject is used from the Mock.&lt;/p&gt;
&lt;p&gt;This feature is really useful when there is a great deal of casting of interfaces done in the system you wish to test. It can save having to mock base classes directly where multiple interfaces are implemented.&lt;/p&gt;
&lt;p&gt;The way this works under the hood is fairly straight forward. TVirtualInterfaces are used when an interface is required to be mocked. This allows the capturing of method calls, and the creation of the interface instance when its required.&lt;/p&gt;
&lt;p&gt;The Implement&amp;lt;I&amp;gt; functionality simply extends this so that when a TProxyVirtualInterface (inherited from TVirtualInterface) has QueryInterface called it also looks to its owning Proxy. If any other Proxies implement the requested interface its that TProxyVirtualInterface which is returned.&lt;/p&gt;
&lt;p&gt;In essence this allows us to fake the Mock implementing multiple interfaces, when in fact there are a list of TVirtualInterface's all implementing a single interface.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>Filtering Tests</title><link href="http://www.ciandcd.com/filtering-tests.html" rel="alternate"></link><updated>2015-06-27T04:04:20+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:filtering-tests.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/717/dunitx-updated-filtering-tests"&gt;https://www.finalbuilder.com/resources/blogs/postid/717/dunitx-updated-filtering-tests&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;Still evolving&lt;/h2&gt;
&lt;p&gt;DUnitX is still quite young, and still evolving. One of the features most often requested (other than the gui runner, which is still planned) is the ability to select which tests to run. I found myself wishing for that feature recently. I never missed it while the number of my tests were relatively small and fast, but as time went by, it was taking longer and longer to debug tests. So, time to add filtering of fixtures and tests.&lt;/p&gt;
&lt;p&gt;The command options support in DUnitX was to be honest, quite useless and poorly though out. So my first task was to tackle how options were set/used in DUnitX, and find an extensible way of handling command line options. The result turned out better than I exepected, so I have published a separate project for that. &lt;a href="https://github.com/VSoftTechnologies/VSoft.CommandLineParser" alt="VSoft.CommandLine project on github" rel="nofollow" target="_blank"&gt;VSoft.CommandLine&lt;/a&gt; is a very simple library for defining and parsing command line options, which decouples the definition and parsing from where the parsed values are stored. I'll blog about this library separately.&lt;/p&gt;
&lt;p&gt;I did try to avoid breaking any existing test projects out there. To invoke the command line option parsing, you will need to add a call to TDUnitX.CheckCommandLine;  at the start of you project code, eg:&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;begin
  try
    TDUnitX.CheckCommandLine;
    //Create the runner
    runner := TDUnitX.CreateRunner;
&lt;/pre&gt;
&lt;p&gt;The call should be inside the try/except because it will throw exceptions if any errors are found with the command line options. I modified the IDE Expert to include the needed changes in any new projects it creates, I recommend running the expert to generate a project and then compare it to your existing dpr.&lt;/p&gt;
&lt;h2&gt;Filtering&lt;/h2&gt;
&lt;p&gt;The next thing to look at was how to apply filtering. After much experimentation, I eventually settled on pretty much copying how NUnit does it. I ported the filter and CategoryExpression classes from NUnit, with a few minor mods needed to adapt them to our needs. The cool thing here is I was able to port the associated unit tests over with ease!&lt;/p&gt;
&lt;p&gt;There are two types of filters, namespace/fixture/test filters, and category filters.&lt;/p&gt;
&lt;h3&gt;Namespace/Fixture/Test filtering&lt;/h3&gt;
&lt;p&gt;The new command line options are :&lt;/p&gt;
&lt;pre&gt;--run - specify which Fixtures or Tests to run, separate values with a comma, or specify the option multiple times&lt;/pre&gt;
eg:
&lt;pre&gt;--run:DUnitX.Tests.TestFixture,DUnitX.Tests.DUnitCompatibility.TMyDUnitTest&lt;/pre&gt;
&lt;p&gt;eg:&lt;/p&gt;&lt;p&gt;If you specify a namespace (ie unit name or part of a unit name) then all fixtures and tests matching the namespace will run.&lt;/p&gt;
&lt;h3&gt;Category Filters&lt;/h3&gt;
&lt;p&gt;A new CategoryAttribute allows you to a apply categories to fixtures and/or tests. Tests inherit their fixture's categories, except when they have their own CategoryAttribute. You can specify multiple categories, separated by commas, eg:&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;[TestFixture]
[Category('longrunning,suspect')]
TMyFixture  = class
public
    [Test]
    procedure Test1;
  
    [Test]
    [Category('fast')]
    procedure Test2;
&lt;/pre&gt;
&lt;p&gt;In the above example, Test1 would have "longrunning" and "suspect" categories, whilst Test2 would have just "fast".&lt;/p&gt;
&lt;p&gt;You can filter tests using these categories, using the --include and/or --exclude command line options. When both options are specifies, all the tests with the included categories are run, except for those with the excluded categories.  The following info is copied from the NUnit doco (on which these options are based) :&lt;/p&gt;

    
        
            Expression
            Action
        
    
    
        
            A|B|C
            Selects tests having any of the categories A, B or C.
        
        
            A,B,C
            Selects tests having any of the categories A, B or C.
        
        
            A+B+C
            Selects only tests having all three of the categories assigned
        
        
            A+B|C
            Selects tests with both A and B OR with category C.
        
        
            A+B-C
            Selects tests with both A and B but not C.
        
        
            -A
            Selects tests not having category A assigned
        
        
            A+(B|C)
            Selects tests having both category A and either of B or C
        
        
            A+B,C
            Selects tests having both category A and either of B or C
        
    

&lt;p&gt;As shown by the last two examples, the comma operator is equivalent to | but has a higher precendence. Order of evaluation is as follows:&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;ol class="operators"&gt;
    &lt;li&gt;Unary exclusion operator (-)&lt;/li&gt;
    &lt;li&gt;High-precendence union operator (,)&lt;/li&gt;
    &lt;li&gt;Intersection and set subtraction operators (+ and binary -)&lt;/li&gt;
    &lt;li&gt;Low-precedence union operator (|)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;
Note :
Because the operator characters have special meaning, you should avoid creating a category that uses any of them in it's name. For example, the category "db-tests" could not be used on the command line, since it appears to means "run category db, except for category tests." The same limitation applies to characters that have special meaning for the shell you are using.
I have also fixed some other minor issues with the naming of repeated tests and test cases to allow them to work with the filter.
&lt;/p&gt;
&lt;h3&gt;Other options&lt;/h3&gt;
&lt;p&gt;Once you have added the command line check, run yourexe /? to see the other command line options available. None of the options are required so running the exe without any options will behave as it did before.&lt;/p&gt;
&lt;h3&gt;Delphi 2010&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Resolved&lt;/strong&gt;&amp;#160;- Thanks to Stefan Glienke for figuring this out - D2010 now support again . This fix was to remove any use of of STRONGLINKTYPES.&amp;#160;&lt;/p&gt;
&lt;p&gt;One thing of note: at the moment these changes break our D2010 support. I get a linker error when I build :&lt;/p&gt;
&lt;pre&gt;[DCC Fatal Error] F2084 Internal Error: L1737&lt;/pre&gt;
&lt;p&gt;Interestingly, the resulting executable is produced and does seem to run ok, however it makes debugging tests impossible, and of course it would fail in automated build. I did spend several hours trying to resolve this error but got nowhere. Since my usage of DUnitX is currently focused on XE2, I'm willing to live with this and just use an older version of DUnitX for D2010. I have tested with XE2, XE5 and XE6.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>Introducing VSoft.CommandLineParser for Delphi</title><link href="http://www.ciandcd.com/introducing-vsoftcommandlineparser-for-delphi.html" rel="alternate"></link><updated>2015-06-27T04:04:17+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:introducing-vsoftcommandlineparser-for-delphi.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/719/introducing-vsoftcommandline-for-delphi"&gt;https://www.finalbuilder.com/resources/blogs/postid/719/introducing-vsoftcommandline-for-delphi&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;Command line parsing&lt;/h2&gt;
&lt;p&gt;Pretty much every delphi console application I have ever written or worked on had command line options, and every one of the projects tried different ways for defining and parsing the supplied options.
Whilst working on DUnitX recently, I needed to add some command line options, and wanted to find a nice way to add them and make it easy to add more in the future. The result is &lt;a href="https://github.com/VSoftTechnologies/VSoft.CommandLineParser" target="_blank"&gt;VSoft.CommandLineParser&lt;/a&gt;
(copies of which are included with the latest DUnitX).&lt;/p&gt;
&lt;h3&gt;Defining Options&lt;/h3&gt;
&lt;p&gt;One of the things I really wanted, was to have the parsing totally decoupled from definition and the storage of the options values. Options are defined by registering them with the TOptionsRegistry, via
TOptionsRegistry.RegisterOption&amp;lt;T&amp;gt; - whilst it makes use of generics, only certain types can be used, the types are checked at runtime, as generic constraints are not flexible enough to specify
which types we allow at compile time. Valid types are string, integer, boolean, enums &amp;amp; sets and floating point numbers. &lt;/p&gt;
&lt;p&gt;Calling RegisterOption will return a definition object which implements IOptionDefinition. This definition object allows you to set various settings (such as Required).
When registering the option, you specify the long option name, the short option name, help text (will be used when showing the usage) and a TProc&amp;lt;T&amp;gt; anonymous method that will take the parsed value as a parameter.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;procedure ConfigureOptions;
var
  option : IOptionDefintion;
begin
  option := TOptionsRegistry.RegisterOption&amp;lt;string&amp;gt;('inputfile','i','The file to be processed',
    procedure(value : string)
    begin
        TSampleOptions.InputFile := value;
    end);
  option.Required := true;

  option := TOptionsRegistry.RegisterOption&amp;lt;string&amp;gt;('outputfile','o','The processed output file',
    procedure(value : string)
    begin
        TSampleOptions.OutputFile := value;
    end);
  option.Required := true;

  option := TOptionsRegistry.RegisterOption&amp;lt;boolean&amp;gt;('mangle','m','Mangle the file!',
    procedure(value : boolean)
    begin
        TSampleOptions.MangleFile := value;
    end);
  option.HasValue := False;

  option := TOptionsRegistry.RegisterOption&amp;lt;boolean&amp;gt;('options','','Options file',nil);
  option.IsOptionFile := true;
end;
&lt;/pre&gt;
&lt;p&gt;For options that are boolean in nature, ie they have do not value part, the value passed to the anonymous method will be true if the option was specified, otherwise the anonymous method will not be called. The 'mangle' option in the above example shows this scenario. &lt;/p&gt;
&lt;p&gt;You can also specify that an option is a File, by setting the IsOptionFile property on the option definition. This tells the parser the value will be a file, which contains other options to be parsed (in the same format as the command line). This is useful for working around windows command line length limitations.&lt;/p&gt;
&lt;p&gt;Currently the parser will accept&lt;br&gt;
-option:value&lt;br&gt;
--option:value&lt;br&gt;
/option:value
&lt;/p&gt;
&lt;p&gt;Note the : delimiter between the option and the value.&lt;/p&gt;
&lt;p&gt;Unnamed parameters are registered via the TOptionsRegistry.RegisterUnNamedOption&amp;lt;T&amp;gt; method. Unlike named options, unnamed options are positional, but only when more than one is registered, as they will
be passed to the anonymous methods in the order they are registered.&lt;/p&gt;
&lt;h3&gt;Parsing the options.&lt;/h3&gt;
&lt;p&gt;Parsing the options is as simple as calling TOptionsRegistry.Parse, which returns a ICommandLineParseResult object. Check the HasErrors property to see if the options were valid, the ErrorText property has the parser error messages.&lt;/p&gt;
&lt;h3&gt;Printing Usage&lt;/h3&gt;
&lt;p&gt;If the parser reports errors, then typically you would show the user what the valid options are and exit the application, e.g:&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;    parseresult := TOptionsRegistry.Parse;
    if parseresult.HasErrors then
    begin
      Writeln(parseresult.ErrorText);
      Writeln('Usage :');
      TOptionsRegistry.PrintUsage(
        procedure(value : string)
        begin
          Writeln(value);
        end);
    end
    else
        ..start normal execution here
&lt;/pre&gt;
&lt;p&gt;The TOptionsRegistry.PrintUsage makes it easy to print the usage to the command line.&lt;/p&gt;
&lt;p&gt;When I started working on this library, I found some really complex libraries (mostly .net) out there with a lot of options, but I decided to keep mine as simple as possible and only cover off the scenarios I need right now. So it's entirely possible this doesn't do everything people might need, but it's pretty easy to extend. The &lt;a href="https://github.com/VSoftTechnologies/VSoft.CommandLineParser" target="_blank"&gt;VSoft.CommandLineParser&lt;/a&gt; library (just three units) is open source and available on Github, with a sample application and unit tests (DUnitX) included.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>Continua 1.5 released</title><link href="http://www.ciandcd.com/continua-15-released.html" rel="alternate"></link><updated>2015-06-27T04:04:14+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:continua-15-released.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/721/continua-15-released"&gt;https://www.finalbuilder.com/resources/blogs/postid/721/continua-15-released&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;Continua Version 1.5 is now &lt;a target="_blank" href="https://www.finalbuilder.com/downloads/continuaci"&gt;available for download&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Today marks a milestone in Continua CI as we release version 1.5 of the product.  Its been many months in the making, we hope you enjoy the update as much as we enjoyed making it.&lt;/p&gt;
&lt;p&gt;There are many features that we think you'll benefit from by updating to v1.5, some of these include: &lt;/p&gt;
&lt;h3&gt;Reworked UI:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Now using bootstrap framework for styling&lt;/li&gt;
    &lt;li&gt;Redesigned &lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/dashboards"&gt;dashboards&lt;/a&gt; that show more information including graphs.&lt;/li&gt;
    &lt;li&gt;Added stages information to the Project tile and list views&lt;/li&gt;
    &lt;li&gt;Disabled configurations are now displayed as faded&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;Cloning:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Can now clone whole projects and clone configurations between projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;Stage Conditions:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Auto Promote conditions - stages can now use conditions to control whether to auto-promote to the next stage.&lt;/li&gt;
    &lt;li&gt;Skip conditions - you can now provide conditions for skipping stages or disable a stage completely.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;New Actions:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Update GitHub Status Action is now deprecated (use event handler instead - see below).&lt;/li&gt;
    &lt;li&gt;&lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/NuGet+Restore+Action"&gt;NuGet restore action&lt;/a&gt;.&lt;/li&gt;
    &lt;li&gt;&lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/Fake+Action"&gt;Fake (F#) build runner.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;Repository Tags: (Git, Mercurial and Subversion repositories only)&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Continua CI can now detect and list repository tags.&lt;/li&gt;
    &lt;li&gt;Tags are now displayed in changeset tabs on configuration and build views.&lt;/li&gt;
    &lt;li&gt;Repository trigger can now be set to trigger on tag changes (new tags, edits and deletions) changes).&lt;/li&gt;
    &lt;li&gt;You can now run a build on a &lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/Builds#Builds-RepositoryBranch/Tag"&gt;tagged changeset&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
 
&lt;ul&gt;
    &lt;li&gt; Octopus Deploy: Create/Deploy/Promote Octopus Deploy releases. &lt;/li&gt;
    &lt;li&gt; Tag Repository Changesets: Apply tags to a repository changeset (Git, Mercurial and Subversion repositories only) &lt;/li&gt;
    &lt;li&gt; &lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/Update+GitHub+Status"&gt;Update GitHub Status: replaces the Update GitHub Status action&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;and many more changes including:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt; Styling changes for improved handling on small screen sizes&lt;/li&gt;
    &lt;li&gt; Report ordering: you can choose which one is displayed first on the build view.&lt;/li&gt;
    &lt;li&gt; New expression functions: Utils.NewGuid() and Utils.RandomNumber() can be used for generation of temporary paths for example&lt;/li&gt;
    &lt;li&gt; Additional LatestChangeset object within the repository object with Branch, BranchName, Comment, CommitterUserName, CommitterFullName, Created, FileCount, Id and RepositoryUsername properties to use in expressions&lt;/li&gt;
    &lt;li&gt; Continua now supports DUnitX enhanced Command Line Options&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Updating&lt;/h2&gt;
&lt;p&gt;Updating to this new release is the same regardless if you are using v1.0.X or a recent build from the beta or release candidate.  Simply download the installer and run it, the setup will guide you through the install process.  As usual we are available on &lt;a href="mailto:support@finalbuilder.com"&gt;support@finalbuilder.com&lt;/a&gt; if you run into any troubles.&lt;/p&gt;
&lt;p&gt;For this release you will need to update both the server and agents.&lt;/p&gt;
&lt;h2&gt;A word of thanks&lt;/h2&gt;
&lt;p&gt;The team wishes to thank everyone who has participated in the beta and release candidate stages for this release.  Your positive feedback has been invaluable in shaping the features and functionality of the product.  Thank you for your continued support.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</summary></entry><entry><title>How to Fix your system path after installing Delphi</title><link href="http://www.ciandcd.com/how-to-fix-your-system-path-after-installing-delphi.html" rel="alternate"></link><updated>2015-06-27T04:04:12+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:how-to-fix-your-system-path-after-installing-delphi.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/722/how-to-fix-your-system-path-after-installing-delphi"&gt;https://www.finalbuilder.com/resources/blogs/postid/722/how-to-fix-your-system-path-after-installing-delphi&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;&lt;strong&gt;&lt;p&gt;Update : Still the same situation with XE8.&amp;#160;&lt;/p&gt;&lt;/strong&gt;&lt;br&gt;
&lt;br&gt;
The Windows Path environment variable has a limit of &lt;p&gt;1023&lt;/p&gt;&amp;#160;*&amp;#160;&lt;p&gt;&lt;strong&gt;2,048&lt;/strong&gt;&amp;#160;&lt;/p&gt;characters, a stupidly short limit in this day and age, and when this limit is exceeded the path is truncated. Why this limit still exists on windows I have no idea.. for that matter why it ever existed... anyway, we're stuck with it (along with it's best buddy, MAX_PATH).&amp;#160;&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
Each version of Delphi adds over 200 characters to your system path. Worst still, they add those 200+ characters to the front of the path, not the end. What happens, is that eventually, important entries get truncated off end of the path, and &lt;strong&gt;strange things happen&lt;/strong&gt;. You will find programs will not run, the task bar displays the wrong icons for programs, even getting to the control panel can be problematic.&amp;#160;&lt;br&gt;
&lt;br&gt;
If you look at the entries that XE7 added to the start of your path you will see something like this :&lt;br&gt;
&lt;br&gt;
C:\Program Files (x86)\Embarcadero\Studio\15.0\bin;&lt;br&gt;
&lt;p&gt;C:\Program Files (x86)\Embarcadero\Studio\15.0\bin64;&lt;br&gt;
&lt;/p&gt;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl;&lt;br&gt;
C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl\Win64;&lt;br&gt;
&lt;br&gt;
Fortunately this can be shortened by the use of junction points. Sadly, this will polute your C: drive with new folders but it's better than the alternative.&lt;br&gt;
&lt;br&gt;
The trick is to create links for the most common paths, so on mine I created these&lt;br&gt;
For XE5 and earlier :&lt;br&gt;
mklink /j RS C:\Program Files (x86)\Embarcadero\RAD Studio&lt;br&gt;
mklink /j rspub&amp;#160;C:\Users\Public\Documents\RAD Studio&lt;br&gt;
&lt;br&gt;
XE6 and above&amp;#160;&lt;br&gt;
&lt;br&gt;
mklink /j Studio&amp;#160;C:\Program Files (x86)\Embarcadero\Studio&lt;br&gt;
&lt;p&gt;mklink /j spub&amp;#160;&lt;/p&gt;&lt;p&gt;C:\Users\Public\Documents\Embarcadero\Studio&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
Once you have those junction points, you can then edit your path and replace the long paths, for example (for XE7) :&lt;br&gt;
&lt;br&gt;
&lt;p&gt;C:\Program Files (x86)\Embarcadero\Studio\15.0\bin -&amp;gt;&amp;#160;&lt;/p&gt;&lt;p&gt;C:\Studio\15.0\bin&lt;br&gt;
&lt;/p&gt;&lt;p&gt;C:\Program Files (x86)\Embarcadero\Studio\15.0\bin64 -&amp;gt;&amp;#160;C:\Studio\15.0\bin64&lt;/p&gt;&lt;br&gt;
&lt;p&gt;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl&amp;#160;-&amp;gt;&amp;#160;C:\spub\15.0\Bpl&lt;/p&gt;&lt;br&gt;
&lt;p&gt;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl\Win64 - &amp;gt; c:\spub\15.0\Bpl\Win64&lt;br&gt;
&lt;/p&gt;&lt;br&gt;
So for XE7, that cuts it down from 218 to 80 characters, if like me you also have multiple versions of Rad Studio installed, this can be a big saving.&lt;br&gt;
&lt;br&gt;
As for Rad Studio, it's extremely rude to add things to the start of the path, the truncation it causes can ruin a machine.. I wasted several hours again today after installing XE7. Embarcadero were told about this issue many times over several releases.. according to the &lt;a&gt;&lt;/a&gt;&lt;strong&gt;PLEASE ADD IT TO THE END!!&lt;/strong&gt; and save us all a bunch of time.&amp;#160;&lt;br&gt;
&lt;br&gt;
*&amp;#160;Correction, max path length is 2048 - very difficult to find a difinitive source of this information on the microsoft site - the max size of an env variable is 2048, however I have seen the path variable truncated at 1024 many times.&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;Each version of Delphi adds over 200 characters to your system path. Worst still, they add those 200+ characters to the front of the path, not the end. What happens, is that eventually, important entries get truncated off end of the path, and. You will find programs will not run, the task bar displays the wrong icons for programs, even getting to the control panel can be problematic.If you look at the entries that XE7 added to the start of your path you will see something like this :C:\Program Files (x86)\Embarcadero\Studio\15.0\bin;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl\Win64;Fortunately this can be shortened by the use of junction points. Sadly, this will polute your C: drive with new folders but it's better than the alternative.The trick is to create links for the most common paths, so on mine I created theseFor XE5 and earlier :mklink /j RS C:\Program Files (x86)\Embarcadero\RAD Studiomklink /j rspub C:\Users\Public\Documents\RAD StudioXE6 and abovemklink /j Studio C:\Program Files (x86)\Embarcadero\StudioOnce you have those junction points, you can then edit your path and replace the long paths, for example (for XE7) :So for XE7, that cuts it down from 218 to 80 characters, if like me you also have multiple versions of Rad Studio installed, this can be a big saving.As for Rad Studio, it's extremely rude to add things to the start of the path, the truncation it causes can ruin a machine.. I wasted several hours again today after installing XE7. Embarcadero were told about this issue many times over several releases.. according to the &lt;a href="http://docwiki.embarcadero.com/RADStudio/XE7/en/Installation_Path_Length_Problem"&gt;doco&lt;/a&gt; , XE7 will popup a message about this.. I didn't see it so not sure when that is supposed to appear, but in any event, if your installer or progam needs to add something to the path environment variable,and save us all a bunch of time.Correction, max path length is 2048 - very difficult to find a difinitive source of this information on the microsoft site - the max size of an env variable is 2048, however I have seen the path variable truncated at 1024 many times.&lt;/p&gt;&lt;/div&gt;</summary></entry><entry><title>FinalBuilder 8 Beta</title><link href="http://www.ciandcd.com/finalbuilder-8-beta.html" rel="alternate"></link><updated>2015-06-27T04:04:08+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:finalbuilder-8-beta.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/729/finalbuilder-8-beta"&gt;https://www.finalbuilder.com/resources/blogs/postid/729/finalbuilder-8-beta&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;h2&gt;What's new in FinalBuilder 8&lt;/h2&gt;
&lt;h3&gt;IDE Themes&lt;/h3&gt;
&lt;p&gt;It's almost 5 years since FinalBuilder 7 was released. Since it's release we have shipped &lt;a href="https://www.finalbuilder.com/downloads/finalBuilder/finalbuilder-7-version-history"&gt;44 official updates&lt;/a&gt; , nearly every update including new features or improvements. This program of continuous improvement has worked well, with customers not having to wait for major new versions to arrive to get support for new versions of Visual Studio or Delphi etc, but it has limited our ability to make major changes. So it's time for a new major version of FinalBuilder.&lt;/p&gt;&lt;p&gt;The IDE has two new themes, Dark and Light (yes, imaginatively named!). The IDE defaults to Dark on first run, however you can change the theme in the options quite easily. The themes are still a work in progress, we are waiting on an update from a third party control vendor to resolve some issues. &lt;/p&gt;

    
        
            
            &lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-ide-light-small.png"&gt;
            
            
            &lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-ide-dark-small.png"&gt;
            
        
    

&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;h3&gt;Debugger&lt;/h3&gt;
&lt;p&gt;One of the most asked for features now available in FinalBuilder 8, &lt;strong&gt;stepping into included projects&lt;/strong&gt;. In FinalBuilder 7 and earlier, you could only step over included projects, and wait for them to return. In FinalBuilder 8, you can step into the included project, if it is not already opened the IDE will open the project and switch to it automatically. To make this possible, there are now "Step Into" and "Step Over" functions. The Step into/over now also applies to targets (see below).&lt;br&gt;
&lt;br&gt;
Debugger breakpoints now have conditions :
&lt;/p&gt;
&lt;p&gt;
&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-breakpoint-props.png"&gt;
&lt;/p&gt;
&lt;h3&gt;Actionlists renamed to Targets&lt;/h3&gt;
&lt;p&gt;ActionLists have been renamed to Targets. Targets can now also define dependencies, so you can for example define Clean, Build, Test, and have Test depend on Build. If you execute the Test target, and Build has not already been executed, it will be executed first before Test. Targets can be specified on the command line.&lt;/p&gt;
&lt;p&gt;&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-target-depend.png"&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;In FinalBuilder 7 and earlier, projects had a Main and an OnFailure (global error handler) actionlist. In FinalBuilder 8, projects just have a Default Target. Older projects will be imported such that the Main and OnFailure Targets are called from the Default Target inside a try/catch block.&lt;/p&gt;
&lt;h3&gt;Run Target Action&lt;/h3&gt;
&lt;p&gt;You can now return values from Targets (ie out parameters) .&lt;/p&gt;
&lt;p&gt;&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-target-outparams.png"&gt;&lt;/p&gt;
&lt;h3&gt;New Help System&lt;/h3&gt;
&lt;p&gt;The help has moved online in the form of a wiki. This enables us to do inline help updates without needing to ship new builds. The new help is still being worked on, lots of screenshots are missing etc..&amp;#160;&lt;/p&gt;
&lt;h2&gt;Non Visible Changes&lt;/h2&gt;
&lt;h3&gt;Stepping Engine&lt;/h3&gt;
&lt;p&gt;The stepping engine was rewritten to enable stepping into included projects, and to enable target dependencies. This, work, together with the new variables architecture is where the bulk of effort/time was spent in the FinalBuilder 8 development cycle.&lt;/p&gt;
&lt;h3&gt;Variables Architecture&lt;/h3&gt;
&lt;p&gt;The variables architecture and the expression evaluator were rewritten to resolve several corner case issues that we were not able to resolve in FinalBuilder 7. The expression evaulator has a new parser that will allow us to more easily extend the syntax in the future. The User variable namespace was removed, it caused too many problems with projects not running under other users, not running on the build server etc. Use Project variables instead. &lt;/p&gt;
&lt;h3&gt;Core Messaging&lt;/h3&gt;
&lt;p&gt;Changes to the messaging has allowed us to improve the performance of the stepping engine and logging, with much less thread switching. This also improved the IDE performance.&lt;/p&gt;
&lt;h3&gt;CLR Hosting&lt;/h3&gt;
&lt;p&gt;The minimum CLR version is now .NET 4.0 (ie FinalBuilder requires .net 4.0 to be installed).&lt;/p&gt;
&lt;h3&gt;Code Changes&lt;/h3&gt;
&lt;p&gt;In addition to the architectural changes, we also spent a lot of time refactoring the code, running static analysis tools over the source, looking for memory leaks, potential bugs etc. One of the results of this is reduced memory usage during a build compared to FB7. The FB8 IDE does use slightly more memory than the FB7 IDE at startup (mostly due to the heavy use of delphi generics), however the runtime memory usage is much lower.A large &amp;#160;part of the refactoring involved unit testing (we created a new&amp;#160;&lt;a href="https://github.com/VSoftTechnologies/DUnitX" target="_blank"&gt;unit test framework&lt;/a&gt; to suite our needs!) and creating a suite of integration tests.&amp;#160;&lt;/p&gt;
&lt;h3&gt;FBCmd&lt;/h3&gt;
&lt;p&gt;The command line parameters have changed to be more consistent and easier to specify. You can also specify one or more targets to execute (when not specified, the default target is executed).
&lt;/p&gt;
&lt;h3&gt;New Project File Formats&lt;/h3&gt;
&lt;p&gt;FinalBuilder has used an xml file format since version 1, however a common complaint over the years, has been that it is difficult to diff file versions. FinalBuilder 8 has tackled this in two ways.&lt;/p&gt;
&lt;p&gt;A new DSL style project file format (.fbp8) is now the default format, it is very easy to diff.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;project
begin
    projectid = {04710B72-066E-46E7-84C7-C04A0D8BFE18}
    target
    begin
        name = Default
        targetid = {E6DE94D6-5484-45E9-965A-DB69885AA5E2}
        rootaction
        begin
            action.group
            begin
                id = {D860420B-DE46-4806-959F-8A92A0C86429}
            end
        end
    end
end
&lt;/pre&gt;
&lt;p&gt;A new xml format (.fbx8), much less verbose than the old format. &lt;/p&gt;
&lt;pre class="brush:xml; toolbar:true;"&gt;&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt;
&amp;lt;finalbuilder&amp;gt;
    &amp;lt;project&amp;gt;
        &amp;lt;projectid&amp;gt;{6A717C24-D00F-4983-9FD0-148B2C609634}&amp;lt;/projectid&amp;gt;
        &amp;lt;target&amp;gt;
            &amp;lt;name&amp;gt;Default&amp;lt;/name&amp;gt;
            &amp;lt;targetid&amp;gt;{E6DE94D6-5484-45E9-965A-DB69885AA5E2}&amp;lt;/targetid&amp;gt;
            &amp;lt;rootaction&amp;gt;
                &amp;lt;action.group&amp;gt;
                    &amp;lt;id&amp;gt;{D860420B-DE46-4806-959F-8A92A0C86429}&amp;lt;/id&amp;gt;
                &amp;lt;/action.group&amp;gt;
            &amp;lt;/rootaction&amp;gt;
        &amp;lt;/target&amp;gt;
    &amp;lt;/project&amp;gt;
&amp;lt;/finalbuilder&amp;gt;
&lt;/pre&gt;
&lt;p&gt;Compressed project files (.fbz8) use the dsl format internally (compressed projects are just a zip file with a project.fbp8 inside it).&lt;/p&gt;
&lt;p&gt;The default project file encoding is now UTF-8, which is more version control friendly (some version control systems treat utf-16 as binaries).&lt;/p&gt;
&lt;h3&gt;New Actions&lt;/h3&gt;
&lt;p&gt;There are no new actions at the moment, although several are in development, they will be added to the beta builds as they are completed.&amp;#160;&lt;/p&gt;
&lt;h3&gt;How do I get the Beta?&lt;/h3&gt;
Links to the beta downloads will be published to the &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;What if I find a bug?&lt;/h3&gt;
We have created a &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
We are particularly keen for people to load up their existing projects from older (ie 7 or earlier) versions of FinalBuilder, save them in FB8 format, and load them again and confirm that everything loaded ok.&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;When will it be released?&lt;/h3&gt;
&lt;h3&gt;
&lt;/h3&gt;
When it's ready ;)&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                         &amp;#13;
                    &lt;p&gt;Links to the beta downloads will be published to the &lt;a href="https://www.finalbuilder.com/downloads/finalbuilder"&gt;FinalBuilder Downloads&lt;/a&gt; page.We have created a &lt;a href="https://www.finalbuilder.com/support/forums/aff/66"&gt;Beta forum&lt;/a&gt; on our forums, or you can email support (please added Beta to the subject). When reporting an issue, be sure to include the beta build number and details about your environment. Please test with the latest beta build before reporting bugs.We are particularly keen for people to load up their existing projects from older (ie 7 or earlier) versions of FinalBuilder, save them in FB8 format, and load them again and confirm that everything loaded ok.When it's ready ;)&lt;/p&gt;&lt;/div&gt;</summary></entry><entry><title>Adding NTLM SSO to Nancyfx</title><link href="http://www.ciandcd.com/adding-ntlm-sso-to-nancyfx.html" rel="alternate"></link><updated>2015-06-27T04:03:58+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:adding-ntlm-sso-to-nancyfx.html</id><summary type="html">From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/730/adding-ntlm-sso-to-nancyfx"&gt;https://www.finalbuilder.com/resources/blogs/postid/730/adding-ntlm-sso-to-nancyfx&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;span&gt;&lt;a&gt;&lt;/a&gt;&lt;span&gt;&lt;a href="https://github.com/NancyFx/Nancy" target="_blank" title="Nancyfx on Github."&gt;Nancyfx&lt;/a&gt; is a Lightweight, low-ceremony, framework for building HTTP based services on .Net and Mono. It's open source and available on github.&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Nancy supports Forms Authentication, Basic Authentication and Stateless Authentication "out of the box", and it's simple to configure. In my application, I wanted to be able to handle mixed Forms and NTLM Authentication, which is something nancyfx &amp;#160;doesn't support. We have done this before with asp.net on IIS, and it was not a simple task, involving a child site with windows authentication enabled while the main site had forms (IIS doesn't allow both at the same time) and all sorts of redirection. It was painful to develop, and it's painful to install and maintain.&amp;#160;&lt;br&gt;
&lt;br&gt;
Fortunately with Nancy and &lt;a href="http://owin.org/" target="_blank" title="Owin Website"&gt;Owin&lt;/a&gt;, it's a lot simpler. Using Microsoft's implementation of the Owin spec, and Nancy's Owin support, it's actually quite easy, without the need for child websites and redirection etc.&amp;#160;&lt;/p&gt;
&lt;p&gt;I'm not going to explain how to use Nancy or Owin here, just the part needed to hook up NTLM support. In my application, NTLM authentication is invoked by a button on the login page ("Login using my windows account") which causes a specific login url to be hit. We're using Owin for hosting rather than IIS and Owin enables us to get access to the HttpListener, so we can control the authentication scheme for each url. We do this by adding an AuthenticationSchemeSelectorDelegate.&lt;/p&gt;
&lt;pre class="brush:c#; toolbar:true;"&gt;internal class Startup
{
    public void Configuration(IAppBuilder app)
    {
        var listener = (HttpListener)app.Properties["System.Net.HttpListener"];
       //add a delegate to select the auth scheme based on the url 
        listener.AuthenticationSchemeSelectorDelegate = request =&amp;gt;
        {
            //the caller requests we try windows auth by hitting a specific url
            return request.RawUrl.Contains("loginwindows") ? AuthenticationSchemes.IntegratedWindowsAuthentication : AuthenticationSchemes.Anonymous;
        }
        app.UseNancy();
    }
}
&lt;/pre&gt;
&lt;br&gt;
What this achieves is to invoke the NTLM negotiation if the "loginwindows" url is hit on our nancy application. If the negotiation is successful (ie the browser supports NTLM and is able to identify the user), &amp;#160;then the Owin environment will have the details of the user, and this is how we get those details out of Owin (in our bootstrapper class).&lt;br&gt;
&lt;br&gt;
&lt;pre class="brush:c#; toolbar:true;"&gt;protected override void ApplicationStartup(TinyIoCContainer container, IPipelines pipelines)
{
  pipelines.BeforeRequest.AddItemToStartOfPipeline((ctx) =&amp;gt;
  {
      if (ctx.Request.Path.Contains("loginwindows"))
      {
          var env = ((IDictionary&amp;lt;string,&amp;gt;)ctx.Items[Nancy.Owin.NancyOwinHost.RequestEnvironmentKey]);
          var user = (IPrincipal)env["server.User"];
          if (user != null &amp;amp;&amp;amp; user.Identity.IsAuthenticated)
          {
              //remove the cookie if someone tried sending one in a request!
              if (ctx.Request.Cookies.ContainsKey("IntegratedWindowsAuthentication"))
                  ctx.Request.Cookies.Remove("IntegratedWindowsAuthentication");
              //Add the user as a cooking on the request object, so that Nancy can see it.
              ctx.Request.Cookies.Add("IntegratedWindowsAuthentication", user.Identity.Name);
          }
      }
      return null;//ensures normal processing continues. 
  });
}&lt;/pre&gt;
&lt;br&gt;
Note we are adding the user in a cookie on the nancy Request object, which might seem a strange thing to do, but it was the only way I could find to add something to the request that can be accessed inside a nancy module, because everything else on the request object is read only. We don't send this cookie back to the user. So with that done, all that remains is the use that user in our login module&lt;br&gt;
&lt;br&gt;
&lt;pre class="brush:c#; toolbar:true;"&gt; Post["/loginwindows"] = parameters =&amp;gt; 
    {
        string domainUser = "";
        if (this.Request.Cookies.TryGetValue("IntegratedWindowsAuthentication",out domainUser))
        {
            //Now we can check if the user is allowed access to the application and if so, add 
            //our forms auth cookie to the response.             
            ...
        }
    }
&lt;/pre&gt;
&lt;br&gt;
Of course, this will probably only work on Windows, not sure what the current status is for System.Net.HttpListener is on Mono. This code was tested with Nancyfx 1.2 from nuget.&amp;#160;&lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                         &amp;#13;
                    &lt;p&gt;What this achieves is to invoke the NTLM negotiation if the "loginwindows" url is hit on our nancy application. If the negotiation is successful (ie the browser supports NTLM and is able to identify the user), then the Owin environment will have the details of the user, and this is how we get those details out of Owin (in our bootstrapper class).Note we are adding the user in a cookie on the nancy Request object, which might seem a strange thing to do, but it was the only way I could find to add something to the request that can be accessed inside a nancy module, because everything else on the request object is read only. We don't send this cookie back to the user. So with that done, all that remains is the use that user in our login moduleOf course, this will probably only work on Windows, not sure what the current status is for System.Net.HttpListener is on Mono. This code was tested with Nancyfx 1.2 from nuget.&lt;/p&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog IBM Rational Publishing Engine 2.0 M5 Beta – Improved document styling</title><link href="http://www.ciandcd.com/jazz-team-blog-ibm-rational-publishing-engine-20-m5-beta-improved-document-styling.html" rel="alternate"></link><updated>2015-06-27T04:03:52+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-ibm-rational-publishing-engine-20-m5-beta-improved-document-styling.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/03/25/ibm-rational-publishing-engine-2-0-m5-beta-improved-document-styling/"&gt;https://jazz.net/blog/index.php/2015/03/25/ibm-rational-publishing-engine-2-0-m5-beta-improved-document-styling/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;We&amp;#8217;re glad to announce that the Rational Publishing Engine (RPE) 2.0 Beta on Bluemix has been &lt;a href="https://rpe.mybluemix.net/rpeng" target="_blank"&gt;updated to the M5 build&lt;/a&gt;!&amp;#160;There is no registration or special process required in order to access the beta. Aside from announcing this update, the intention of this post is to provide a little extra help to those looking for guidance on getting started using using the RPE 2.0 M5 Beta via some helpful resources. We&amp;#8217;ll also touch on what&amp;#8217;s new in this build of the beta.&lt;/p&gt;
&lt;h2&gt;Goal of the beta&lt;/h2&gt;
&lt;p&gt;This is meant to give RPE users an opportunity to provide feedback on the  features and usability of our new web interface. The focus is on the  report designer and end user scenarios.&lt;/p&gt;
&lt;p&gt;What we&amp;#8217;d like to learn is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Is the design simple enough for our end users?&lt;/li&gt;
&lt;li&gt;Do you see all the capabilities that your report designers need?&lt;/li&gt;
&lt;li&gt;Is the overall interface intuitive enough?&lt;/li&gt;
&lt;li&gt;What is missing from this new component of RPE to make it attractive for your organization?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We welcome all your feedback, so please send your thoughts to &lt;a href="mailto:rpe20_beta_support@wwpdl.vnet.ibm.com"&gt;rpe20_beta_support@wwpdl.vnet.ibm.com&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;p&gt;Help Guide:&amp;#160;&lt;a href="https://jazz.net/blog/wp-content/uploads/2015/03/IBM-Rational-Publishing-Engine-2-M5-Help.pdf"&gt;IBM Rational Publishing Engine 2 M5 Help&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Video Tutorials:&lt;/p&gt;
 
&lt;h2&gt;What&amp;#8217;s new in this build&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Due to the new features implemented in M5, we had to recreate the database which means that assets and documents created using the previous build have been lost.&lt;/p&gt;
&lt;h2&gt;(i) &amp;#160;&amp;#160; Notifications&lt;/h2&gt;
&lt;p&gt;The notifications widget at the top of the screen is now active and will show all new events that occurred since you last checked its contents. The only event supported for now is the completion (successful or not) of a document generation.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://jazz.net/blog/wp-content/uploads/2015/03/Notifications.png"&gt;&lt;img class="alignnone size-full wp-image-12936" title="Notifications" src="https://jazz.net/blog/wp-content/uploads/2015/03/Notifications.png" alt="" width="460" height="68"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;(ii) &amp;#160;&amp;#160; Stylesheet support&lt;/h2&gt;
&lt;p&gt;You can now upload stylesheets and use them in your reports.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://jazz.net/blog/wp-content/uploads/2015/03/Styleseheet.png"&gt;&lt;img class="alignnone size-full wp-image-12937" title="Styleseheet" src="https://jazz.net/blog/wp-content/uploads/2015/03/Styleseheet.png" alt="" width="440" height="273"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;(iii)&amp;#160;&amp;#160; Advanced Configuration Mode for reports&lt;/h2&gt;
&lt;p&gt;Report designers now have access to an advanced edit mode where the report configuration can be tailored in detail. It is now possible to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set the default connection      for the report data sources&lt;/li&gt;
&lt;li&gt;Set the default values for      the report variables&lt;/li&gt;
&lt;li&gt;Rename variables and data      sources to be more meaningful to the end user&lt;/li&gt;
&lt;li&gt;Hide variables and data      sources from the end user&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://jazz.net/blog/wp-content/uploads/2015/03/Configuration.png"&gt;&lt;img class="alignnone size-full wp-image-12938" title="Configuration" src="https://jazz.net/blog/wp-content/uploads/2015/03/Configuration.png" alt="" width="697" height="631"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the image above, the report designer modifies the &amp;#8220;News Glimpse&amp;#8221; report by setting its data source connection to the BBC News Feed and at the same time hiding the data source. This will effectively set the report to this configuration and end users can run it without further configuration.&lt;/p&gt;
&lt;h2&gt;(iv) &amp;#160;&amp;#160; Other changes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The action list has been      pruned with many of the redundant actions removed or redistributed.&lt;/li&gt;
&lt;li&gt;The default action in the Design      page has been changed to &amp;#8220;Edit&amp;#8221;.&lt;/li&gt;
&lt;li&gt;The user can view all      documents generated for a report from the Generate page by clicking &amp;#8220;View      Generated documents&amp;#8221; in the Actions menu.&lt;/li&gt;
&lt;li&gt;Users can create examples      multiple times.&amp;#160; The assets created      in each run of &amp;#8220;Create Examples&amp;#8221; are independent of one another.&lt;/li&gt;
&lt;li&gt;Internet Explorer 10 and      11 are now supported.&lt;/li&gt;
&lt;li&gt;Error messages should be      more informative now.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Bug Fixes&lt;/h2&gt;
&lt;p&gt;The following limitations of the previous build have been addressed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Generate page, if      you select the Generate Later action, the scheduled run of the report is      created but you cannot download the documents or the logs&lt;/li&gt;
&lt;li&gt;If there is an error while      scheduling a report using the Generate Later action, check if the date is      in the past.&lt;/li&gt;
&lt;li&gt;IE is supported&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Known Issues&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;If after signing on you      are redirected to an empty page by the IBM Single Sign-On you need to      issue the original request in the browser, https://rpe.mybluemix.net/rpeng&lt;/li&gt;
&lt;/ol&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog Using dashboards for status reviews: An interview with CLM Product Delivery Lead Brian Lang</title><link href="http://www.ciandcd.com/jazz-team-blog-using-dashboards-for-status-reviews-an-interview-with-clm-product-delivery-lead-brian-lang.html" rel="alternate"></link><updated>2015-06-27T04:00:36+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-using-dashboards-for-status-reviews-an-interview-with-clm-product-delivery-lead-brian-lang.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/05/12/using-dashboards-for-status-reviews-an-interview-with-clm-product-delivery-lead-brian-lang/"&gt;https://jazz.net/blog/index.php/2015/05/12/using-dashboards-for-status-reviews-an-interview-with-clm-product-delivery-lead-brian-lang/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Having experience with different types of reporting and status updates, Brian Lang, the Collaborative Lifecycle Management (CLM) Product Delivery Leader, spent some time discussing with me some of the key productivity gains he&amp;#8217;s noticed in using Rational Team Concert (RTC).&amp;#160; The focus here is on the benefits of having a collaborative and transparent workflow, especially when it comes to meeting preparations.&amp;#160; Brian shares with us the benefits of using RTC Dashboards so that the data is available, current, and updated as part of the natural development workflow.&lt;/p&gt;
&lt;p&gt;Brian, what types of meetings have you needed to pull together presentations in the past and today?&lt;/p&gt;
&lt;p&gt;In the past, when I was using a chart-based status process, leading up to the Senior VP&amp;#8217;s Monthly Operations Review (MOR), there would be a review with my VP where we would review the status of everything in my portfolio.&amp;#160; This included key dates of delivery, status (red, yellow, green), and any additional key points that we wanted to raise to an executive level.&amp;#160; These topics might typically included key capabilities, beta feedback, or what kinds of achievements or accomplishments the team had this month. &amp;#160;Also, we prepared risks&amp;#160;and mitigations. &amp;#160;Each product would have their own chart.&lt;/p&gt;
&lt;p&gt;Additionally, we covered other things like burn down charts, user stories, velocity, story points, and month&amp;#160;to month trends.&amp;#160; We also covered various forms of technical debt in the form of APARs, defect backlogs which rounded out the reviews.&lt;/p&gt;
&lt;p&gt;Now, in CLM, while we still have MORs, the process is different even though the types of data are the same.&amp;#160; Rather than create a separate set of material, the materials are baked into our workflow with regular reviews with teams.&amp;#160; The same sorts of materials that would have been prepared and reviewed are part of the workflow including scrum meetings, release team meetings, and daily communications and work activities.&amp;#160; The schedule is laid out and published for the whole team.&amp;#160; Risks and mitigations are captured and updated in plan items.&amp;#160; If a plan item&amp;#8217;s risk changes from green to yellow or red, the viewlet in the dashboard will pull in that plan item, with the latest updates about actions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What kinds of preparation do you do for these meetings?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When pulling together charts, we would work our way backwards from the review with the Senior VP.&amp;#160; We ended up with four separate meetings to review material specific to the status update.&amp;#160; With the CLM dashboards, we can be ready for an update at any time.&amp;#160; It&amp;#8217;s transparent and anyone in the team can check on the overall status because transparency is built into the product and supports our process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How long did it take to create the dashboards?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Viewlets are part of the RTC capabilities and some are out of the box. For example, risk and issues are available out of the box. &amp;#160;It doesn&amp;#8217;t take long to set up the queries against project areas. Depending on how many and the complexity, it typically takes less than an hour to get them put up.&amp;#160; Once they&amp;#8217;re there, they are automatically updated, so you don&amp;#8217;t have to repeat creating them.&amp;#160; One example is that we have a tab on our dashboard for risks and issues.&amp;#160; When we are tracking multiple releases, like we did with 5.0.2 and 6.0, we can separate them out, while keeping them on the same tab.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Going back to collecting the data for the charts, how many people are typically involved in gathering and consolidating that information?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, the offering team pulls together the information.&amp;#160; They usually have a release engineer, a project management, a development lead or chief programmer, an architect, a test lead, and a support lead, six people typically.&amp;#160; Sometimes there is the first line manager too so about six to seven people gathering and generating content to be reviewed. &amp;#160;The managers were the ones who presented the data to me, they are responsible for the content being presented.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How many teams did you have for a typical monthly status review?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When I was doing chart-based reporting, I had about three key teams.&amp;#160; This meant that 18-21 people were preparing for the meeting with me.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How long does it take to pull that information together&amp;#160;for each&amp;#160;team?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It takes a couple of hours for each person, approximately two to three hours to verify and answer are we green, yellow, or red?; how many test cases did we run?; what kinds of things are blocking us, etc. &amp;#160;That was spent running reports and following up with people for verification.&amp;#160; If things are not looking good, we may need more activity, up to maybe four hours.&amp;#160; That&amp;#8217;s about 24 hours per team.&amp;#160; Add on a 60-90 minute review in the offering team meeting making up another nine hours of people time (33 hours), plus another three hours for turnaround time on any follow ups. &amp;#160;We&amp;#8217;re looking at maybe 36 &amp;#8211; 40 person hours to generate that first set of data for review.&lt;/p&gt;
&lt;p&gt;Then there is the review with me.&amp;#160; The least number of people in the room are the three managers and maybe someone from their team&amp;#160;if there was a key technical issue to discuss, so five to six people for another 90 minutes making up another nine to ten hours. Then another set of questions, and we&amp;#8217;re up to 45-50 hours.&amp;#160; We have another review including me and another person or two, the support and development leads, for another hour.&amp;#160; After all of that, it adds up to about 60-65 person hours to get ready for the&amp;#160; Sr. VP MOR.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Talk a little more about how the preparation differs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The preparation is baked into the process.&amp;#160; I update the executive status on the dashboard weekly as part of my preparation for the ALM release team weekly meeting.&amp;#160; That is where I update my overall take on the release. &amp;#160;If we&amp;#8217;re yellow, I share why I think we&amp;#8217;re yellow and what we&amp;#8217;re doing to mitigate the risk. &amp;#160;It takes about 15 minutes for me to update that and it&amp;#8217;s part of my workflow.&amp;#160; The release team meeting is where we talk about the release and where we need to focus.&amp;#160; It&amp;#8217;s less about status and more about what the team needs to work on accomplishing that week.&lt;/p&gt;
&lt;p&gt;The chart-based reporting teams were also working on&amp;#160;those things, but they needed to document it outside their natural process. &amp;#160;How they met and communicated was a key difference because these types of updates were not part of their daily or weekly workflow.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s hard to do an apples to apples comparison because they are such different ways of working. &amp;#160;In the CLM world, everyone can see when risks and issues are updated. &amp;#160;In the chart world, the risks and issues were only seen by about 10% of the team. &amp;#160;If only a subset of the team understands the risk, it&amp;#8217;s hard to go to a newly hired developer and ask about the work they were doing on risk &amp;#8220;X&amp;#8221; because they might not know what you&amp;#8217;re talking about, or know about it in the same context.&amp;#160; Also, the &amp;#8220;man hours&amp;#8221; involved may be similar with the dashboards because the whole team is involved in updating issues regularly, but it&amp;#8217;s a natural part of the workflow so it doesn&amp;#8217;t feel like anyone on the team is spending time gathering status.&lt;/p&gt;
&lt;p&gt;We use Jazz.net to build Jazz.net, using the dashboards to drive our work.&amp;#160; Once that work is done, we all can see our prioritized backlog to pull off the next thing to do more work.&amp;#160;The collaborative nature of the design makes transparency, priorities, and risk part of the process vs ppt where only a select number of people see it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Most meetings result in follow up actions, how are actions from the meetings captured?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Actions in the chart world&amp;#160;would have been tracked in an email.&amp;#160; I&amp;#8217;d get an email saying that the VP met with Sr. vP and here are the two to three things to work on based on the review. &amp;#160;Then I&amp;#8217;d assign the work, and follow up. &amp;#160;If my VP doesn&amp;#8217;t remember, or loses the email, the actions fall through the cracks. &amp;#160;We&amp;#8217;d report on those actions through email and follows up in status meetings or 1&amp;#215;1s.&lt;/p&gt;
&lt;p&gt;In the RTC world, actions are captured as work items. &amp;#160;We review the actions to pursue which are tracked and prioritized with other work items in RTC. &amp;#160;So, if anyone has any questions, they can revert to the work item. &amp;#160;There is a live audit trail, when it was opened, who opened it, who owns, what has happened, etc.&amp;#160; It becomes part of the workflow.&lt;/p&gt;
&lt;p&gt;I can also add that in test we have major productivity gains from dashboards usage that are linked to test plans. They help to eliminate the manual chart compilation work and results are kept live and up to date, which is imperative as our releases and test cycles are getting shorter.&lt;/p&gt;
I&amp;#8217;d like to thank Brian for taking the time to discuss this topic. Using RTC for dashboards enables a natural development workflow supporting open communication and transparency while reducing overhead for the organization.&amp;#160; Understanding the priority of the work, the status of the work, and the risks of the work all help keep teams focused. By making it part of the natural development workflow it increases productivity.&amp;#160; I&amp;#8217;m not sure who to attribute this quote to: &amp;#8220;If it hurts, do it more often&amp;#8221; (&lt;a&gt;&lt;/a&gt;&lt;p&gt;I&amp;#8217;d like to thank Brian for taking the time to discuss this topic. Using RTC for dashboards enables a natural development workflow supporting open communication and transparency while reducing overhead for the organization. Understanding the priority of the work, the status of the work, and the risks of the work all help keep teams focused. By making it part of the natural development workflow it increases productivity. I&amp;#8217;m not sure who to attribute this quote to: &amp;#8220;If it hurts, do it more often&amp;#8221; ( &lt;a href="http://martinfowler.com/bliki/FrequencyReducesDifficulty.html"&gt;maybe&lt;/a&gt; ?). But, it definitely has reduced stress and overhead in this context!&lt;/p&gt;&lt;p&gt;Beth Zukowsky&lt;br&gt;
Program Director and Rational DevOps Protagonist&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog Try out the new configuration management features in CLM 6.0 RC1!</title><link href="http://www.ciandcd.com/jazz-team-blog-try-out-the-new-configuration-management-features-in-clm-60-rc1.html" rel="alternate"></link><updated>2015-06-27T04:00:28+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-try-out-the-new-configuration-management-features-in-clm-60-rc1.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/05/14/try-out-the-new-configuration-management-features-in-clm-6-0-rc1/"&gt;https://jazz.net/blog/index.php/2015/05/14/try-out-the-new-configuration-management-features-in-clm-6-0-rc1/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;The recent release of Collaborative Lifecycle Management (CLM) 6.0 RC1 signals the release candidate (RC) phase of development, which means that the official CLM 6.0 release is in its final stages. The 6.0 release offers new and exciting configuration management capabilities. To learn more about these capabilities, read the &lt;a href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.vvc.doc/topics/c_cm_assess.html?lang=en"&gt;Getting started with configuration management&lt;/a&gt; help topic or watch the &lt;a href="https://www.youtube.com/watch?v=Yv4-G79OUDI&amp;amp;list=PLZGO0qYNSD4V6xyq6nmZgD8jg7Y9iDpGM&amp;amp;index=6"&gt;Introduction to configuration management&lt;/a&gt; video, which is part of a larger &lt;a href="https://www.youtube.com/playlist?list=PLZGO0qYNSD4V6xyq6nmZgD8jg7Y9iDpGM"&gt;video series&lt;/a&gt;. You can try the configuration management capabilities in an existing &lt;a href="https://jazz.net/products/sandbox/?tag=clm"&gt;cloud sandbox&lt;/a&gt;, or you can evaluate them in your own environment by downloading &lt;a href="https://jazz.net/downloads/clm/"&gt;CLM 6.0 RC1&lt;/a&gt;, reading the &lt;a href="https://jazz.net/servlet/clm-cm/request-key"&gt;considerations&lt;/a&gt;, and obtaining an activation key.&lt;/p&gt;
&lt;p&gt;&lt;img src="" alt="" width="644" height="289"&gt;&lt;/p&gt;
&lt;p&gt;Tim Feeney&lt;br&gt;
Executive IT Specialist&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog Raising your game with configuration management in and across your tools</title><link href="http://www.ciandcd.com/jazz-team-blog-raising-your-game-with-configuration-management-in-and-across-your-tools.html" rel="alternate"></link><updated>2015-06-27T03:58:00+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-raising-your-game-with-configuration-management-in-and-across-your-tools.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/06/09/raising-your-game-with-configuration-management-in-and-across-your-tools/"&gt;https://jazz.net/blog/index.php/2015/06/09/raising-your-game-with-configuration-management-in-and-across-your-tools/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;High-performing teams are never satisfied with their performance. They regularly ask, &amp;#8220;How can we do better?&amp;#8221;&amp;#160; They have a certain restlessness. A sense of mission, stewardship, and empathy for the people who will use the things they design and build.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s our mission to provide tools and make possible development practices that help your high-performing teams improve their game.&amp;#160; To that end, Collaborative Lifecycle Management (CLM) 6.0 brings significant new capabilities for configuration management within and across your Jazz tools &amp;#8212; with the potential for tools from other vendors to participate in these innovations.&lt;/p&gt;
&lt;p&gt;In our days you&amp;#8217;d be hard pressed to find a software development team that would undertake serious work without using a SCM system.&amp;#160; In CLM 6.0, we are extending configuration management capabilities (including development streams, baselines, branching, merging, change sets, comparing across streams) to other tools, so practitioners in other disciplines can gain the same kinds of efficiencies. We are solving this in an open, federated way through (1) new implementations of configuration management in Rational DOORS Next Generation and Rational Quality Manager; and (2) support for Global Configurations as defined in in the OASIS &lt;a href="https://wiki.oasis-open.org/oslc-ccm/" target="_blank"&gt;OSLC Configuration Management&lt;/a&gt; specification.&lt;/p&gt;
&lt;p&gt;We expect these capabilities will help teams be more effective in using baselines, doing parallel development, working in large programs of projects, and doing product line engineering.&amp;#160; Look for baby steps you can take. Walk now; run later.&lt;/p&gt;
&lt;p&gt;To learn more, check out the &lt;a href="https://www.ibm.com/developerworks/community/blogs/35dfcb99-111b-423a-aaa4-50f3fddae141?lang=en" target="_blank"&gt;Continuous Engineering blog&lt;/a&gt; on developerWorks, or see the short videos on &lt;a href="https://www.ibm.com/developerworks/library/?sort_by=&amp;amp;show_abstract=true&amp;amp;show_all=&amp;amp;search_flag=&amp;amp;contentarea_by=All+Zones&amp;amp;search_by=&amp;amp;product_by=All++Products&amp;amp;topic_by=Configuration+management&amp;amp;industry_by=All++Industries&amp;amp;type_by=Video+and+audio&amp;amp;ibm-search=Search" target="_blank"&gt;developerWorks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Daniel Moul&lt;br&gt;
Senior Product Manager&lt;/p&gt;
&lt;p&gt;P.S. Many thanks to those of you who downloaded beta milestones and provided feedback, or sat down with us to share your insights about what your engineers need to raise their game.&amp;#160; We know you are on a journey; we are too. It&amp;#8217;s a privilege to run together.&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog Announcing Rational Publishing Engine 2.0 GA</title><link href="http://www.ciandcd.com/jazz-team-blog-announcing-rational-publishing-engine-20-ga.html" rel="alternate"></link><updated>2015-06-27T03:55:54+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-announcing-rational-publishing-engine-20-ga.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/06/17/announcing-rational-publishing-engine-2-0-ga/"&gt;https://jazz.net/blog/index.php/2015/06/17/announcing-rational-publishing-engine-2-0-ga/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;The Rational Publishing Engine 2.0 is now available as a GA download. This major release includes a simplified web interface that will help clients focus on generating documents with minimal steps and also apply effective template reuse within their organization.&lt;/p&gt;
&lt;p&gt;To learn more about the capabilities of this release, read the &amp;#8220;&lt;a href="www-01.ibm.com/support/knowledgecenter/SS6RHZ_2.0.0/com.ibm.rational.pe.overview.doc/topics/c_whats_new_20.html?lang=en-us"&gt;What&amp;#8217;s new&lt;/a&gt;&amp;#8221; section in our &lt;a href="http://www-01.ibm.com/support/knowledgecenter/SS6RHZ_2.0.0/com.ibm.rational.pe.nav.doc/helpindex_rpe.html"&gt;Infocenter documentation for RPE 2.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can try the document generation capabilities by accessing our cloud sandbox on &lt;a href="https://rpe.mybluemix.net/rpeng/home"&gt;https://rpe.mybluemix.net/rpeng/home&lt;/a&gt;. &amp;#160;Login with your id and click on &amp;#8220;Create Examples&amp;#8221; for a quick start on using the new web interface.&lt;/p&gt;
&lt;p&gt;We look forward to your feedback on the design and usability of the system. If there are any use cases in your organization that is not addressed with the current system, please write to us at &lt;strong&gt;rpe20_beta_support@wwpdl.vnet.ibm.com&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this release, we have adopted IBM Design Thinking methodology for the first time. We have received valuable inputs from our clients and our stakeholders through the design partner program. I would like to thank all our clients who participated in the design partner and in the Beta program. We look forward to your inputs on the GA version of Rational Publishing Engine 2.0.&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog New single sign-on options in CLM 6.0</title><link href="http://www.ciandcd.com/jazz-team-blog-new-single-sign-on-options-in-clm-60.html" rel="alternate"></link><updated>2015-06-27T03:55:46+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-new-single-sign-on-options-in-clm-60.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/06/19/new-single-sign-on-options-in-clm-6-0/"&gt;https://jazz.net/blog/index.php/2015/06/19/new-single-sign-on-options-in-clm-6-0/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Collaborative Lifecycle Management (CLM) has directly supported two types of single sign-on (SSO) authentication for some time. First, all applications installed in the same application server (whether IBM WebSphere Application Server or Tomcat) automatically share login sessions, such that if you log in to one application, you are also logged into all the other applications deployed in the same server. Second, when all applications are deployed in one or more WebSphere Application Servers, you can configure&amp;#160;&lt;a title="Lightweight Third Party Authentication" href="http://www-01.ibm.com/support/knowledgecenter/api/content/nl/en-us/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_jazz_single_sign_on.html#c_jazz_single_sign_on__was-ltpa-auth-sec" target="_blank"&gt;Lightweight Third Party Authentication (LTPA) SSO&lt;/a&gt; so that login sessions are shared across all the WebSphere servers.&lt;/p&gt;
&lt;p&gt;We are excited to announce that we have added &lt;a title="Jazz single sign-on options" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_jazz_single_sign_on.html" target="_blank"&gt;two new SSO options&lt;/a&gt; in the CLM 6.0 release. You&amp;#8217;ll now have the option to use either &lt;a title="Kerberos" href="http://en.wikipedia.org/wiki/Kerberos_%28protocol%29" target="_blank"&gt;Kerberos&lt;/a&gt; authentication, or what we call &amp;#8220;Jazz Security Architecture Single Sign-On&amp;#8221;, which is based on the &lt;a title="OpenID Connect" href="http://openid.net/connect/" target="_blank"&gt;OpenID Connect&lt;/a&gt; standards.&lt;/p&gt;
&lt;p&gt;Kerberos is a well-established SSO protocol that is also the default authentication protocol used by Microsoft Windows, so if your organization uses Windows workstations, Microsoft Active Directory for user management, and deploy Jazz applications in WebSphere 8 or later, it will be possible to configure CLM so that your Windows login session is automatically used to log in to CLM. Kerberos can also be used with non-Windows workstations, as long as you use a Microsoft Active Directory server to manage your user accounts. While it has been possible to configure CLM servers to use Kerberos for some time, only web browser clients could take advantage of Kerberos login sessions &amp;#8211; the RTC Eclipse client, the Microsoft Visual Studio RTC client, the other Windows .NET clients, the RTC build engine and clients, and the various command-line clients could not use Kerberos. Now, all those RTC clients will work with Kerberos. See &amp;#160;&lt;a title="Single sign-on authentication in CLM" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_jazz_single_sign_on.html" target="_blank"&gt;Single sign-on authentication in CLM&lt;/a&gt; for the complete list of RTC clients that support Kerberos, and &lt;a title="Configuring Kerberos" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_kerSso_config.html" target="_blank"&gt;Configuring Kerberos&lt;/a&gt; for details on setting up Kerberos for CLM.&lt;/p&gt;
&lt;p&gt;The OpenID Connect (OIDC) authentication protocol was established in early 2014 as an extension of the&amp;#160;&lt;a title="OAuth 2.0" href="http://oauth.net/2/" target="_blank"&gt;OAuth 2.0&lt;/a&gt; protocol, designed to be easier to adopt across a wide range of clients (native applications, browsers, browser-based applications, and mobile devices). It is extensible and configurable (with optional features). Jazz Security Architecture (JSA) is a particular profile of OIDC, specifying which optional features are included, and a few extensions. Authentication is handled by the Jazz Authorization Server (JAS); Jazz applications delegate to that server instead of relying on the application server to handle authentication. Single sign-on is supported across all applications that are configured to use the same JAS, independent of what sort of application servers they are deployed in, and what platform they are running on. To use Jazz Security Architecture SSO, you must &lt;a title="Installing the Rational solution for Collaborative Lifecycle Management by using IBM Installation Manager" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/t_s_server_installation_im.html" target="_blank"&gt;install the Jazz Authorization Server&lt;/a&gt;, &lt;a title="Deploying and starting Jazz Authorization Server" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_jsasso_jas_deploy_start.html" target="_blank"&gt;configure it and start it up&lt;/a&gt;, and either enable JSA SSO in CLM applications when installing (for a new installation), or &lt;a title="Enabling Jazz Security Architecture single sign-on after upgrading" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_JsaSso_enable_after_upgrade.html" target="_blank"&gt;enable JSA SSO after upgrading to the 6.0 release&lt;/a&gt; (for existing installations).&lt;/p&gt;
&lt;p&gt;The login form for the JAS looks very similar to the Jazz application login form, but you&amp;#8217;ll know that you&amp;#8217;re using the JAS for authentication if the login form says &amp;#8220;AUTHORIZATION SERVER&amp;#8221; instead of &amp;#8220;TEAM SERVER&amp;#8221;:&lt;/p&gt;
&lt;p&gt;You can find more information on how authentication works in general, and the various options available, in the &lt;a title="Jazz Server Authentication Explained" href="https://jazz.net/library/article/75" target="_blank"&gt;Jazz Server Authentication Explained&lt;/a&gt; article. We&amp;#8217;re hoping these new SSO options provide increased flexibility and ease-of-use for our users.&lt;/p&gt;
&lt;p&gt;John Vasta&lt;br&gt;
Senior Software Engineer&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog Unlocking engineering insight for an IoT world</title><link href="http://www.ciandcd.com/jazz-team-blog-unlocking-engineering-insight-for-an-iot-world.html" rel="alternate"></link><updated>2015-06-27T03:53:35+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-unlocking-engineering-insight-for-an-iot-world.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/06/24/unlocking-engineering-insight-for-an-iot-world/"&gt;https://jazz.net/blog/index.php/2015/06/24/unlocking-engineering-insight-for-an-iot-world/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Gary Cernosek&lt;/p&gt;
&lt;p&gt;Sr. Product Manager&lt;/p&gt;
&lt;p&gt;IBM IoT Continuous Engineering&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m writing this series of posts over the next few weeks to spur dialog on the topic of how organizations practicing in an IoT world need better ways to extract and derive value from the many sources that comprise their environment of engineering information. I plan to post this topic in four parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Part 1: The State of engineering information&lt;/strong&gt;. I open this series of blog entries with the context of why customers care about gaining insight from their engineering data now more than ever.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Part 2: Aggregating engineering information from multiple sources&lt;/strong&gt;. I&amp;#8217;ll next address the problems indicated in Part 1 by discussing old and new ways for bringing multiple sources of information together and unifying the way engineers gain access to and work with such information.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Part 3: Integrating across disparate tools&lt;/strong&gt;. Here I&amp;#8217;ll address the need to gain access to engineering information from tools not originally designed to be integrated with the outside world.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Part 4: From information to insight&lt;/strong&gt;. Imagine a world where we connect everything that needs to be connected. Then what? Here I&amp;#8217;ll discuss the vision for IBM&amp;#8217;s Continuous Engineering solution as it provides the basis for analytics and turning raw tool data into true engineering insight.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Part 1: The State of engineering information &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Gary Cernosek&lt;/p&gt;
&lt;p&gt;Sr. Product Manager&lt;/p&gt;
&lt;p&gt;IBM IoT Continuous Engineering&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I know it&amp;#8217;s here, somewhere&amp;#8230; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Workers across engineering disciplines spend a lot of time (not) finding the information they need to do their jobs. Consider these statistics captured by KMWorld and The Ridge Group:1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Knowledge      workers spend 15% to 35% of their time searching for information&lt;/li&gt;
&lt;li&gt;40%      of corporate users report they cannot find the information they need to do      their jobs&lt;/li&gt;
&lt;li&gt;50%      of Internet searches are abandoned&lt;/li&gt;
&lt;li&gt;90%      of the time that knowledge workers spend in creating new reports is recreating      information that already exists&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The problem is not creating good information, it&amp;#8217;s finding it! What&amp;#8217;s the root cause of these problems?&lt;/p&gt;
&lt;p&gt;Much of it has to do with how engineering environments tend to be highly fragmented across disparate tools. And the challenge to connect them is growing exponentially. Each engineering tool comes with its own user interface, and often multiple interfaces for use on the Web vs. desktop application. Behind the scenes, the tools offer various presentations of views and tasks, and often proprietary logic for workflow, process, search, query, scale, security, and collaboration. Storage methods vary from use of individual files on workstation or servers to databases with proprietary interfaces.&lt;/p&gt;
&lt;p&gt;This degree of variance makes it very difficult for organizations to ensure that engineering information is available to users and traceable across different tools&amp;#8212;even when the tools come from the same vendor! The results are brittle/poor integrations, silos everywhere, high cost to maintain and administer the tools, and little reuse.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What&amp;#8217;s so special about IoT?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Maybe your organization has handled these challenges fine up to now. But many are finding that IoT presents new or amplified issues that challenge their status quo. Two trends tend to stand out for organizations delivering products and systems connected to the Internet:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Market      pressure to increase product delivery frequency and compress cycle time&lt;/li&gt;
&lt;li&gt;Sheer      volume and complexity of software required in modern products and systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These trends are depicted in the graphics below and illustrate the need for organizations to be more &amp;#8216;agile&amp;#8217; and to build &amp;#8216;smarter&amp;#8217; products:&lt;a rel="attachment wp-att-13291" href="https://jazz.net/blog/index.php/2015/06/24/unlocking-engineering-insight-for-an-iot-world/image-for-uei-blog/"&gt;&lt;img class="aligncenter size-full wp-image-13291" title="Image for UEI blog" src="https://jazz.net/blog/wp-content/uploads/2015/06/Image-for-UEI-blog.jpg" alt="" width="783" height="306"&gt;&lt;/a&gt;Projects that used to take years are expected to deliver in months, and those previously completed in months now have make at least incremental progress in weeks, or even days. Environments that historically treated software as a &amp;#8216;part&amp;#8217; that was captured once per product release cycle and stored off in the product data management tool for simple compliance now require greater granularity of lifecycle assets and tighter coordination between software and hardware engineering processes. These factors are driving organizations to reevaluate the way they develop and deliver their products and systems.&lt;/p&gt;
&lt;h2&gt;Do you identify with these issues and trends?&lt;/h2&gt;
&lt;p&gt;If these issues and challenges resonate with your experience, comment in the blog. Let me and others know how it&amp;#8217;s affecting your day-to-day worklife and your organization&amp;#8217;s business results. And stay tuned for the next parts of my entries for &amp;#8220;Unlocking engineering insight for an IoT world.&amp;#8221;&lt;/p&gt;
&lt;h2&gt;1Sources:&lt;/h2&gt;
&lt;p&gt;KMWorld, &amp;#8220;The high cost of not finding information,&amp;#8221; &lt;a href="http://bit.ly/1AnNGZO"&gt;http://bit.ly/1AnNGZO&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Information Gathering in the Electronic Age: The Hidden Cost of the Hunt, The Ridge Group&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog Transforming your product development for the IoT</title><link href="http://www.ciandcd.com/jazz-team-blog-transforming-your-product-development-for-the-iot.html" rel="alternate"></link><updated>2015-06-27T03:53:26+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-transforming-your-product-development-for-the-iot.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/06/25/transforming-your-product-development-for-the-iot/"&gt;https://jazz.net/blog/index.php/2015/06/25/transforming-your-product-development-for-the-iot/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;Development Practices for the IoT Era&lt;/h2&gt;
&lt;p&gt;The Internet of Things (IoT) is not just about connecting things to the Internet and controlling them remotely. It is a major opportunity for developers of things (makers) and operators of things to unlock new value propositions from the lifecycle of things, and to improve innovation and the quality of things. In our context, things are products such as automobiles, medical devices, consumer goods, factory machines, etc. To leverage the value of connected and instrumented devices, there are several important aspects to consider, one of which is a proper digital product development process. Also, it is no longer a secret that in today&amp;#8217;s advanced products most of the innovation comes from the embedded software, so the effectiveness of the software development process is an important parameter of the overall product development process.&lt;/p&gt;
&lt;p&gt;Here are some key leverage points of connected products:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is possible to continuously collect operational data from devices when in operation.&lt;/li&gt;
&lt;li&gt;It is possible to remotely update the software that is embedded in the products.&lt;/li&gt;
&lt;li&gt;With the addition of social media, product makers can also get continuous information on how products are used in different market segments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, to leverage such enablers, product makers need to change their traditional development processes. The development processes need to be much more dynamic and agile to leverage the connectivity and advanced engagement of connected products. Here are some key transformational aspects for the development process:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Connected product complexity&lt;/strong&gt;&amp;#8212;Complexity is increasing with the additional functionalities provided by new interactions between products and product to cloud. Practices for handling this complexity rely on digital systems engineering processes that are based on digital representations of product requirements, product architecture, and product verification plans. Such digital systems engineering approaches enable continuous verification of product designs to eliminate risks early in the process as part of addressing this complexity. Continuous verification utilizes techniques such as simulation and rules-based checking to validate the requirements and the system architecture.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transforming data into engineering insight&lt;/strong&gt;&amp;#8212;The amount of operational data available from connected systems is overwhelming and typically engineering information is locked in isolated silos.  Data coming from operations and manufacture may trace to product requirements, product design, and product test. Being able to properly analyze all those product engineering aspects requires complete digitalization, traceability, and analytics of all product development aspects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Increasing speed of development&lt;/strong&gt;&amp;#8212;The connected world increases the need to respond much more quickly to market findings and demands. The ability to effectively respond to change in multidisciplinary products depends on an effective change management process, where impact analysis of the change is conducted in a completely digital manner based on query across lifecycle data. It also relies on the ability to create change contexts across the lifecycle, without interfering with the overall system state before the change is actually approved. Creating such change contexts is enabled by configurations across the lifecycle.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Specialization&lt;/strong&gt;&amp;#8212;With the advancement of social media around connected products there is going to be higher demand to create more specialized products to deal with competition and optimize product revenue.  That requires capabilities to properly manage reuse and variation as part of the product development process. Ineffective ways to manage variation limit the ability of product makers to effectively leverage product variation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Streamlined process with continuous integration&lt;/strong&gt;&amp;#8212;IoT architectures require both proper support for embedded software that can be updated on devices, as well as software on cloud that analyzes and controls devices.&lt;/p&gt;
&lt;p&gt;In order to achieve this transformation of the engineering development process, customers should look to the &lt;a href="http://www.ibm.com/software/info/iot_ce_solution/" target="_blank"&gt;IBM Internet of Things Continuous Engineering Solution&lt;/a&gt;. The IBM Continuous Engineering (CE) platform, which is based on the &lt;a href="http://www.ibm.com/software/products/en/ratlclm" target="_blank"&gt;Rational solution for Collaborative Lifecycle Management&lt;/a&gt; (CLM), provides the infrastructure and capabilities to enable a digital engineering lifecycle, which is necessary to meet the challengse of rapid and effective multidisciplinary development.  Any activity and artifact as part of the process are digital and cross-linked&amp;#8212;whether those artifacts are requirements, product designs and architectures, test plans or change history. There is no need to rely on traditional documents in the process, which are typically the main blocker for digitalization of the lifecycle.  Open, standards-based lifecycle data indexing, query, reporting, and analysis are also key to effectively supporting the stream of incoming changes as part of the connected lifecycle. Recent updates to the CE platform now provide the new capability to define cross-lifecycle configurations, enabling parallel work on new innovations as well as effectively handling product variations by efficient reuse.&lt;/p&gt;
&lt;p&gt;To summarize, the new generation of connected products that makes the Internet of Things is a major opportunity for product makers if they properly adapt their product development practices to leverage the opportunities and meet the challenges.  As already identified by some key IoT-related initiatives, such as&amp;#160; &lt;a href="http://www.bmbf.de/en/19955.php" target="_blank"&gt;Industrie 4.0&lt;/a&gt; in Germany, and &lt;a href="http://www.iiconsortium.org/" target="_blank"&gt;Industrial Internet of Things&lt;/a&gt; (IIoT) initiatives in the United States, the required transformation is to shift product development to a digital platform.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Jazz Team Blog What’s new in DOORS Next Generation 6.0?</title><link href="http://www.ciandcd.com/jazz-team-blog-whats-new-in-doors-next-generation-60.html" rel="alternate"></link><updated>2015-06-27T03:51:06+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jazz-team-blog-whats-new-in-doors-next-generation-60.html</id><summary type="html">From:&lt;a href="https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/"&gt;https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;This release could well be introducing the most fundamental function into a requirements management (RM) tool since RM systems began.&amp;#160; While we continue our drive with usability and productivity, we are also providing support for requirements configuration management (CM), built from the ground up as part of the native tool, rather than simply integrating an external CM system.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h2&gt;Configuration Management&lt;/h2&gt;
&lt;p class="MsoNormal"&gt;&lt;a href="https://jazz.net/downloads/rational-doors-next-generation/releases/6.0" target="_blank"&gt;DOORS Next Generation 6.0&lt;/a&gt; is our first release providing native configuration management of requirements, enabling functionality for strategic reuse and Product Line Engineering. &lt;/p&gt;
&lt;p class="MsoNormal"&gt;RM offers the ability to define the scope of a project, program, or deliverable&amp;#8212;but unless you have control over change this scope could well consume more of your project costs than you expected. Placing requirements under CM allows for the scope to be controlled, while enabling your teams to work in parallel versions at the same time without the need to make project copies to handle variants. &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13270" href="https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/cfgm/"&gt;&lt;img class="aligncenter size-full wp-image-13270" title="CfgM" src="https://jazz.net/blog/wp-content/uploads/2015/06/CfgM.png" alt="" width="524" height="179"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;p class="MsoNormal"&gt;On a basic level, CM provides a way to manage groups of artifacts and their versions. Versions can be split to support different variants and merged in order to deliver changes of requirements back to accepted releases. With CM, users can efficiently create different streams to help manage parallel versions without the need to make copies of their requirements. Additionally, there is robust linking that is specific to the stream the user is working in. This means that following the link shows users the requirement, test, or design element on the other end of the link that is appropriate for the stream they are working in. The ability to compare across streams and baselines helps users to understand how their versions or variants are different and to correct any mistakes.&lt;/p&gt;
&lt;p class="MsoNormal"&gt;The functionality has been designed expecting only a small number of people to engage directly with parallel versions and CM, while the rest of the engineers continue with their work, mostly as if nothing has changed. &lt;/p&gt;
&lt;p class="MsoNormal"&gt;By default, these new capabilities are turned off and project administrators have to enable them for the server and for each project area where users want to take advantage of them. &lt;/p&gt;
&lt;h2&gt;Global Configuration Management&lt;/h2&gt;
&lt;p class="MsoNormal"&gt;For some time we have been discussing the benefits of being able to support use cases such as &amp;#8220;link a version of a test case with a version of a requirement&amp;#8221;.&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13269" href="https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/global-configurations/"&gt;&lt;img class="alignleft size-full wp-image-13269" title="Global Configurations" src="https://jazz.net/blog/wp-content/uploads/2015/06/Global-Configurations.jpg" alt="" width="366" height="215"&gt;&lt;/a&gt;6.0 extends CM with a federated approach to lifecycle information. Strategic reuse for complex systems and software is now possible for requirements (RDNG), design (RDM), test (RQM) and software development (RTC). &lt;/p&gt;
&lt;ul type="disc"&gt;
&lt;li class="MsoNormal"&gt;Plan and manage the reuse      of configurations in the many versions or variants of the product or      software line.&lt;/li&gt;
&lt;li class="MsoNormal"&gt;Define complex products      and applications as hierarchies of components and reuse those components      in multiple products and applications.&lt;/li&gt;
&lt;li class="MsoNormal"&gt;Automatically handle links      between artifacts when branching or delivering changes to another stream      such as, links between tests and requirements.&lt;/li&gt;
&lt;li class="MsoNormal"&gt;Create cross lifecycle      baselines to support parallel development of multiple versions and      variants, branching and merging, and change management.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Diagram editor&lt;/h2&gt;
&lt;p class="MsoNormal"&gt;Users can create many types of diagrams to refine and communicate their ideas and to elaborate their requirements.&lt;/p&gt;
&lt;p class="MsoNormal"&gt;&lt;a rel="attachment wp-att-13268" href="https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/picture1-2/"&gt;&lt;img class="alignright size-full wp-image-13268" title="DNG informal diagram editor" src="https://jazz.net/blog/wp-content/uploads/2015/06/Picture11.jpg" alt="" width="376" height="288"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p class="MsoNormal"&gt;The new diagram editor provides high-quality diagrams that are simple to create in all supported browsers without the need for a Java&amp;#8482; plug-in. The large selection of shapes and themed styles make it easy to create many types of diagrams with eye-catching color palettes. To increase productivity, users can use the keyboard to create all the diagrams. They can comment on and create links between individual diagram elements and other artifacts. Diagrams can be added to modules and embedded in rich-text artifacts.&lt;/p&gt;
&lt;p class="MsoNormal"&gt;
&lt;/p&gt;&lt;p class="MsoNormal"&gt;See the &lt;a href="https://jazz.net/downloads/rational-doors-next-generation/releases/6.0?p=releaseNotes" target="_blank"&gt;Release Notes&lt;/a&gt; for further information!&lt;/p&gt;
&lt;p class="MsoNormal"&gt;  &lt;/p&gt;
&lt;p class="MsoNormal"&gt;This release could well be introducing the most fundamental function into a requirements management tool since RM systems began. While we continue our drive with usability and productivity we are also providing support for requirements configuration management, built from the ground up as part of the native tool, rather than simply integrating to an external CM system.&lt;/p&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</summary></entry><entry><title>Continuous integration and deployment solution!</title><link href="http://www.ciandcd.com/continuous-integration-and-deployment-solution.html" rel="alternate"></link><updated>2015-06-27T03:43:51+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:continuous-integration-and-deployment-solution.html</id><summary type="html">From:&lt;a href="http://www.pmease.com/hotnews?id=1"&gt;http://www.pmease.com/hotnews?id=1&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;
	
		
			&lt;h3&gt;QuickBuild 6.0 is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

Feature highlights in this release:&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Find repository/step/variable overrides and usages for configuration refactoring.&lt;/li&gt;
&lt;li&gt;Optionally trust authenticated user in specified http header to support single sign-on.&lt;/li&gt;
&lt;li&gt;Permission set definition to facilitate assigning same set of permissions repeatedly.&lt;/li&gt;
&lt;li&gt; Administrator can select to run as arbitrary user to facilitate checking user profile.&lt;/li&gt;
&lt;li&gt;Aggregate SCM changes to display change summary and statistics in high level configuration.&lt;/li&gt;
&lt;li&gt;Gerrit integration to verify open changes and score specified Gerrit label accordingly.&lt;/li&gt;
&lt;li&gt;JFrog Artifactory integration to publish and use artifacts during build.&lt;/li&gt;
&lt;li&gt;Persist unprocessed build requests after server shutdown and resume processing after startup.&lt;/li&gt;
&lt;li&gt;Accurev proof build to test active changes on QuickBuild before getting them promoted.&lt;/li&gt;
&lt;li&gt;Optionally run scripts after deletion of configuration and build.&lt;/li&gt;
&lt;li&gt;Able to view live log by step, and view log of finished steps before build finishes.&lt;/li&gt;
&lt;li&gt;Step to record SCM changes without checking out the repository.&lt;/li&gt;
&lt;li&gt;Able to display custom banner in QuickBuild page.&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;We are proud to annouce QuickBuild 6.0.Feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 5.1 is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

Feature highlights in this release:&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Verify GitHub pull requests and update pull request status based on build result.&lt;/li&gt;
&lt;li&gt;GitHub issue tracker integration to parse issues in commit messages.&lt;/li&gt;
&lt;li&gt;Leverage perforce shelve/unshelve feature to run pre-commit builds without using user agent.&lt;/li&gt;
&lt;li&gt;Retrieve changes of Subversion externals for source view and diff.&lt;/li&gt;
&lt;li&gt;Custom columns to display custom build and request info.&lt;/li&gt;
&lt;li&gt;Display reasons for waiting builds and steps.&lt;/li&gt;
&lt;li&gt;Define environment variables in composite steps for inheritance and overriding.&lt;/li&gt;
&lt;li&gt;Detect broken communication links to agents to fail build fast.&lt;/li&gt;
&lt;li&gt;Drag&amp;amp;drop to organize favorite dashboards.&lt;/li&gt;
&lt;li&gt;Dashboard list to display all dasbhoards in system.&lt;/li&gt;
&lt;li&gt;Resource access information to know about resource usage status.&lt;/li&gt;
&lt;li&gt;Coverity report rendering&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;We are proud to annouce the formal release of QuickBuild 5.1Feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 5.0 is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

Feature highlights in this release:&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Launch build agent on demand in cloud environment including Amazon EC2.&lt;/li&gt;
&lt;li&gt;Build pipeline to visualize commits life cycle across different build and deployment stages.&lt;/li&gt;
&lt;li&gt;Optionally store artifacts of configuration sub tree to specified build agents to reduce server load.&lt;/li&gt;
&lt;li&gt;Grid and server metrics collecting and trending.&lt;/li&gt;
&lt;li&gt;Alert definition and notification for key performance indicators.&lt;/li&gt;
&lt;li&gt;Enhanced tray monitor and refined message window.&lt;/li&gt;
&lt;li&gt;Toggle node and step information in build log.&lt;/li&gt;
&lt;li&gt;Share dashboards with specified users besides groups.&lt;/li&gt;
&lt;li&gt;Headless plugin build.&lt;/li&gt;
&lt;li&gt;New dashboard gadgets to display build pipeline, grid performance measurements and system alerts.&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;We are proud to annouce the formal release of QuickBuild 5.Feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 4.0 formal release is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

Feature highlights in this release:&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Customizable dashboard for users and groups to organize build information via gadgets.&lt;/li&gt;
&lt;li&gt;Report aggregation to provide build metrics summary of descendant configurations.&lt;/li&gt;
&lt;li&gt;Resource management for better control of build distribution and agent load.&lt;/li&gt;
&lt;li&gt;Grid partition to divide grid nodes between different configuration trees.&lt;/li&gt;
&lt;li&gt;User activity audit to track and review every modification to the system.&lt;/li&gt;
&lt;li&gt;CollabNet TeamForge integration for user authentication, file uploading, release creation, issue linking. and issue updating.&lt;/li&gt;
&lt;li&gt;Redmine integration to link QuickBuild builds with Redmine issues.&lt;/li&gt;
&lt;li&gt;Google Repo integration to detect changes, check out source, and create tags against Repo.&lt;/li&gt;
&lt;li&gt;Boost test integration to render test reports and display test trends.&lt;/li&gt;
&lt;li&gt;Redesigned report system for improved user experience and performance.&lt;/li&gt;
&lt;li&gt;RESTful API for changes, issues, and various reports.&lt;/li&gt;
&lt;li&gt;Plugin API for third party issue tracker and unit test framework integration.&lt;/li&gt;
&lt;li&gt;Searchable users and groups.&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;We are proud to annouce the formal release of QuickBuild 4.Feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 3.1 - distributed version control system integration and enhanced .NET support&lt;/h3&gt;&lt;p&gt;QuickBuild 3.1 is released to integrate with Git, Mercurial, Bazaar and Team Foundation Server. This integration makes possible below actions in a continuous integration or release management environment when dealing with these SCMs:&lt;/p&gt;
&lt;ul class="square"&gt;&lt;li&gt;Retrieve source code for build and test from tip or specified revision.&lt;/li&gt;
&lt;li&gt;Create tags for retrieved source code if necessary.&lt;/li&gt;
&lt;li&gt;Detect source changes between builds and notify committers under specified condition.&lt;/li&gt;
&lt;li&gt;Promote SCM revisions to higher stage, for example from qa to release.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Git, Mercurial and Bazaar integration also includes the gated push feature, with which you can submit ready-for-push commits to QuickBuild for build/test, and have QuickBuild to push them to the official repository automatically after building/testing successfully.&lt;/p&gt;

&lt;p&gt;This release also supports to build .NET projects through MSBuild and Visual Studio solution builder.&lt;/p&gt;

&lt;p&gt;Refer to &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new/&lt;/a&gt; for details.&lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 3.1 beta1 released to support Git, Mercurial, TFS and Bazaar&lt;/h3&gt;&lt;br&gt;&lt;br&gt;
You may visit &lt;a&gt;&lt;/a&gt;&lt;p&gt;Git, Mercurial, Team Foundation Server and Bazaar support is now in beta. In this beta, QuickBuild can checkout code, create tags, detect changes, view/diff source files from these version control systems. Proof build support is not yet included but will be delivered in future betas.You may visit &lt;a href="http://www.pmease.com/downloads/eap/"&gt;this link&lt;/a&gt; to download the beta. Any feedbacks or suggestions are very welcomed!&lt;/p&gt;
	
		
			&lt;h3&gt;The formal release of QuickBuild 3 is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

This release works tightly with issue tracking systems to provide an integrated view of issues, builds and SCM changes. No longer worry about which issues are fixed in a particular build, or which build a particular issue is fixed in. QuickBuild tracks these information for you automatically! The release management functionality is improved considerably with the ability to use next unreleased version in issue tracker as next build version, and push built versions into issue tracker as released versions. Currently JIRA, Trac and Bugzilla are supported.&lt;br&gt;&lt;br&gt;

Other feature highlights in this release:&lt;br&gt;&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Step can be repeated for different set of parameters, either parallelly, or sequentially. For example, you may create a singe test step to have it execute for each combination of possible databases and OS platforms, or have it run on all applicable build agents. This can greatly reduce number of steps needed in a complex build workflow.&lt;/li&gt;
&lt;li&gt;QuickBuild can now terminate spawned build processes immediately and reliably when a build is canceled or timed out. You no longer need to manually kill relevant processes to release workspace mutexes. This works on Windows, Linux and Unix platforms.&lt;/li&gt;
&lt;li&gt;A non-admin account can now be authorized to administer a configuration subtree.&lt;/li&gt;
&lt;li&gt;Multiple promote actions can be defined with the ability to customize the condition of each action. For example, you may define a release action and have it appear only when build is recommended and current user belongs to release manager group.&lt;/li&gt;
&lt;li&gt;Inherited settings such as steps, repositories and variables will be displayed directly in descendant configurations. This makes examination and modification of inherited settings much easier.&lt;/li&gt;
&lt;li&gt;Build workflow can now be created/rearranged by dragging and dropping steps.&lt;/li&gt;
&lt;li&gt;Trends of duration and success rate of each executed steps are now available in statistics tab of a configuration. You can even compare these trends between different steps to find out which step fails the most and which step costs the most time.&lt;/li&gt;
&lt;li&gt;SCM changes screen is reworked to support text search in changes between two arbitrary builds.&lt;/li&gt;
&lt;li&gt;The same step can now be reused in different composition steps.&lt;/li&gt;
&lt;li&gt;Add the option of auto-detecting user time zone from browser to display local date/time.&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;We are pround to annouce the formal release of QuickBuild 3.This release works tightly with issue tracking systems to provide an integrated view of issues, builds and SCM changes. No longer worry about which issues are fixed in a particular build, or which build a particular issue is fixed in. QuickBuild tracks these information for you automatically! The release management functionality is improved considerably with the ability to use next unreleased version in issue tracker as next build version, and push built versions into issue tracker as released versions. Currently JIRA, Trac and Bugzilla are supported.Other feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 3.0 beta1 is now available&lt;/h3&gt;&lt;a&gt;&lt;/a&gt;&lt;p&gt;The first beta of QuickBuild 3.0 is now available. This release integrates tightly with JIRA, Trac and Bugzilla to streamline the development process. Other improvements include reusable and repeatable steps, inheritance visibility, process tree killing, build engine optimization, UI polishments. Refer to &lt;a href="http://wiki.pmease.com/display/qb30/3.0.0-beta1"&gt;release notes&lt;/a&gt; for details.&lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 2.1 is available now&lt;/h3&gt;&lt;a&gt;&lt;/a&gt;&lt;p&gt;QuickBuild 2.1 is just released with plugin and RESTful API, a cross-platform tray monitor, FxCop, NCover and CPD support, custom statistics, Oracle and SSL support, and much more. Refer to &lt;a href="http://www.pmease.com/features/whats-new/"&gt;what's new&lt;/a&gt; for a complete list of new features added to this release.&lt;/p&gt;
	
		
			&lt;h3&gt;The brand new QuickBuild 2.0 is released&lt;/h3&gt;&lt;br&gt;
Please refer to &lt;a&gt;&lt;/a&gt;&lt;p&gt;After years of development and test, QuickBuild 2.0 is finally released to embrace latest innovations in continuous integration and build management area. Most important features introduced in this version are pre-commit test, advanced build grid, versatile build reports, graphical build workflow design, visual build promotion, source code view/diff, and build comparison. QuickBuild 2.0 also includes enormous improvments such as intuitive user interface, fine-grained permission control, real time build progress and log monitoring, variable prompting.Please refer to &lt;a http: www.pmease.com features&gt;the feature page&lt;/a&gt; for the complete list of achievements in this version.&lt;/p&gt;
	
&lt;/div&gt;
</summary></entry><entry><title>JetBrains 2014: The Year in Review</title><link href="http://www.ciandcd.com/jetbrains-2014-the-year-in-review.html" rel="alternate"></link><updated>2015-06-27T03:42:20+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jetbrains-2014-the-year-in-review.html</id><summary type="html">From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/21/jetbrains-2014-the-year-in-review/"&gt;http://blog.jetbrains.com/blog/2015/01/21/jetbrains-2014-the-year-in-review/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p dir="ltr"&gt;Our team was hard at work in 2014 delivering new releases of our existing products and bringing new ones to market. In this post we are going to take a look at those and some of the other biggest moments of the year.&lt;/p&gt;
&lt;p dir="ltr"&gt;If you remember back to&amp;#160;&lt;strong&gt;&lt;a title="JetBrains Day @ FooCafé" href="http://blog.jetbrains.com/blog/2013/09/12/jetbrains-day-foocafe-recap-announcements-and-videos/" target="_blank"&gt;JetBrains Day @ FooCaf&amp;#233;&lt;/a&gt;&lt;/strong&gt; in September 2013, we announced several new projects. 2014 saw those plans come to fruition. In February,&amp;#160;&lt;strong&gt;&lt;a title="ReShaper C++" href="https://www.jetbrains.com/resharper/features/cpp.html" target="_blank"&gt;ReSharper C++ Early Access Program&lt;/a&gt;&lt;/strong&gt;&amp;#160;went live, in May&amp;#160;&lt;strong&gt;&lt;a title="Nitra was made open source" href="http://blog.jetbrains.com/blog/2014/05/27/nitra-goes-open-source/" target="_blank"&gt;Nitra was made open source&lt;/a&gt;&lt;/strong&gt;, September brought&amp;#160;&lt;strong&gt;&lt;a title="CLion EAP program" href="https://www.jetbrains.com/clion/" target="_blank"&gt;CLion EAP&lt;/a&gt;&lt;/strong&gt;, and in December&amp;#160;&lt;strong&gt;&lt;a title="Upsource" href="https://www.jetbrains.com/upsource/" target="_blank"&gt;Upsource&lt;/a&gt;&lt;/strong&gt;, our repository browsing and code review tool, reached a stable 1.0 build.&lt;/p&gt;
&lt;p dir="ltr"&gt;&lt;img class="aligncenter size-full wp-image-6888" alt="Upsource" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/pic_upsource.png" width="274" height="120"&gt;&lt;/p&gt;
&lt;p dir="ltr"&gt;We didn&amp;#8217;t stop there. Two new products were also added to our portfolio:&amp;#160;&lt;strong&gt;&lt;a title="0xDBE" href="https://www.jetbrains.com/dbe/" target="_blank"&gt;0xDBE&lt;/a&gt;&lt;/strong&gt;, JetBrains&amp;#8217; brand new IDE for DBAs and SQL developers, was first announced in June and in October&amp;#160;&lt;strong&gt;&lt;a title="PyCharm Education Edition" href="https://www.jetbrains.com/pycharm-educational/" target="_blank"&gt;PyCharm Education Edition&lt;/a&gt;&lt;/strong&gt;, a free IDE for learning and teaching programming with Python, went public. You may be interested in checking out our&amp;#160;&lt;strong&gt;&lt;a title="Interactive Python Programming Course Contest" href="https://www.jetbrains.com/pycharm-educational/contest/" target="_blank"&gt; Interactive Python Programming Course Contest&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p dir="ltr"&gt;In 2014 we continued our commitment to the open source community through our various projects and by providing&amp;#160;&lt;strong&gt;&lt;a title="Free Open Source Licenses" href="https://www.jetbrains.com/devnet/sponsorship/open-source/" target="_blank"&gt;free open source licenses&lt;/a&gt;&lt;/strong&gt; to non-commercial OS software projects. In July a&amp;#160;&lt;strong&gt;&lt;a title="New Kotlin website" href="http://kotlinlang.org/" target="_blank"&gt;new open source Kotlin website&lt;/a&gt;&lt;/strong&gt; went live and steady releases of JetBrains&amp;#160;&lt;strong&gt;&lt;a title="Meta Programming System (MPS)" href="https://www.jetbrains.com/mps/" target="_blank"&gt;Meta Programming System&lt;/a&gt;&lt;/strong&gt; (MPS) continued to go out the door.&lt;/p&gt;
&lt;p dir="ltr"&gt;&lt;img class="aligncenter size-full wp-image-6889" alt="Open Source" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/pic_pyCharm.png" width="415" height="83"&gt;&lt;/p&gt;
&lt;p dir="ltr"&gt;Travel again back in time to May 2013 when&amp;#160;&lt;strong&gt;&lt;a title="Google to Build Android Studio on IntelliJ Platform" href="http://blog.jetbrains.com/blog/2013/05/15/intellij-idea-is-the-base-for-android-studio-the-new-ide-for-android-developers/" target="_blank"&gt;Google announced their selection of IntelliJ IDEA as the base of Android Studio&lt;/a&gt;&lt;/strong&gt;. Well, in December, the highly anticipated&amp;#160;&lt;strong&gt;&lt;a href="http://developer.android.com/tools/studio/index.html"&gt;Android Studio 1.0&lt;/a&gt;&lt;/strong&gt; release hit the virtual shelves! This is a great example of open source collaboration working both ways with the work being done on Android Studio being incorporated back into &lt;strong&gt;&lt;a title="IntelliJ IDEA" href="https://www.jetbrains.com/idea/" target="_blank"&gt;IntelliJ IDEA Ultimate Edition&lt;/a&gt;&lt;/strong&gt; and the free and open source &lt;strong&gt;Community Edition&lt;/strong&gt;.&lt;/p&gt;
&lt;p dir="ltr"&gt;One of the proudest moments of the year came in September when we announced &lt;strong&gt;&lt;a title="JetBrains Student License Program" href="https://www.jetbrains.com/student/" target="_blank"&gt;JetBrains Student License Program&lt;/a&gt;&lt;/strong&gt;. Through this program students and teachers have access to our entire product line of IDEs and .NET Tools. Within the first two weeks of the program, more than&amp;#160;&lt;strong&gt;&lt;a title="34,000 students receive free licenses" href="http://blog.jetbrains.com/blog/2014/10/07/jetbrains-student-program-34k-students-join-in-two-weeks/" target="_blank"&gt;34,000 students were approved&lt;/a&gt;&lt;/strong&gt; and now there are &lt;strong&gt;nearly 100,000 students using JetBrains tools for free!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class="alignright size-full wp-image-6890" alt="JetBrains Startup Discount" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/pic_discount-2.png" width="149" height="103"&gt;Nearly a decade and a half on we haven&amp;#8217;t forgotten our startup roots. In February we announced&amp;#160;&lt;strong&gt;&lt;a title="JetBrains Startup Discount Plan" href="https://www.jetbrains.com/estore/startup/" target="_blank"&gt;JetBrains Startup Discount Plan&lt;/a&gt;&lt;/strong&gt;. Software startup businesses that meet straightforward criteria get a &lt;strong&gt;50% discount on all of our products&lt;/strong&gt;. If your startup is just getting off the ground, this is a great place to begin.&lt;/p&gt;
&lt;p&gt;Lastly, here are some of the &lt;strong&gt;honors that our products picked up in 2014&lt;/strong&gt;.&lt;/p&gt;
 
&lt;p&gt;&lt;strong&gt;2014 was a fantastic year and we expect more of the same excitement in 2015. We sincerely thank you; all of our friends and colleagues, for your continued support and wish you all the best in the coming year. Here&amp;#8217;s to another outstanding and productive year in 2015!&lt;/strong&gt;&lt;/p&gt;
											&lt;/div&gt;</summary></entry><entry><title>Webinar Recording: What’s New in TeamCity 9</title><link href="http://www.ciandcd.com/webinar-recording-whats-new-in-teamcity-9.html" rel="alternate"></link><updated>2015-06-27T03:42:17+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:webinar-recording-whats-new-in-teamcity-9.html</id><summary type="html">From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/26/webinar-recording-whats-new-in-teamcity-9/"&gt;http://blog.jetbrains.com/blog/2015/01/26/webinar-recording-whats-new-in-teamcity-9/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;The recording of our recent webinar with Wes Higbee, &lt;strong&gt;What&amp;#8217;s New in TeamCity 9&lt;/strong&gt;,&amp;#160;is now available on &lt;a href="http://youtu.be/q62fHl6lrxY"&gt;JetBrains YouTube Channel&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this webinar, Wes goes over the new features of TeamCity 9, namely: rearranging projects with Project Import; storing settings in VCS; creating and editing Custom Charts; running builds in Cloud Agents; as well as some other improvements.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Below are a selection of some of the most frequently asked questions.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h2&gt;&amp;#160;Versioned Settings:&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;When is this feature going to be available with Perforce?&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;&lt;/strong&gt;A:&amp;#160;We&amp;#8217;re considering support for Subversion and Perforce in TeamCity 9.1, but can&amp;#8217;t make any guarantees at this point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;What about TFS?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;TFS might be supported in the future but after Subversion and Perforce.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;Given your VCS support priorities for new features, &amp;#160;are Git, Mercurial and TFS your recommended VCS combinations with TeamCity?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;Apart from storing settings in VCS, Git, Mercurial, Subversion and Perforce, they are all supported greatly with TFS catching up. CVS, Vault and ClearCase support can be a bit limited.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;How does TeamCtiy handle it if somebody corrupts the configuration in the repository?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;If there are errors while applying changes then TeamCity will not change project settings and will show an error.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;Is it possible to use branches, e.g. to test a change in the build configuration before making it productive?&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;&lt;/strong&gt;A: Not yet, but we definitely want to add this feature.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;How does the VCS know which branch to use?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;It uses default branch specified in VCS root.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;If you want to revert to an earlier version, you need to find the desired version from within the version control system. &amp;#160;That is, there&amp;#8217;s no GUI way to see the previous version from TeamCity perspective?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;There is a changelog tab where you can see all the changes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;What about parameters? Are they synced too? If not, the new features could replace templates, couldn&amp;#8217;t they?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;All the settings are synced form the VCS as if you edit the settings right in the TeamCity data directory (or change them in UI).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: If a have sync on the root project, are all sub-projects synced too? Is it recommended to have VCS for the sub projects, or a VCS for the root project only? Or are both recommended?&lt;/strong&gt;&lt;br&gt;
A: By default sub projects will be placed into the same version control. If you don&amp;#8217;t want it for some projects, you can disable synchronization in them.&lt;/p&gt;
&lt;h2&gt;Project Import&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;Can I import a TC8 backup in TC9? It would make testing easier &lt;img src="http://blog.jetbrains.com/wp-includes/images/smilies/icon_smile.gif" alt=":)" class="wp-smiley"&gt; &lt;/strong&gt;&lt;br&gt;
A:&amp;#160;No, both servers should have the same version. 9.0 and 9.0.x are compatible, but 8.1 and 9.0 not.&lt;/p&gt;
&lt;h2&gt;Cloud Agents&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;How does that work out with the licensing system? I guess the number of agents licensed its the hard limit of active agents, including from the cloud?&lt;/strong&gt;&lt;br&gt;
A: Yes. The total number of agents (real and virtual) connected at any given time should not exceed the total agent licenses limit. When there are enough agent licences, TeamCity automatically authorizes new cloud agents and unauthorizes the stopped ones.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: How do we create the VM image?Is a build image template available for the Azure VM image?&lt;/strong&gt;&lt;br&gt;
A: There are no templates with TeamCity agents for now&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Can we configure the &amp;#8220;on-demand&amp;#8221; agents to use the same VM with more than one agent, until that max out? i.e. 3 agents per Azure VM.&lt;/strong&gt;&lt;br&gt;
A: TeamCity assumes there is a single agent per instance. The recommended setup is to have a single agent per machine.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Can the on-demand agents be used with on-premise vCenter?&lt;/strong&gt;&lt;br&gt;
A: Yes we have &lt;a href="http://blog.jetbrains.com/teamcity/2014/12/teamcity-vmware-vsphere-plugin/"&gt;vSphere plugin&lt;/a&gt; doing the same.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Does the agent spun up hang around for a while or is it immediately removed?&lt;/strong&gt;&lt;br&gt;
A: There is an idle timeout setting to shutdown the agent instance after. When stopped, the agent is deleted from TeamCity list of agents.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: EC2 cloud agents auto-shutdown policy is not the best it could be meaning that it doesn&amp;#8217;t take into account that you always get charged for an hour of usage of an EC2 instance. Any plans to improve this?&lt;/strong&gt;&lt;br&gt;
A: Yes, we do have plans to adjust the shut down to the hour limit. You are welcome to vote for &lt;a href="https://youtrack.jetbrains.com/issue/TW-9680"&gt;https://youtrack.jetbrains.com/issue/TW-9680&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Custom Charts&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Q: Is it possible to have time instead of build number on the X axis?&lt;/strong&gt;&lt;br&gt;
A: No, this is not possible&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: I have a configuration that has different snapshot dependencies, is there any way to show the build time from beginning to end, meaning when the first dependency run to the end?&lt;/strong&gt;&lt;br&gt;
A: No, statistics charts operate per build. Theoretically you can calculate this time and report it as statistic value in the last build of the chain.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Can you export the stats data?&lt;/strong&gt;&lt;br&gt;
A: Yes, there is a &amp;#8220;download&amp;#8221; action on the chart. Also available via REST API.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Does TeamCity have possibility to show charts with time that took to run every test?&lt;/strong&gt;&lt;br&gt;
A: On the build&amp;#8217;s Tests tab, you can see the duration chart for each test. As well on the Test history page.&lt;/p&gt;
&lt;img class="alignleft  wp-image-2363" alt="Wes McClure" src="http://blog.jetbrains.com/teamcity/files/2015/01/Wes_sq_small.jpg" width="190" height="190"&gt;&lt;strong&gt;&lt;a title="Follow Wes McClure on Twitter" href="https://twitter.com/g0t4" target="_blank"&gt;Wes Higbee&lt;/a&gt;&lt;/strong&gt;&amp;#160;is passionate about helping companies achieve remarkable results with technology and software. He&amp;#8217;s had extensive experience developing software and working with teams to improve how software is developed to meet business objectives. Wes launched &lt;strong&gt;&lt;a title="Full City Tech Co." href="http://www.fullcitytechnology.com/" target="_blank"&gt;Full City Tech&lt;/a&gt;&lt;/strong&gt; to leverage his expertise to help companies rapidly deliver high quality software to delight customers. He has a strong background in using Continuous Integration with TeamCity to bring quality to the table.&lt;p&gt;is passionate about helping companies achieve remarkable results with technology and software. He&amp;#8217;s had extensive experience developing software and working with teams to improve how software is developed to meet business objectives. Wes launchedto leverage his expertise to help companies rapidly deliver high quality software to delight customers. He has a strong background in using Continuous Integration with TeamCity to bring quality to the table.&lt;/p&gt;&lt;p&gt;Follow TeamCity updates on our &lt;a title="TeamCity Blog" href="http://blog.jetbrains.com/teamcity/" target="_blank"&gt;blog&lt;/a&gt;, Twitter &lt;a title="Follow TeamCity on Twitter" href="https://twitter.com/teamcity" target="_blank"&gt;@TeamCity&lt;/a&gt;, and our &lt;a title="TeamCity Product Pages" href="https://www.jetbrains.com/teamcity/" target="_blank"&gt;product pages&lt;/a&gt;.&lt;/p&gt;
											&lt;/div&gt;</summary></entry><entry><title>Webinar Recording: Reactive Stream Processing with Akka Streams</title><link href="http://www.ciandcd.com/webinar-recording-reactive-stream-processing-with-akka-streams.html" rel="alternate"></link><updated>2015-06-27T03:42:15+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:webinar-recording-reactive-stream-processing-with-akka-streams.html</id><summary type="html">From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/29/webinar-recording-reactive-stream-processing-with-akka-streams/"&gt;http://blog.jetbrains.com/blog/2015/01/29/webinar-recording-reactive-stream-processing-with-akka-streams/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;On Tuesday we had the pleasure to host a webinar together with Typesafe where Konrad Malawski, a Scala enthusiast who works on the Akka toolkit, gave a very comprehensive overview of the &lt;a href="http://www.reactive-streams.org/"&gt;Reactive Streams&lt;/a&gt; specification and one of its implementations &amp;#8212;&amp;#160;&lt;a href="http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala.html"&gt;Akka Streams&lt;/a&gt;.&amp;#160;The slides from Konrad&amp;#8217;s presentation can be found at &lt;a href="http://www.slideshare.net/ktoso/reactive-stream-processing-with-akka-streams"&gt;SlideShare&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;About the presenter&lt;/strong&gt;&lt;/p&gt;
&lt;img class="alignleft size-full wp-image-2363" alt="Konrad Malawski" src="http://blog.jetbrains.com/idea/files/2015/01/rsz_115271243730_1368918237_o.jpg" width="110" height="110"&gt;&lt;strong&gt;Konrad Malawski&lt;/strong&gt; is a late-night passionate dev living by the motto, &amp;#8220;Life is Study!&amp;#8221;, hacking on the Akka toolkit at Typesafe. While working on Akka Streams he also implemented the Reactive Streams specifications Technology Compatibility Kit. You can follow him on Twitter &amp;#8211; &lt;a&gt;&lt;/a&gt;&lt;p&gt;is a late-night passionate dev living by the motto, &amp;#8220;Life is Study!&amp;#8221;, hacking on the Akka toolkit at Typesafe. While working on Akka Streams he also implemented the Reactive Streams specifications Technology Compatibility Kit. You can follow him on Twitter &amp;#8211; &lt;a href="https://twitter.com/ktosopl"&gt;@ktosopl&lt;/a&gt; &lt;/p&gt;&lt;p&gt;Develop with Pleasure!&lt;/p&gt;
											&lt;/div&gt;</summary></entry><entry><title>IntelliJ IDEA and WebStorm: InfoWorld’s 2015 Technology of the Year Award Winners</title><link href="http://www.ciandcd.com/intellij-idea-and-webstorm-infoworlds-2015-technology-of-the-year-award-winners.html" rel="alternate"></link><updated>2015-06-27T03:41:12+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:intellij-idea-and-webstorm-infoworlds-2015-technology-of-the-year-award-winners.html</id><summary type="html">From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/30/intellij-idea-and-webstorm-infoworlds-2015-technology-of-the-year-award-winners/"&gt;http://blog.jetbrains.com/blog/2015/01/30/intellij-idea-and-webstorm-infoworlds-2015-technology-of-the-year-award-winners/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;On January 26th, 2015, &lt;strong&gt;&lt;a title="InfoWorld Announces the 2015 Technology of the Year Award Recipients" href="http://www.idgenterprise.com/press/infoworld-announces-the-2015-technology-of-the-year-award-recipients" target="_blank"&gt;InfoWorld announced their 2015 Technology of the Year award recipients&lt;/a&gt;&lt;/strong&gt;. In total there were 32 winners representing the best of cloud, data, hardware and software applications.&lt;/p&gt;
&lt;p&gt;For the &lt;strong&gt;second year in a row WebStorm is a winner&lt;/strong&gt; and &lt;strong&gt;IntelliJ IDEA returns to the list in 2015&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;&lt;img class="wp-image-6917 aligncenter" alt="InfoWorld 2015 Technology of the Year Award" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/InfoWorld_TOY_Logo_2015.png" width="383" height="287"&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;WebStorm&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The WebStorm review by Martin Heller, InfoWorld Test Center Editor, highlights the core features that makes WebStorm &amp;#8220;more than an editor&amp;#8221; such as: built-in code inspections and code quality tools, Node.js and JavaScript debugger and tracer, Live edit, and integration with the testing tools.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;IntelliJ IDEA&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Just last month IntelliJ IDEA 14 picked up the&amp;#160;&lt;strong&gt;&lt;a title="Jolt Awards 2015: Coding Tools" href="http://www.drdobbs.com/joltawards/jolt-awards-2015-coding-tools/240169420?pgno=6" target="_blank"&gt;2015 Jolt Productivity Award for Coding Tools&lt;/a&gt;&lt;/strong&gt; and now InfoWorld&amp;#8217;s 2015 Technology of the Year. What a great ending to 2014 and start to the new year!&lt;/p&gt;
&lt;p&gt;Here is part of what Rick Grehan had to say in his review.&lt;/p&gt;
&lt;p&gt;&amp;#8220;Granted, we wish the Community edition were equipped with the sorts of J2EE development tools found only in the Ultimate edition: database tools, support for frameworks such as JPA and Hibernate, deployment tools for application servers like JBoss AS, WildFly, and Tomcat. Nevertheless, the Community edition makes a fine Java application development platform that also gives you Android tools, as well as support for other JVM languages like Groovy, Clojure, and Scala (the last two via free plug-ins). Whichever version of IntelliJ IDEA you use, you&amp;#8217;ll find a rich array of tools designed to simplify otherwise tedious development chores.&amp;#8221;&lt;/p&gt;
&lt;p&gt;Read more about WebStorm (slide 15), IntelliJ IDEA (slide 16) and the other winners in &lt;strong&gt;&lt;a title="InfoWorld&amp;#x27;s 2015 Technology of the Year Award winners" href="http://www.infoworld.com/article/2871935/application-development/infoworlds-2015-technology-of-the-year-award-winners.html" target="_blank"&gt;InfoWorld&amp;#8217;s 2015 Technology of the Year Award slide show&lt;/a&gt;&lt;/strong&gt;.&amp;#160;&lt;strong&gt;&lt;a title="InfoWorld&amp;#x27;s 2015 Technology of the Year Award winners" href="http://www.infoworld.com/article/2871935/application-development/infoworlds-2015-technology-of-the-year-award-winners.html" target="_blank"&gt;&lt;br&gt;
&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
											&lt;/div&gt;</summary></entry><entry><title>JetBrains Night in Munich Recap, Raffle Winners and Recording</title><link href="http://www.ciandcd.com/jetbrains-night-in-munich-recap-raffle-winners-and-recording.html" rel="alternate"></link><updated>2015-06-27T03:38:04+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:jetbrains-night-in-munich-recap-raffle-winners-and-recording.html</id><summary type="html">From:&lt;a href="http://blog.jetbrains.com/blog/2015/04/29/jetbrains-night-in-munich-recap-raffle-winners-and-recording/"&gt;http://blog.jetbrains.com/blog/2015/04/29/jetbrains-night-in-munich-recap-raffle-winners-and-recording/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;In March 2015, we announced an evening event at our JetBrains office in Munich where we would show our guests how to Use ReSharper Effectively, and Perform Exploratory Code Reviews with Upsource. &lt;strong&gt;The level of interest was so great that we decided to hold an additional night to accommodate the volume of demand.&lt;/strong&gt; We could have filled a much larger venue, but we wanted to provide an opportunity to mingle with the team in a relaxed informal atmosphere. In hindsight, this was a good decision.&lt;/p&gt;
&lt;p&gt;Over two nights, March 24th and 25th, &lt;strong&gt;120 participants&lt;/strong&gt; gathered at JetBrains office to see in action &lt;strong&gt;&lt;a title="Repository Browser and Code Review Tool" href="https://www.jetbrains.com/upsource/" target="_blank"&gt;Upsource&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a title="Why Prefer ReSharper Ultimate" href="https://www.jetbrains.com/dotnet/" target="_blank"&gt;ReSharper Ultimate&lt;/a&gt;&lt;/strong&gt; (ReSharper, dotTrace, dotMemory and dotCover). The feedback that we received on location and through a follow-up survey were overwhelmingly positive, so much so that we are &lt;strong&gt;currently planning to extend the same concept with 3 hour in-depth workshops&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-7009" alt="JetBrains Night in Munich" src="http://blog.jetbrains.com/wp-content/uploads/2015/04/CA8yHBQUcAAQRJH.jpg" width="599" height="337"&gt;&lt;/p&gt;
&lt;p&gt;JetBrains, and our Munich team in particular, would like to thank all of the participants for their time, great conversations and overall positive sentiment that contributed to making the evenings successful. As promised, today we are announcing the &lt;strong&gt;winners of our free personal license raffle&lt;/strong&gt;, along with their product of choice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maik Heller&amp;#160;&amp;#8211; dotCover&lt;/li&gt;
&lt;li&gt;Michael Baur&amp;#160;&amp;#8211; IntelliJ IDEA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lastly, we would like to share the recorded session featuring Matt Ellis (&lt;a title="Follow Matt Ellis on Twitter" href="https://twitter.com/citizenmatt" target="_blank"&gt;@citizenmatt&lt;/a&gt;), Using ReSharper Effectively. Enjoy the video and we hope to meet you at an upcoming event near you!&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Develop with Pleasure!&lt;/p&gt;
&lt;p&gt;- The JetBrains Team&lt;/p&gt;
											&lt;/div&gt;</summary></entry><entry><title>Stopping support for Java</title><link href="http://www.ciandcd.com/stopping-support-for-java.html" rel="alternate"></link><updated>2015-06-27T03:36:32+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:stopping-support-for-java.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2014/07/09/stopping-support-for-java-jdk-6.html"&gt;http://www.go.cd/2014/07/09/stopping-support-for-java-jdk-6.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;There was a &lt;a href="http://support.thoughtworks.com/entries/23692466-Upgrade-to-Java-7-recommended"&gt;recommendation&lt;/a&gt;, in April 2013, that all users move their Go Server and Go Agent installations to Java 7. Oracle and OpenJDK no longer support Java 6. So it is time for Go to stop supporting it. 14.2.0 will be last Go release which will work with Java 6. Any new Go release beyond 14.2.0 might not work with Java 6.  &lt;/p&gt;

&lt;p&gt;If you have not already moved to Java 7, we request you to do so. Should you face any issues please do write to the &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;community mailing list&lt;/a&gt;. &lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Continuous Delivery with Go</title><link href="http://www.ciandcd.com/continuous-delivery-with-go.html" rel="alternate"></link><updated>2015-06-27T03:36:31+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:continuous-delivery-with-go.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2014/08/07/go-webinar-recording.html"&gt;http://www.go.cd/2014/08/07/go-webinar-recording.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Every couple weeks ThoughtWorks hosts learning sessions for people who want more information about continuous delivery with Go. This is a recording of the session from 7 August, 2014&lt;/p&gt;



&lt;/div&gt;</summary></entry><entry><title>Sample Go CD Virtualbox based environment</title><link href="http://www.ciandcd.com/sample-go-cd-virtualbox-based-environment.html" rel="alternate"></link><updated>2015-06-27T03:36:28+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:sample-go-cd-virtualbox-based-environment.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2014/09/09/Go-Sample-Virtualbox.html"&gt;http://www.go.cd/2014/09/09/Go-Sample-Virtualbox.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;If you're interested in checking out Go but don't want to spend the time automating your
own system, this might be a great option for you.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit on 11 November, 2014&lt;/strong&gt; - This box has been updated to Go version 14.3. For information about
what's new in this release please see &lt;a href="http://www.go.cd/releases/"&gt;http://www.go.cd/releases/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We've created an environment using Vagrant and Virtualbox. Once it's up, you'll have a full
Go installation including several example pipleines. &lt;/p&gt;

&lt;h3&gt;System Requirements&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In order to run this you'll need &lt;a href="https://www.virtualbox.org/"&gt;Virtualbox&lt;/a&gt; 
and &lt;a href="https://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;.&lt;/strong&gt; Both of these are available for most operating 
systems.&lt;/p&gt;

&lt;h3&gt;Using the box&lt;/h3&gt;

&lt;p&gt;To get started, open a command prompt in an empty directory and type...&lt;/p&gt;

&lt;blockquote&gt;
vagrant init gocd/gocd-demo
&lt;/blockquote&gt;

&lt;p&gt;This will create a file called Vagrantfile in your current directory. &lt;/p&gt;

&lt;p&gt;Next, type...&lt;/p&gt;

&lt;blockquote&gt;
vagrant up
&lt;/blockquote&gt;

&lt;p&gt;Completion of this (especially the first time) will take quite a while, depending on your
bandwidth. Vagrant will be downloading the full box image (almost 1.4GB) from Vagrantcloud 
while you wait.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you have an existing Go installation on the same machine as this virtual machine
you may get a port conflict. Vagrant will automatically map to a new port which will be 
shown in the startup messages. &lt;/p&gt;

&lt;p&gt;After a few minutes, you should be able to navigate to http://localhost:8153/ on your local
machine and see the following...&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/sample-virtualbox/pipelines.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;These pipelines are all related, as shown in the following value stream map screenshot...&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/sample-virtualbox/vsm.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;Feel free to play around with the installation and see how everything works. You can always
reset the box to it's orginal state if you need to!&lt;/p&gt;

&lt;h3&gt;What's on the machine?&lt;/h3&gt;

&lt;p&gt;The box will be updated as new things come out, but as of this writing...&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Go 14.3 Server&lt;/li&gt;
&lt;li&gt;Go 14.3 Agent&lt;/li&gt;
&lt;li&gt;3 very small PHP applications&lt;/li&gt;
&lt;li&gt;Basic Capistrano deployment scripts&lt;/li&gt;
&lt;li&gt;Local Git repo using Gitolite to manage permissions&lt;/li&gt;
&lt;li&gt;A couple simple phpunit tests&lt;/li&gt;
&lt;li&gt;A couple simple watir scripts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of the code is on the Virtualbox machine at /home/vagrant/projects. The easiest way
to access this is to type 'vagrant ssh' at the command prompt in the same place you 
started the machine.&lt;/p&gt;

&lt;p&gt;The hope is that using this box you can see how real applications (even if they are small)
are built, tested and deployed with Go. &lt;/p&gt;

&lt;p&gt;As always, Go questions can be asked at &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;https://groups.google.com/forum/#!forum/go-cd&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Distributed Test Execution with Go + TLB</title><link href="http://www.ciandcd.com/distributed-test-execution-with-go-tlb.html" rel="alternate"></link><updated>2015-06-27T03:36:27+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:distributed-test-execution-with-go-tlb.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2014/10/09/Distrubuted-Test-Execution.html"&gt;http://www.go.cd/2014/10/09/Distrubuted-Test-Execution.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Writing tests has finally become the norm. Consequently, running tests for every commit is central to &amp;amp; the most time consuming activity in any CI/CD setup. In a decent-sized production quality project you tend to have thousands of tests. That means the cycle time, i.e. the time it takes for a commit to reach deployable state (after running all unit, integration &amp;amp; functional tests), keeps growing.&lt;/p&gt;

&lt;p&gt;It gets harder when teams follow XP related practices like "small commits, frequent commits" since it causes parallel builds &amp;amp; resource starvation.&lt;/p&gt;

&lt;p&gt;One such example is Go's codebase. Just the "Common" &amp;amp; "Server" components of Go which comprises of unit &amp;amp; integration tests, together has ~6000 tests which will take about ~5 hours if run serially! The functional test suite is about 260+ tests with combined runtime of ~15 hours. That's close to a day &amp;amp; we haven't even run everything for a single commit!&lt;/p&gt;

&lt;p&gt;Note that the number of tests is so huge that just putting in a powerful box &amp;amp; running test in parallel will not bring it down to acceptable limits. Also, a large number of other problems surface if you start running tests in parallel on same box (without sandboxed environment) like concurrency issues etc.&lt;/p&gt;

&lt;h2&gt;Solution [Go + TLB]&lt;/h2&gt;

&lt;p&gt;Go improves the cycle time of its own build by making test execution faster, distributing it across many agents (machines). After this "Common" + "Server" takes 20 minutes. All functional tests run in 45 minutes. Thats close to an hour! Still not ideal (a few minutes - constrained by resource availability), but better. :)&lt;/p&gt;

&lt;h3&gt;Test Load Balancer (TLB)&lt;/h3&gt;

&lt;p&gt;&lt;a href="http://test-load-balancer.github.io"&gt;TLB&lt;/a&gt; is an open-source library which provides the ability to break up a test suite into pieces and run a part. It guarantees 'Mutual Exclusion' &amp;amp; 'Collective Exhaustion' properties that are essential to reliably running tests in distributed fashion.&lt;/p&gt;

&lt;p&gt;TLB's strength lies in intelligent test distribution which is based on time, i.e. the tests will be distributed based on time they take to execute, making the jobs close to equal runs which leads to better resource utilization. It falls back on count based splitting if test times are not available. It also runs tests in 'Failed First' order, so if a test has failed in previous run it will be run before other tests which means faster feedback.&lt;/p&gt;

&lt;p&gt;Note: As of this writing, TLB integrates with JUnit (through Ant, Maven &amp;amp; Buildr), RSpec (through Rake), Cucumber (through Rake), Twist (through Ant &amp;amp; Buildr).&lt;/p&gt;

&lt;h4&gt;Quick Setup&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://code.google.com/p/tlb/downloads/detail?name=tlb-complete-0.3.2.tar.gz&amp;amp;can=2&amp;amp;q="&gt;Download&lt;/a&gt; TLB&lt;/p&gt;

&lt;p&gt;Unzip &lt;code&gt;tlb-complete-0.3.2.tar.gz&lt;/code&gt; to &lt;code&gt;tlb-complete-0.3.2&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sh"&gt;&lt;p class="nv"&gt;$ &lt;/p&gt;&lt;p class="nb"&gt;cd &lt;/p&gt;tlb-complete-0.3.2/server
&lt;p class="nv"&gt;$ &lt;/p&gt;chmod +x server.sh
&lt;p class="nv"&gt;$ &lt;/p&gt;./server.sh start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This should start server at &lt;code&gt;http://host-ip-address:7019&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Resources:&lt;/p&gt;

 

&lt;h3&gt;Go&lt;/h3&gt;

&lt;p&gt;&lt;a href="http://www.go.cd/"&gt;Go&lt;/a&gt; is an open-source CI/CD tool. Its well known for its powerful modelling, tracing &amp;amp; visualization capabilities.&lt;/p&gt;

&lt;p&gt;While TLB is doing all the distribution, Go does what it does best - orchestrate the parallel execution. &lt;/p&gt;

&lt;h4&gt;Run 'X' instances&lt;/h4&gt;

&lt;p&gt;Starting release 14.3 you can spawn 'x' instances of a job. So if you want to distribute your tests across 10 machines you just need to set &lt;code&gt;run instance count&lt;/code&gt; to 10 &amp;amp; Go will spawn 10 instances of the job when scheduling.&lt;/p&gt;

&lt;h4&gt;Sample Configuration&lt;/h4&gt;

&lt;p&gt;Setup a pipeline with material (SCM) that contains your tests.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/1.png"&gt;&lt;/p&gt;

&lt;p&gt;Setup Job to spawn required number of instances (run instance count).&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/3.png"&gt;&lt;/p&gt;

&lt;p&gt;Setup TLB related environment variables at Environment / Pipeline / Stage / Job level.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/2.png"&gt;&lt;/p&gt;

&lt;p&gt;Setup the task to consume &lt;code&gt;GO_PIPELINE_NAME&lt;/code&gt;, &lt;code&gt;GO_STAGE_NAME&lt;/code&gt;, &lt;code&gt;GO_PIPELINE_COUNTER&lt;/code&gt;, &lt;code&gt;GO_STAGE_COUNTER&lt;/code&gt;, &lt;code&gt;GO_JOB_RUN_INDEX&lt;/code&gt; &amp;amp; &lt;code&gt;GO_JOB_RUN_COUNT&lt;/code&gt; environment variables that Go exposes.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/4.png"&gt;&lt;/p&gt;

&lt;p&gt;Upload junit xmls as test artifacts.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/4-2.png"&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sample Pipeline Configuration&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-xml"&gt;    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"maven-project"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;git&lt;/p&gt; &lt;p class="na"&gt;url=&lt;/p&gt;&lt;p class="s"&gt;"https://github.com/test-load-balancer/sample_projects.git"&lt;/p&gt; &lt;p class="na"&gt;dest=&lt;/p&gt;&lt;p class="s"&gt;"sample_projects"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;stage&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"unit-tests"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;jobs&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;job&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"test-split"&lt;/p&gt; &lt;p class="na"&gt;runInstanceCount=&lt;/p&gt;&lt;p class="s"&gt;"3"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;environmentvariables&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_BASE_URL"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;http://localhost:7019&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_TMP_DIR"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;/tmp&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_JOB_NAME"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;${GO_PIPELINE_NAME}-${GO_STAGE_NAME}-test-split&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_JOB_VERSION"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;${GO_PIPELINE_COUNTER}-${GO_STAGE_COUNTER}&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_PARTITION_NUMBER"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;${GO_JOB_RUN_INDEX}&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_TOTAL_PARTITIONS"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;${GO_JOB_RUN_COUNT}&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/environmentvariables&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;tasks&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"mvn"&lt;/p&gt; &lt;p class="na"&gt;workingdir=&lt;/p&gt;&lt;p class="s"&gt;"sample_projects/maven_junit"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;clean&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;install&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;-DskipTests&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;runif&lt;/p&gt; &lt;p class="na"&gt;status=&lt;/p&gt;&lt;p class="s"&gt;"passed"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/exec&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"mvn"&lt;/p&gt; &lt;p class="na"&gt;workingdir=&lt;/p&gt;&lt;p class="s"&gt;"sample_projects/maven_junit"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;clean&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;test&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;-DskipTests&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;-Drun.tests.using.tlb=true&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;runif&lt;/p&gt; &lt;p class="na"&gt;status=&lt;/p&gt;&lt;p class="s"&gt;"passed"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/exec&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/tasks&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;artifacts&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;test&lt;/p&gt; &lt;p class="na"&gt;src=&lt;/p&gt;&lt;p class="s"&gt;"sample_projects/maven_junit/target/reports/*.xml"&lt;/p&gt; &lt;p class="na"&gt;dest=&lt;/p&gt;&lt;p class="s"&gt;"test-reports"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/artifacts&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;/job&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/jobs&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/stage&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Other features that helps with Test Parallelization&lt;/h3&gt;

&lt;h4&gt;Wait for all jobs to finish&lt;/h4&gt;

&lt;p&gt;Go's modelling capability gives it the ability to run jobs in parallel but wait for all of them to finish before the next Stage / downstream Pipelines are triggered.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/6.png"&gt;&lt;/p&gt;

&lt;h4&gt;Stop the downstream flow&lt;/h4&gt;

&lt;p&gt;If any of the tests (and as a result the Job running the test) fails, the Stage is considered as failed. This causes the flow to stop as expected.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/5.png"&gt;&lt;/p&gt;

&lt;h4&gt;Consolidated Test Report&lt;/h4&gt;

&lt;p&gt;Once all the Jobs are done running, Go consolidates test reports &amp;amp; shows the result at stage level for easy consumption.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/7.png"&gt;&lt;/p&gt;

&lt;h4&gt;Drill down&lt;/h4&gt;

&lt;p&gt;You can drill down at job level to know more information like 'test count', 'console output' for the Job (test) etc.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/8.png"&gt;
&lt;img src="/images/blog/run-x-instance/10.png"&gt;
&lt;img src="/images/blog/run-x-instance/9.png"&gt;&lt;/p&gt;

&lt;h4&gt;Partition re-run&lt;/h4&gt;

&lt;p&gt;Go also provides ability to re-run a Job of a stage. This provides ability to run the partition that could have failed due to flaky test etc. The best part is, TLB runs the exact tests that it ran the last time making sure no test is missed out!&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/11-1.png"&gt;
&lt;img src="/images/blog/run-x-instance/11-2.png"&gt;&lt;/p&gt;

&lt;h4&gt;TLB Correctness Check&lt;/h4&gt;

&lt;p&gt;TLB provides an ability to check correctness, i.e. it will make sure all tests were run. You can configure to run this correctness check once all partitions are done executing, may be in next stage / pipeline.&lt;/p&gt;

&lt;h3&gt;Power of dynamic splitting&lt;/h3&gt;

&lt;p&gt;Go's one knob control to amount of parallelization means that when the number of tests increase/decrease all you will need to do is change the &lt;code&gt;run instance count&lt;/code&gt; based on number of tests &amp;amp; resource availability &amp;amp; you are done!&lt;/p&gt;

&lt;p&gt;--&lt;/p&gt;

&lt;p&gt;As always, Go questions can be asked at &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;go-cd&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Go 14.3 Released</title><link href="http://www.ciandcd.com/go-143-released.html" rel="alternate"></link><updated>2015-06-27T03:36:26+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:go-143-released.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2014/11/11/Go_14_3_announced.html"&gt;http://www.go.cd/2014/11/11/Go_14_3_announced.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Today we released Go 14.3&lt;/p&gt;

&lt;p&gt;You can download it from &lt;a href="http://www.go.cd/download/"&gt;here&lt;/a&gt;. Take a look at &lt;a href="http://www.go.cd/releases/#latest"&gt;release notes&lt;/a&gt; to see details. &lt;/p&gt;

&lt;p&gt;This release saw lot of contributions from the community. A huge callout to the following contributors (not in any particular order) for their outstanding contributions : &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/lcs777"&gt;@lcs777&lt;/a&gt;, &lt;a href="https://github.com/ciotlosm"&gt;@ciotlosm&lt;/a&gt;, &lt;a href="https://github.com/tusharm"&gt;@tusharm&lt;/a&gt;, &lt;a href="https://github.com/juniorz"&gt;@juniorz&lt;/a&gt;, &lt;a href="https://github.com/RikTyer"&gt;@RikTyer&lt;/a&gt;, &lt;a href="https://github.com/mmb"&gt;@mmb&lt;/a&gt;, &lt;a href="https://github.com/afoster"&gt;@afoster&lt;/a&gt; , &lt;a href="https://github.com/sahilm"&gt;@sahilm&lt;/a&gt;,  &lt;a href="https://github.com/gregoriomelo"&gt;@gregoriomelo&lt;/a&gt;, &lt;a href="https://github.com/greenmoss"&gt;@greenmoss&lt;/a&gt; , &lt;a href="https://github.com/dvarchev"&gt;@dvarchev&lt;/a&gt; and Temmert&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(We have tried to be as accurate as possible. Sincere apologies if we missed mentioning anyone above)&lt;/p&gt;

&lt;p&gt;We would also like to thank people who reported issues/feature requests and participated in various discussions. That list is too big to be mentioned here, but please know that all the time and energy spent by everyone in improvising Go is very much appreciated.&lt;/p&gt;

&lt;p&gt;Thanks once again!&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Issue with uploading compressed artifacts in Go 14.3.0</title><link href="http://www.ciandcd.com/issue-with-uploading-compressed-artifacts-in-go-1430.html" rel="alternate"></link><updated>2015-06-27T03:35:53+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:issue-with-uploading-compressed-artifacts-in-go-1430.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2014/11/14/Go_14_3_issue_with_uploading_compressed_artifacts.html"&gt;http://www.go.cd/2014/11/14/Go_14_3_issue_with_uploading_compressed_artifacts.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;There was an &lt;a href="https://github.com/gocd/gocd/issues/703"&gt;issue&lt;/a&gt; reported with respect to artifact uploads in the 14.3.0 release of Go. &lt;/p&gt;

&lt;h3&gt;Issue&lt;/h3&gt;

&lt;p&gt;On Go server running with OpenJDK7, uploading compressed artifacts fails. The operation is reported as success in console-log on job details page but actual artifact does not get uploaded. Please note this does not affect uploading console-log itself or even a simple file as an artifact. This is an issue only with Go v14.3.0. Read further to know if you are affected by this defect.&lt;/p&gt;

&lt;h3&gt;Who does this affect?&lt;/h3&gt;

&lt;p&gt;This defect would affect you only if your Go Server v14.3.0 is run using OpenJDK(jdk or jre) and the agent responsible for artifact upload is using a version of java other than the one used by Go server. &lt;/p&gt;

&lt;p&gt;You are unaffected by this defect if:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;you use Sun/Oracle java to run Go Server&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;you have SunEC extension installed for your OpenJDK [EDIT: on your Go server]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Both your server and agent processes run using OpenJDK (not necessarily the same version) [EDIT: without &lt;a href="http://en.wikipedia.org/wiki/Elliptic_curve_cryptography"&gt;ECC cipher suites&lt;/a&gt;.
As explained in "What caused this?" section, this issue occurs when java on agent supports ECC cipher suites but java on server doesnot. You should definitely run the litmus test to be sure.]&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Litmus test&lt;/h4&gt;

&lt;p&gt;You should run a pipeline which uploads a compressed file as an artifact to ensure you are not affected by this defect. If the artifact shows up on the artifacts tab of the job and can be successfully downloaded, you are safe from the defect.&lt;/p&gt;

&lt;h3&gt;Workaround&lt;/h3&gt;

&lt;p&gt;We are aware that you have been waiting to try your hands on the new APIs and several bug fixes that came out in 14.3.0. 
Fortunately we have a few workarounds available to help you move ahead with the upgrade, meanwhile we would be working on finding the best possible fix for this issue. 
You could go for one of the workarounds listed below:&lt;/p&gt;

&lt;p&gt;Options:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install SunEC extension on your OpenJDK setup. Get sunec.jar and place it under &lt;code&gt;jre/lib/ext/&lt;/code&gt; folder. You must also place libsunec.so in &lt;code&gt;jre/lib/amd64/&lt;/code&gt; folder. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OR&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install Oracle JRE on your Go server and switch to that. 
For Go server running on Windows, this means updating the system level environment variable &lt;code&gt;GO_SERVER_JAVA_HOME&lt;/code&gt; to oracle jre home
For Linux based installations, update &lt;code&gt;/etc/default/go-server&lt;/code&gt; to set &lt;code&gt;JAVA_HOME&lt;/code&gt; to oracle jre home.
For Others, set the value of system level environment variable &lt;code&gt;JAVA_HOME&lt;/code&gt; to oracle jre home.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OR&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install the same version of java as you have on your agent. Update java used by Go server to appropriate value as suggested in the previous option.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At this point restart Go Server. Trigger your affected pipeline to ensure the artifact got uploaded successfully. This should resolve the issue.
If the issue persists even after applying the suggested workaround, do write to the go-cd mailing list reporting the same.&lt;/p&gt;

&lt;h3&gt;What caused this?&lt;/h3&gt;

&lt;p&gt;I cannot speak about this without getting into some technical details. &lt;/p&gt;

&lt;p&gt;As a part of upgrading to Rails v4, we also had to upgrade bouncycastle-bcprov library. Earlier versions of Go used bouncycastle-bcprov v1.40. With that the cipher suites accepted by Go server would always be one of &lt;code&gt;SSL_RSA_WITH_RC4_128_SHA&lt;/code&gt;, &lt;code&gt;SSL_RSA_EXPORT_WITH_RC4_40_MD5&lt;/code&gt; or &lt;code&gt;SSL_RSA_WITH_RC4_128_MD5&lt;/code&gt;.
Go 14.3.0 has moved on to use org.bouncycastle-bcprov v1.47. Bouncycastle v1.46 brought in support for &lt;a href="http://tools.ietf.org/html/rfc4492"&gt;ECC cipher suites&lt;/a&gt;. ECC cipher suites are made available by SunEC extension which is not packaged along with OpenJDK7 by default. 
Go server is run using Jetty which uses bouncycastle crypto package (i.e. bcprov) for the handshake. At this point, instead of agreeing on the expected SSL &amp;amp; RSA based ciphers, one of the ECC ciphers get picked during the agent/server handshake. Jetty6 (yes, we are still using this!) does not work well with the modern cipher suites and causes issues like the one mentioned above. To tackle such scenarios, all supported ciphers suites apart from the three mentioned above are excluded from Jetty. Since, ECC cipher suites were not available on the server, they did not get excluded. However if your JVM has ECC ciphers available (by default or after applying one of the workarounds), Go would ensure they get excluded and make Jetty happy. &lt;/p&gt;

&lt;p&gt;Jetty upgrade has been on the cards for a while, and that would possibly help resolve this. But that is a much involved task and hence works better as a long term solution. We need to evaluate other options as well which could fix the issue in the short term. &lt;/p&gt;

&lt;p&gt;Many thanks to &lt;a href="https://github.com/bormotov"&gt;Vladimir Bormotov&lt;/a&gt; for reporting this issue and allowing us to use his setup to gather the required debug information.&lt;/p&gt;

&lt;p&gt;As always, you could write to &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;go-cd&lt;/a&gt; and &lt;a href="https://groups.google.com/forum/#!forum/go-cd-dev"&gt;go-cd-dev&lt;/a&gt; mailing lists if you have any ideas/feedback/questions.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Go 14.4 Released</title><link href="http://www.ciandcd.com/go-144-released.html" rel="alternate"></link><updated>2015-06-27T03:35:51+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:go-144-released.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2014/12/17/Go_14_4_announced.html"&gt;http://www.go.cd/2014/12/17/Go_14_4_announced.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Today we released Go 14.4&lt;/p&gt;

&lt;p&gt;You can download it from &lt;a href="http://www.go.cd/download/"&gt;here&lt;/a&gt;. Take a look at &lt;a href="http://www.go.cd/releases/#latest"&gt;release notes&lt;/a&gt; to see details. &lt;/p&gt;

&lt;p&gt;Sincere thanks to everyone who contributed to Go in form of features, ideas, issues / feature requests and much more! A special mention goes to &lt;a href="https://github.com/mythgarr"&gt;@mythgarr&lt;/a&gt;, &lt;a href="https://github.com/hammerdr"&gt;@hammerdr&lt;/a&gt; and to the &lt;a href="http://www.pivotal.io/?mkt_tok=3RkMMJWWfF9wsRomrfCcI63Em2iQPJWpsrB0B%2FDC18kX3RUvIL6Wbgfind1SFJk7a8C6XFNJSt1Q5CkVSLnE"&gt;Pivotal&lt;/a&gt; team: &lt;a href="https://github.com/mmb"&gt;@mmb&lt;/a&gt;, &lt;a href="https://github.com/gajwani"&gt;@gajwani&lt;/a&gt; , &lt;a href="https://github.com/fkotsian"&gt;@fkotsian&lt;/a&gt;,  &lt;a href="https://github.com/bsnchan"&gt;@bsnchan&lt;/a&gt; for their active contributions and support.&lt;/p&gt;

&lt;p&gt;Thanks once again!&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Go Plugin Competition</title><link href="http://www.ciandcd.com/go-plugin-competition.html" rel="alternate"></link><updated>2015-06-27T03:35:50+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:go-plugin-competition.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/01/20/Go_plugin_competition.html"&gt;http://www.go.cd/2015/01/20/Go_plugin_competition.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Are you up for the challenge?&lt;/p&gt;

&lt;p&gt;Do you have what it takes to build an awesome Go plugin? Here&amp;#8217;s your chance to put your development skills to the test. ThoughtWorks invites you to the first ever Go plugin challenge. We want you to build a plugin that showcases the best of Go. Have you been playing with an idea on the side or has your organisation developed something really cool that others would love? This is your chance to showcase it and win a prize!
&lt;a href="http://thght.works/1CdY4aq"&gt;Read more...&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Important Dates&lt;/p&gt;

&lt;p&gt;Submission Deadline:
February 20, 2015 at 11:59 PM CST 
(February 21, 2015 at 5:59 AM GMT)&lt;/p&gt;

&lt;p&gt;Notification of Acceptance: 
February 27, 2015&lt;/p&gt;

&lt;p&gt;Results: 
March 10, 2015 &lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>For Go 15.1 upgrade your Java</title><link href="http://www.ciandcd.com/for-go-151-upgrade-your-java.html" rel="alternate"></link><updated>2015-06-27T03:35:17+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:for-go-151-upgrade-your-java.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/04/23/Go_15_1_jdk7_announcement.html"&gt;http://www.go.cd/2015/04/23/Go_15_1_jdk7_announcement.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;GoCD has &lt;a href="http://www.go.cd/2014/07/09/stopping-support-for-java-jdk-6.html"&gt;stopped support JDK 6&lt;/a&gt; for some time now. But we understand that some users were using Java 6, so we continued to support it as long as we could while helping users migrate their Go servers and agents to Java 7.&lt;/p&gt;

&lt;p&gt;Java 6 was declared end-of-life in February 2013, and Java 7 is scheduled to be declared end-of-life soon.&lt;/p&gt;

&lt;p&gt;Starting with the 15.1 release of GoCD, it will only run with Java 7. Users are encouraged to upgrade to the latest release of GoCD with Java 8.&lt;/p&gt;

&lt;p&gt;Starting with the next release, we plan on providing support for Java 8.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Feature Branch Support</title><link href="http://www.ciandcd.com/feature-branch-support.html" rel="alternate"></link><updated>2015-06-27T03:35:16+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:feature-branch-support.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/04/27/Feature-Branch-Support.html"&gt;http://www.go.cd/2015/04/27/Feature-Branch-Support.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Go 15.1 introduced support for writing material repository plugins, to extend the kind of source code material
repositories that Go works with. This resulted in community-driven plugins developed for Go, to implement support for
feature branches, with help from members of Go's core contributors. This blog posts has information specifically about
GitHub Pull Request support.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In this post, the terms Branch and Pull Request are used interchangeably, since a Pull Request is
essentially just a branch.&lt;/p&gt;

&lt;p&gt;As codebases grow and teams start writing more tests, they often hit upon a challenging problem. If they have setup
their build, test and deploy pipelines as a normal team or teams working with trunk-based development would have, then
increasing the number of tests they have results in a longer time to certify a build and deploy to production.&lt;/p&gt;

&lt;p&gt;Here is an example of a Value Stream Map from &lt;a href="https://build.go.cd"&gt;Go CD&lt;/a&gt; (Username: view, Password: password) itself,
where running all the tests and generating installers can take hours:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/mature-ci-cd-setup.png" class="has_border full_size" alt="Figure 1: GoCD - Value Stream Map" id="mature_ci_cd_setup" title="GoCD - Value Stream Map"&gt;
  Figure 1: GoCD - Value Stream Map &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;Due to this, it becomes critical to keep the main Value Stream green all the time. A failed build would mean all other
commits ready to go in have to wait until the failed build is fixed:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/failed-build.png" class="has_border full_size" alt="Figure 2: Failed build stops everything" id="failed_build" title="Failed build stops everything"&gt;
  Figure 2: Failed build stops everything &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;




&lt;p&gt;The root of this problem is a slow build, and sometimes that can be tackled directly. However, with the advent of
short-lived feature branches (aka, Pull Requests in GitHub land), this problem can become worse. Since feature
branches are not regularly verified before merging, merging them could itself be a little risky, and could cause the
build to fail un-necessarily.&lt;/p&gt;

&lt;p&gt;In general, development workflows in organizations has moved to something which looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;Pull Request (GitHub, Gerrit etc.) / Feature Branch =&amp;gt; Code Review =&amp;gt; Merge =&amp;gt; Build
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, whether a feature branch based workflow is the best approach or not is hotly debated (see Martin Fowler's
&lt;a href="http://martinfowler.com/bliki/FeatureBranch.html"&gt;article&lt;/a&gt; on this). Organizations who follow a feature branch based
workflow have been wanting support for it in Go.  Historically, &lt;a href="http://support.thoughtworks.com/entries/22037619-Support-for-feature-branches#view-post-21612654"&gt;Go has advocated against feature
branches&lt;/a&gt; and support
for it has been limited. Go users have come up with some innovative work arounds, like this one from &lt;a href="https://groups.google.com/d/topic/go-cd/veZ5QyySR8k/discussion"&gt;Vision
Critical&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Though the Go core contribution team continues to be wary of long-lived feature branches, short-lived feature branches
create a window for validating changes before they are merged into the main branch. Since the majority of time spent in
a CI/CD setup tends to be in running tests, and failed builds are typically due to test failures, you could run tests on
a proposed change in a feature branch, get feedback about it and fix tests if needed, before merging it into the trunk.
Though this does not always catch integration issues (that depends on what else was merged before this one was), it
allows you to increase the chances of your main Value Stream staying green and in a deployable state for longer.&lt;/p&gt;

&lt;p&gt;A problem with this approach though, is that every change will be tested twice (once on the feature branch and once on
the main branch after the merge) which means the effective time for a commit to reach production could be more, unless
you have more hardware (agents) to run branch builds.&lt;/p&gt;

&lt;h3&gt;The way forward&lt;/h3&gt;

&lt;p&gt;Assuming you have chosen the approach mentioned above, you can now use Go 15.1, with its two new extension points - &lt;a href="http://www.go.cd/documentation/user/15.1.0/extension_points/scm_extension.html"&gt;SCM
end-point&lt;/a&gt; and the &lt;a href="http://www.go.cd/documentation/user/15.1.0/extension_points/notification_extension.html"&gt;Notification
end-point&lt;/a&gt;, to test feature
branches before they are merged.&lt;/p&gt;

&lt;p&gt;To use this with GitHub requires the use of two community-driven and community-supported plugins: &lt;a href="https://github.com/ashwanthkumar/gocd-build-github-pull-requests"&gt;Git Branch Poller
Plugin&lt;/a&gt; and the &lt;a href="https://github.com/srinivasupadhya/gocd-build-status-notifier"&gt;Build Status Notification
Plugin&lt;/a&gt;. The first one is an SCM Material plugin, and is
responsible for polling a configured repository for changes, while the second one is a Notification plugin, which is
responsible for notifying GitHub about the suitability of a Pull Request for merging.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Even though this post specifically mentions GitHub only, plugins have been written to work with plain Git,
Atlassian Stash, Gerrit and more! See the &lt;a href="http://www.go.cd/community/plugins.html#notification-plugins"&gt;Go community plugins
page&lt;/a&gt; for more information.&lt;/p&gt;

&lt;h3&gt;Quick Setup&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Download the &lt;a href="https://github.com/ashwanthkumar/gocd-build-github-pull-requests#user-content-get-started"&gt;Git Branch Poller Plugin&lt;/a&gt; and the &lt;a href="https://github.com/srinivasupadhya/gocd-build-status-notifier#user-content-get-started"&gt;Build Status Notification Plugin&lt;/a&gt;. Place them under &lt;code&gt;&amp;lt;go-server&amp;gt;/plugins/external&lt;/code&gt;. Restart the Go Server.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Verify that the plugins are loaded correctly.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/feature-branch/plugins-loaded.png" class="has_border full_size" alt="Figure 3: Verify Plugins" id="verify_plugins" title="Verify Plugins"&gt;
  Figure 3: Verify Plugins &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Decide which parts of the value stream you want the Pull Requests to run till, and extract a template for those
pipelines, so that you can have a parallel set of pipelines to run against Pull Requests. The need to create a
separate set of pipelines is to make sure that the main build and the branch build never get interleaved, and a branch
build never gets deployed into production, by mistake.&lt;/p&gt;

&lt;p&gt;Your decision should be based on how much of your tests can reasonably be run for every Pull Request, and how far down
the Value Stream can a build containing those changes Go. For some, every test in the system needs to run before it is
deemed merge-able and for some, only unit and integration tests might be enough. It depends.&lt;/p&gt;

&lt;p&gt;Suppose you have a setup of three pipelines like this:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/setup.png" class="full_size" alt="Figure 4: Example setup" id="example_setup" title="Example setup"&gt;
  Figure 4: Example setup &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;and you decide that you want the first two pipelines to run for every Pull Request, you need to change your pipelines
to look like this:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/with_prs.png" class="full_size" alt="Figure 5: Extract templates, create pipelines for PR" id="create_pipelines" title="Extract templates, create pipelines for PR"&gt;
  Figure 5: Extract templates, create pipelines for PR &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;Based on your decision, extract templates and create the new pipelines:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/extract-template.png" class="has_border full_size" alt="Figure 6: Extract template" id="extract_template" title="Extract template"&gt;
  Figure 6: Extract template &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the new pipeline or pipelines that have been setup to run for every Pull Request, change the Git material to use
the GitHub material (this material is provided by the GitHub poller plugin installed earlier):&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/replace-material-1.png" class="has_border full_size" alt="Figure 7: Add GitHub material" id="add_github_material" title="Add GitHub material"&gt;
  Figure 7: Add GitHub material &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;



  &lt;img src="/images/blog/feature-branch/replace-material-2.png" class="has_border full_size" alt="Figure 8: Add GitHub material - Details" id="add_github_material_details" title="Add GitHub material - Details"&gt;
  Figure 8: Add GitHub material - Details &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;Once you have setup the GitHub material for the pipeline, you can remove the Git material from that pipeline.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That's it.&lt;/p&gt;

&lt;h3&gt;Results&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Go will trigger builds for every new Pull Request and for new commits to existing Pull Requests:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/trigger-build.png" class="has_border full_size" alt="Figure 9: PR triggers build" id="pr_triggers_build" title="PR triggers build"&gt;
  Figure 9: PR triggers build &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Go will update Pull Request in GitHub with the build status:&lt;/p&gt;


   
  Figure 10: GitHub PR page gets updated &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;



   
  Figure 11: GitHub PR listing page gets updated &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fan-in and Value Stream Map work as expected:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/vsm.png" class="has_border full_size" alt="Figure 12: Fan-in and VSM work" id="vsm_works" title="Fan-in and VSM work"&gt;
  Figure 12: Fan-in and VSM work &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Shortcomings and known issues:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If multiple branches are updated at once, the plugin provides all of them as changes and Go will not run the pipeline
for every change separately. Go currently combines multiple changes into a single pipeline run (to save time). A
feature allowing &lt;a href="https://github.com/gocd/gocd/pull/939"&gt;"force trigger pipeline for each change"&lt;/a&gt; should be able to
overcome this. This has not yet been accepted into the main GoCD codebase.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If there are multiple commits in a branch, the plugin only returns the top commit as a change. Hence only one change
shows up in the dashboard, value stream, etc. Also, since Go does not know about the other changes you will not be
able to manually trigger a pipeline with the other commits.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The UI is lacking in certain areas: For instance, it is not possible to add an SCM plugin material during pipeline
creation, to associate an existing SCM to a pipeline you will need to edit Config XML etc. These 
will be fixed in upcoming releases.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;References&lt;/h3&gt;

&lt;p&gt;Some discussions on the GoCD mailing lists and on GitHub about this:&lt;/p&gt;

 

&lt;h3&gt;Sample Configuration&lt;/h3&gt;

&lt;p&gt;Here is a part of the configuration used to create the images shown above:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-xml"&gt;  &lt;p class="nt"&gt;&amp;lt;scms&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;scm&lt;/p&gt; &lt;p class="na"&gt;id=&lt;/p&gt;&lt;p class="s"&gt;"b7386c23-71d5-4581-8129-bba5b67638e4"&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-repo"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;pluginConfiguration&lt;/p&gt; &lt;p class="na"&gt;id=&lt;/p&gt;&lt;p class="s"&gt;"github.pr"&lt;/p&gt; &lt;p class="na"&gt;version=&lt;/p&gt;&lt;p class="s"&gt;"1"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;property&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;key&amp;gt;&lt;/p&gt;url&lt;p class="nt"&gt;&amp;lt;/key&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;https://github.com/srinivasupadhya/sample-repo.git&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/scm&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;/scms&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;pipelines&lt;/p&gt; &lt;p class="na"&gt;group=&lt;/p&gt;&lt;p class="s"&gt;"sample-group-master"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline-master"&lt;/p&gt; &lt;p class="na"&gt;template=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;git&lt;/p&gt; &lt;p class="na"&gt;url=&lt;/p&gt;&lt;p class="s"&gt;"https://github.com/srinivasupadhya/sample-repo.git"&lt;/p&gt; &lt;p class="na"&gt;dest=&lt;/p&gt;&lt;p class="s"&gt;"sample-repo"&lt;/p&gt; &lt;p class="na"&gt;materialName=&lt;/p&gt;&lt;p class="s"&gt;"sample-repo"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline-master"&lt;/p&gt; &lt;p class="na"&gt;template=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;pipelineName=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline-master"&lt;/p&gt; &lt;p class="na"&gt;stageName=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-2"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;/pipelines&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;pipelines&lt;/p&gt; &lt;p class="na"&gt;group=&lt;/p&gt;&lt;p class="s"&gt;"sample-group-PR"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline-PR"&lt;/p&gt; &lt;p class="na"&gt;template=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;scm&lt;/p&gt; &lt;p class="na"&gt;ref=&lt;/p&gt;&lt;p class="s"&gt;"b7386c23-71d5-4581-8129-bba5b67638e4"&lt;/p&gt; &lt;p class="na"&gt;dest=&lt;/p&gt;&lt;p class="s"&gt;"sample-repo"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline-PR"&lt;/p&gt; &lt;p class="na"&gt;template=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;pipelineName=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline-PR"&lt;/p&gt; &lt;p class="na"&gt;stageName=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-2"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;/pipelines&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;templates&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;stage&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-1"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;jobs&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;job&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-job-1"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;tasks&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"ls"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/tasks&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;/job&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/jobs&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/stage&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;stage&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-2"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;jobs&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;job&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-job-2"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;tasks&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"ls"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/tasks&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;/job&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/jobs&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/stage&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;stage&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-3"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;jobs&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;job&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-job-3"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;tasks&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"ls"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/tasks&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;/job&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/jobs&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/stage&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;/templates&amp;gt;&lt;/p&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As always, Go questions can be asked on the &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Go 15.1.0 Released</title><link href="http://www.ciandcd.com/go-1510-released.html" rel="alternate"></link><updated>2015-06-27T03:35:14+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:go-1510-released.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/04/29/Go_15_1_announced.html"&gt;http://www.go.cd/2015/04/29/Go_15_1_announced.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;We would like to announce a new release of gocd. Head over to our &lt;a href="http://www.go.cd/download/"&gt;downloads page&lt;/a&gt; to get your hands on the latest and greatest. Read more about what's new in this release from our &lt;a href="http://www.go.cd/releases/#latest"&gt;release notes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Sincere thanks to everyone who contributed to Go in form of features, ideas, issues / feature requests and much more! A special mention goes to &lt;a href="https://github.com/ashwanthkumar"&gt;@ashwanthkumar&lt;/a&gt;, &lt;a href="https://github.com/alexschwartz"&gt;@alexschwartz&lt;/a&gt;, &lt;a href="https://github.com/sachinsudheendra"&gt;@sachinsudheendra&lt;/a&gt;, &lt;a href="https://github.com/pwen"&gt;@pwen&lt;/a&gt;, &lt;a href="https://github.com/pamo"&gt;@pamo&lt;/a&gt;, &lt;a href="https://github.com/bernardn"&gt;@bernardn&lt;/a&gt;, &lt;a href="https://github.com/danielsomerfield"&gt;@danielsomerfield&lt;/a&gt;, &lt;a href="https://github.com/iliasbartolini"&gt;@iliasbartolini&lt;/a&gt; for their active contributions and support.&lt;/p&gt;

&lt;p&gt;Thanks once again!&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Get Started Using Go</title><link href="http://www.ciandcd.com/get-started-using-go.html" rel="alternate"></link><updated>2015-06-27T03:35:13+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:get-started-using-go.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/05/06/Getting-Started-Resources.html"&gt;http://www.go.cd/2015/05/06/Getting-Started-Resources.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Some resources to help get started using Go.&lt;/p&gt;

&lt;h4&gt;Go User Documentation&lt;/h4&gt;

&lt;p&gt;There are a couple sections of the user documentation that can be especially helpful to people new to Go.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.go.cd/documentation/user/current/introduction/concepts_in_go.html"&gt;Concepts in Go&lt;/a&gt; - This covers some of the
basic concepts used in Go. A good understanding of what Pipelines, Stages, Jobs and Tasks are will be very helpful.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.go.cd/documentation/user/current/configuration/managing_a_build_cloud.html"&gt;Managing Agents&lt;/a&gt; - The Go server
produces the user interface for Go, but it doesn't actually run your jobs. Learn how to use Go Agents to "do the work".&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.go.cd/documentation/user/current/configuration/quick_pipeline_setup.html"&gt;Setting up a new Pipeline&lt;/a&gt; See how
to set up your first pipeline&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;&lt;p&gt;
Of course there's a lot more information available as well.&lt;/p&gt;

&lt;h4&gt;Other information online&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;The Go mailing list&lt;/a&gt; - A great place to search for answers to questions
you may have, or of course ask them if they aren't already covered.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://webchat.freenode.net/?channels=gocd"&gt;IRC&lt;/a&gt; - Connect to freenode with your own IRC client or use this web client.
Don't forget to uncheck "auth to services" if you're not planning to login with your preset freenode information.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Live demonstrations&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.thoughtworks.com/products/go-continuous-delivery/resources#Webinars"&gt;Webinars&lt;/a&gt; - ThoughtWorks presents live
webinars every couple weeks so that you can see Go in action. There are also recordings of previous webinars on this blog.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Professional Support&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.thoughtworks.com/products/go-continuous-delivery"&gt;ThoughtWorks&lt;/a&gt; - The first 30 days of professional support
provided by ThoughtWorks is free. You'll get access to a global support team, and tough issues can be escalated directly to
the Go development team.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Alternative Trial Installation&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://registry.hub.docker.com/u/gocd/gocd-server/"&gt;Docker Container&lt;/a&gt; - This is an easy way to see what Go does. As it
says in the description, this is not a production container. You'll also need at least one instance of the &lt;a href="https://registry.hub.docker.com/u/gocd/gocd-agent/"&gt;agent container&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Using Windows PowerShell tasks</title><link href="http://www.ciandcd.com/using-windows-powershell-tasks.html" rel="alternate"></link><updated>2015-06-27T03:35:10+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:using-windows-powershell-tasks.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/06/13/using-windows-powershell-tasks.html"&gt;http://www.go.cd/2015/06/13/using-windows-powershell-tasks.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Some things to be aware of when using Windows PowerShell tasks.&lt;/p&gt;

&lt;h3&gt;Go Agent default installation&lt;/h3&gt;

&lt;p&gt;The &lt;a href="http://www.go.cd/documentation/user/current/installation/installing_go_agent.html"&gt;default&lt;/a&gt; installation of a Go
agent will use a 32-bit JRE unless you indicate otherwise. This JRE is embedded in the Go agent installer.&lt;/p&gt;

&lt;p&gt;If you want to use an alternative JRE (must satisfy Go's JRE requirements) after the initial installation, you can alter
the "wrapper.java.command" key's value in the &lt;code&gt;[InstallDirectory]\config\wrapper-agent.conf&lt;/code&gt; file  to point to a
different JRE. You will then need to restart the Go agent service to start using the alternative JRE.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;[InstallDirectory]&lt;/code&gt; refers to the Go agents installation directory which by default is &lt;code&gt;"C:\Program Files (x86)\Go Agent"&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;Pre-requisites for running PowerShell task commands&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;You can only run on Windows based agents&lt;/li&gt;
&lt;li&gt;You should tag the agents if your are also using linux agents&lt;br&gt;&lt;/li&gt;
&lt;li&gt;You probably want to ensure your agents all have the same version of PowerShell&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;32-bit Go agent&lt;/h4&gt;

&lt;p&gt;If you are running a default Go agent installation then you will be running a 32-bit JRE.&lt;/p&gt;

&lt;p&gt;The 32-bit JRE will try to run PowerShell tasks in the 32-bit version of PowerShell, even if you give the full path to
the 64-bit PowerShell executable in the task. If you need to execute a PowerShell script then you will need to alter the
execution policy as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Open 32-bit version of PowerShell as an administrator: Start -&amp;gt; All Programs -&amp;gt; Accessories -&amp;gt; Windows Powershell -&amp;gt; Windows Powershell (x86) and type:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&lt;p class="c"&gt;# Alter execution policy&lt;/p&gt;
&lt;p class="nb"&gt;set-executionpolicy&lt;/p&gt; &lt;p class="n"&gt;remotesigned&lt;/p&gt; &lt;p class="n"&gt;-force&lt;/p&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will allow you to run local scripts on the Windows Go agent box.&lt;/p&gt;

&lt;h4&gt;64-bit Go agent&lt;/h4&gt;

&lt;p&gt;If you are running a Go agent using a 64-bit JRE, it will run PowerShell tasks in the 64-bit version of PowerShell.&lt;/p&gt;

&lt;p&gt;If you need to execute a PowerShell script, then you will need to alter the execution policy as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Open 64-bit version of PowerShell as an administrator: Start -&amp;gt; All Programs -&amp;gt; Accessories -&amp;gt; Windows Powershell -&amp;gt;
Windows Powershell and type:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&lt;p class="c"&gt;# Alter execution policy&lt;/p&gt;
&lt;p class="nb"&gt;set-executionpolicy&lt;/p&gt; &lt;p class="n"&gt;remotesigned&lt;/p&gt; &lt;p class="n"&gt;-force&lt;/p&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will allow you to run local scripts on the Windows Go agent box.&lt;/p&gt;

&lt;h3&gt;PowerShell task commands&lt;/h3&gt;

&lt;p&gt;You can configure the task as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;command: powershell  
arg: .\run.ps1 arg1value  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This assumes that the &lt;code&gt;run.ps1&lt;/code&gt; script is in the task's working directory.&lt;/p&gt;

&lt;p&gt;If you create the &lt;code&gt;run.ps1&lt;/code&gt; file with the following content you can see details of the execution context in the console log for the pipeline:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&lt;p class="k"&gt;param&lt;/p&gt;
&lt;p class="p"&gt;(&lt;/p&gt;
    &lt;p class="no"&gt;[string]&lt;/p&gt; &lt;p class="nv"&gt;$arg1&lt;/p&gt;
&lt;p class="p"&gt;)&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Script:            "&lt;/p&gt; &lt;p class="nv"&gt;$MyInvocation&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;MyCommand&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;Path&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Pid:               "&lt;/p&gt; &lt;p class="nv"&gt;$pid&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Host.Version:      "&lt;/p&gt; &lt;p class="nv"&gt;$host&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;version&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Is 64-bit process: "&lt;/p&gt; &lt;p class="p"&gt;$(&lt;/p&gt;&lt;p class="no"&gt;[Environment]&lt;/p&gt;&lt;p class="p"&gt;::&lt;/p&gt;&lt;p class="n"&gt;Is64BitProcess&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Execution policy:  "&lt;/p&gt; &lt;p class="p"&gt;$(&lt;/p&gt;&lt;p class="nb"&gt;get-executionpolicy&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Arg1:              "&lt;/p&gt; &lt;p class="nv"&gt;$arg1&lt;/p&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Propagating failures&lt;/h3&gt;

&lt;p&gt;You need to ensure that PowerShell exits with an exit code that is not 0 in the event of a failure, this needs to cater to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Script errors&lt;/li&gt;
&lt;li&gt;External process calls that indicate failure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You will need to decide how to handle these failures and if they should indicate the PowerShell task has been successful
or not. This may mean that some script errors and external process calls failing is okay in your context.&lt;/p&gt;

&lt;p&gt;The following script demonstrates a strategy I use where I exit with a non zero code if any script error was encountered
or an external process call fails:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&lt;p class="nb"&gt;set-strictmode&lt;/p&gt; &lt;p class="n"&gt;-version&lt;/p&gt; &lt;p class="n"&gt;latest&lt;/p&gt;
&lt;p class="nv"&gt;$ErrorActionPreference&lt;/p&gt; &lt;p class="p"&gt;=&lt;/p&gt; &lt;p class="s1"&gt;'Stop'&lt;/p&gt;

&lt;p class="k"&gt;function&lt;/p&gt; &lt;p class="n"&gt;execute-externaltool&lt;/p&gt;
&lt;p class="p"&gt;(&lt;/p&gt;
    &lt;p class="no"&gt;[string]&lt;/p&gt; &lt;p class="nv"&gt;$context&lt;/p&gt;&lt;p class="p"&gt;,&lt;/p&gt;
    &lt;p class="no"&gt;[scriptblock]&lt;/p&gt; &lt;p class="nv"&gt;$actionBlock&lt;/p&gt;
&lt;p class="p"&gt;)&lt;/p&gt;
&lt;p class="p"&gt;{&lt;/p&gt;
    &lt;p class="c"&gt;# This function exists to check the exit code for the external tool called within the script block, so we don't have to do this for each call&lt;/p&gt;
    &lt;p class="p"&gt;&amp;amp;&lt;/p&gt; &lt;p class="nv"&gt;$actionBlock&lt;/p&gt;
    &lt;p class="k"&gt;if&lt;/p&gt; &lt;p class="p"&gt;(&lt;/p&gt;&lt;p class="nv"&gt;$LastExitCode&lt;/p&gt; &lt;p class="o"&gt;-gt&lt;/p&gt; &lt;p class="n"&gt;0&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt; &lt;p class="p"&gt;{&lt;/p&gt; &lt;p class="k"&gt;throw&lt;/p&gt; &lt;p class="s2"&gt;"$context : External tool call failed"&lt;/p&gt; &lt;p class="p"&gt;}&lt;/p&gt;
&lt;p class="p"&gt;}&lt;/p&gt;


&lt;p class="k"&gt;try&lt;/p&gt;
&lt;p class="p"&gt;{&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Script:            "&lt;/p&gt; &lt;p class="nv"&gt;$MyInvocation&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;MyCommand&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;Path&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Pid:               "&lt;/p&gt; &lt;p class="nv"&gt;$pid&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Host.Version:      "&lt;/p&gt; &lt;p class="nv"&gt;$host&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;version&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Execution policy:  "&lt;/p&gt; &lt;p class="p"&gt;$(&lt;/p&gt;&lt;p class="nb"&gt;get-executionpolicy&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt;

    &lt;p class="c"&gt;# Query a service that does not exist, sc.exe will return with a non 0 exit code&lt;/p&gt;
    &lt;p class="n"&gt;execute-externaltool&lt;/p&gt; &lt;p class="s2"&gt;"Query a non existent service, will return with exit code != 0"&lt;/p&gt; &lt;p class="p"&gt;{&lt;/p&gt; &lt;p class="n"&gt;c&lt;/p&gt;&lt;p class="err"&gt;:&lt;/p&gt;&lt;p class="p"&gt;\&lt;/p&gt;&lt;p class="n"&gt;windows&lt;/p&gt;&lt;p class="p"&gt;\&lt;/p&gt;&lt;p class="n"&gt;system32&lt;/p&gt;&lt;p class="p"&gt;\&lt;/p&gt;&lt;p class="n"&gt;sc&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;exe&lt;/p&gt; &lt;p class="n"&gt;query&lt;/p&gt; &lt;p class="n"&gt;service_does_not_exist&lt;/p&gt; &lt;p class="p"&gt;}&lt;/p&gt; 
&lt;p class="p"&gt;}&lt;/p&gt;
&lt;p class="k"&gt;catch&lt;/p&gt;
&lt;p class="p"&gt;{&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"$pid : Error caught - $_"&lt;/p&gt;
    &lt;p class="k"&gt;if&lt;/p&gt; &lt;p class="p"&gt;($?&lt;/p&gt; &lt;p class="o"&gt;-and&lt;/p&gt; &lt;p class="p"&gt;(&lt;/p&gt;&lt;p class="nb"&gt;test-path&lt;/p&gt; &lt;p class="n"&gt;variable&lt;/p&gt;&lt;p class="err"&gt;:&lt;/p&gt;&lt;p class="n"&gt;LastExitCode&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt; &lt;p class="o"&gt;-and&lt;/p&gt; &lt;p class="p"&gt;(&lt;/p&gt;&lt;p class="nv"&gt;$LastExitCode&lt;/p&gt; &lt;p class="o"&gt;-gt&lt;/p&gt; &lt;p class="n"&gt;0&lt;/p&gt;&lt;p class="p"&gt;))&lt;/p&gt; &lt;p class="p"&gt;{&lt;/p&gt; &lt;p class="n"&gt;exit&lt;/p&gt; &lt;p class="nv"&gt;$LastExitCode&lt;/p&gt; &lt;p class="p"&gt;}&lt;/p&gt;
    &lt;p class="k"&gt;else&lt;/p&gt; &lt;p class="p"&gt;{&lt;/p&gt; &lt;p class="n"&gt;exit&lt;/p&gt; &lt;p class="n"&gt;1&lt;/p&gt; &lt;p class="p"&gt;}&lt;/p&gt;
&lt;p class="p"&gt;}&lt;/p&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;This script uses a try catch block to handle all errors

&lt;ul&gt;
&lt;li&gt;The $? and $LastExitCode caters to both script and external process calls&lt;/li&gt;
&lt;li&gt;We fall back on an exit code of 1 if we do not have an external process exit code&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;This script uses an execute-externaltool function which takes a script block argument

&lt;ul&gt;
&lt;li&gt;The script will invoke the script block&lt;/li&gt;
&lt;li&gt;It will then check for a non zero exit code (Assumes the script block just calls an external process), if so it will throw an exception.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;See also&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://technet.microsoft.com/en-us/library/hh849812.aspx"&gt;PowerShell execution policy&lt;/a&gt;&lt;br&gt;
&lt;a href="https://blog.netspi.com/15-ways-to-bypass-the-powershell-execution-policy/"&gt;Bypassing PowerShell execution policy&lt;/a&gt;&lt;br&gt;
&lt;a href="https://codelucidate.wordpress.com/powershell/change-execution-policy-in-the-registry/"&gt;Setting execution policy directly in the registry&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/manojlds/gocd-powershell-runner"&gt;Go PowerShell runner plugin&lt;/a&gt; - I believe it can only be configured on Windows based Go servers  &lt;/p&gt;

&lt;h3&gt;About the author&lt;/h3&gt;

&lt;p&gt;This is a guest post by Pat Mc Grath. You can find Pat &lt;a href="https://github.com/pmcgrath"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Upcoming API Changes</title><link href="http://www.ciandcd.com/upcoming-api-changes.html" rel="alternate"></link><updated>2015-06-27T03:35:00+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:upcoming-api-changes.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/06/17/Upcoming-API-Changes.html"&gt;http://www.go.cd/2015/06/17/Upcoming-API-Changes.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;With the upcoming release of Go 15.2, we'd like to begin unifying and improving some of the existing APIs that Go supports.&lt;/p&gt;

&lt;p&gt;Go's APIs are fairly old, have &lt;a href="https://github.com/gocd/gocd/issues/572"&gt;inconsistent and unpredictable content types&lt;/a&gt; (csv, xml, json, plain text).&lt;/p&gt;

&lt;p&gt;Going forward, we would like to announce an ongoing effort to improve these APIs to use something that is more modern, easy to discover, learn and build API clients for.&lt;/p&gt;

&lt;p&gt;We would be using the &lt;a href="http://stateless.co/hal_specification.html"&gt;JSON HAL specification&lt;/a&gt;. Our API guidelines are &lt;a href="https://github.com/gocd/gocd/issues/1100"&gt;published on our RFC&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This will give us the opportunity to leverage Ruby and Rails to build these APIs, which should make it easier to incrementally iterate through and improve existing APIs to bring them to parity with our new guidelines.&lt;/p&gt;

&lt;p&gt;We welcome &lt;a href="https://github.com/gocd/gocd/issues/1100"&gt;any feedback&lt;/a&gt; to improve our guidelines and &lt;a href="https://github.com/gocd/gocd/issues?q=is%3Aopen+label%3Aapis+label%3Aenhancement"&gt;contributions&lt;/a&gt; to improve existing APIs.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Authentication end-point</title><link href="http://www.ciandcd.com/authentication-end-point.html" rel="alternate"></link><updated>2015-06-27T03:34:57+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:authentication-end-point.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/06/18/authentication-end-point.html"&gt;http://www.go.cd/2015/06/18/authentication-end-point.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Starting 15.2.0 Go Server will expose authentication end-point. What this means is Go users can add "custom" authentication schemes through plugins. With &lt;a href="http://www.go.cd/documentation/developer/writing_go_plugins/plugin_settings/plugin_settings_overview.html"&gt;plugin settings&lt;/a&gt; &amp;amp; &lt;a href="http://www.go.cd/documentation/developer/writing_go_plugins/handling_web_requests.html"&gt;web request handling ability&lt;/a&gt; plugin developers get enough flexibility to write any authentication plugin they intend to write.&lt;/p&gt;

&lt;p&gt;Examples of integrations possible:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OAuth Login - &lt;a href="https://github.com/srinivasupadhya/gocd-oauth-login"&gt;GitHub&lt;/a&gt;, &lt;a href="https://github.com/srinivasupadhya/gocd-oauth-login"&gt;Google&lt;/a&gt;, Hotmail, Yahoo! etc.&lt;/li&gt;
&lt;li&gt;Single Sign-on (SSO) - LDAP, Okta etc.&lt;/li&gt;
&lt;li&gt;2-factor authentication - SMS verification etc.&lt;/li&gt;
&lt;li&gt;Custom &lt;code&gt;username&lt;/code&gt; &amp;amp; &lt;code&gt;password&lt;/code&gt; authentication&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;How does it work?&lt;/h3&gt;

&lt;p&gt;Below is an explanation of how &lt;a href="https://github.com/srinivasupadhya/gocd-oauth-login"&gt;GitHub OAuth Login plugin&lt;/a&gt; works.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Generate OAuth token on GitHub.&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/generate-oauth-token.png" class="has_border full_size" alt="Figure 1: GitHub - Generate Oauth Token" id="mature_ci_cd_setup" title="GoCD - Generate Oauth Token"&gt;
  Figure 1: Generate oauth token &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;On plugin listing page users will see a gear icon (similar to one on the pipeline dashboard).&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/list-plugin.png" class="has_border full_size" alt="Figure 1: GoCD - Plugin Listing" id="mature_ci_cd_setup" title="GoCD - Plugin Listing"&gt;
  Figure 1: Plugin listing with gear icon &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Clicking on the gear icon opens a pop-up that renders "Plugin Settings".&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/configure-plugin.png" class="has_border full_size" alt="Figure 2: GoCD - Configure Plugin" id="mature_ci_cd_setup" title="GoCD - Configure Plugin"&gt;
  Figure 2: Configure plugin pop-up &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Login Page&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/login-page.png" class="has_border full_size" alt="Figure 2: GoCD - Login Page" id="mature_ci_cd_setup" title="GoCD - Login Page"&gt;
  Figure 3: Login Page with GitHub icon &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Click on GitHub icon&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/github-login.png" class="has_border full_size" alt="Figure 2: GoCD - Authorize Go Server on GitHub" id="mature_ci_cd_setup" title="GoCD - Authorize Go Server on GitHub"&gt;
  Figure 3: Authorize Go Server to access GitHub &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Successful login&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/successful-login.png" class="has_border full_size" alt="Figure 2: GoCD - On Successful Login" id="mature_ci_cd_setup" title="GoCD - On Successful Login"&gt;
  Figure 3: On successful login &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Ability to Search &amp;amp; Add users&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/search-user.png" class="has_border full_size" alt="Figure 2: GoCD - Search User" id="mature_ci_cd_setup" title="GoCD - Search User"&gt;
  Figure 3: Search User &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;We hope plugin developers are able to use this feature to support their organizations authentication mechanism.&lt;/p&gt;

&lt;h4&gt;References:&lt;/h4&gt;

 

 

 



&lt;p&gt;As always, Go questions can be asked on the &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Plugin Settings</title><link href="http://www.ciandcd.com/plugin-settings.html" rel="alternate"></link><updated>2015-06-27T03:34:55+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:plugin-settings.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/06/18/plugin-settings.html"&gt;http://www.go.cd/2015/06/18/plugin-settings.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Go is continously improving its plugin infrastructure. Starting 15.2.0 Go will support "Plugin Settings" that will allow plugins developers to accept global settings. Currently these configurations had to be supported via system properties or a file that is in specified format in a specified location, which makes it a little haphazard. With this feature "all" plugins will have one approach to accept plugins settings from user &amp;amp; access plugin settings from Go Server.&lt;/p&gt;

&lt;h3&gt;How does it work?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;On plugin listing page users will see a gear icon (similar to one on the pipeline dashboard) for the plugins that accept plugin settings.&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/plugin-settings/list-plugin.png" class="has_border full_size" alt="Figure 1: GoCD - Plugin Listing" id="mature_ci_cd_setup" title="GoCD - Plugin Listing"&gt;
  Figure 1: Plugin listing with gear icon &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Clicking on the gear icon opens a pop-up that renders "Plugin Settings" template that is provided by the plugin.&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/plugin-settings/configure-plugin.png" class="has_border full_size" alt="Figure 2: GoCD - Configure Plugin" id="mature_ci_cd_setup" title="GoCD - Configure Plugin"&gt;
  Figure 2: Configure plugin pop-up &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;On "Save" the user inputs are validated by plugin.&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/plugin-settings/configure-plugin-errors.png" class="has_border full_size" alt="Figure 2: GoCD - Configure Plugin Errors" id="mature_ci_cd_setup" title="GoCD - Configure Plugin Errors"&gt;
  Figure 3: Configure plugin pop-up with errors &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;We hope plugin developers are able to use this feature to provide a better experience to their users.&lt;/p&gt;

&lt;h4&gt;References:&lt;/h4&gt;

 

 

 



&lt;p&gt;As always, Go questions can be asked on the &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>Hardly Anyone Knows Continuous Delivery</title><link href="http://www.ciandcd.com/hardly-anyone-knows-continuous-delivery.html" rel="alternate"></link><updated>2015-06-27T03:34:54+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:hardly-anyone-knows-continuous-delivery.html</id><summary type="html">From:&lt;a href="http://www.go.cd/2015/06/23/hardly-anyone-knows-cd.html"&gt;http://www.go.cd/2015/06/23/hardly-anyone-knows-cd.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Those of us who work in or around teams doing continuous delivery often think it&amp;#8217;s a mainstream thing. This couldn&amp;#8217;t be further from the truth.&lt;/p&gt;

&lt;p&gt;I work for ThoughtWorks, a company that implements processes and technologies we think are good long before most. We built the first CI server with Cruise Control, and Go was the first purpose built Continuous Delivery server. I go to a lot of conferences and events, read a lot of blogs, talk to a lot of peers, work with a lot of partners, etc. I thought most people involved with the creation of software had a pretty good idea what CD is.&lt;/p&gt;

&lt;p&gt;I was wrong.&lt;/p&gt;

&lt;p&gt;I just got back from a pretty big software conference that was a bit off my normal track. They had a few DevOps sessions this year, but historically this particular conference has been more about agile methodologies. As one of the sponsors, I spent a lot of time at the booth talking to people.&lt;/p&gt;

&lt;p&gt;The conversations in a trade show booth generally start with the visitor asking what we do (gotta work more on that so they don&amp;#8217;t have to) and me telling them that Go is a continuous delivery server. From there we go on to talk about what makes Go unique and why they should use it.&lt;/p&gt;

&lt;p&gt;At this show, when I told people Go is a continuous delivery server I was met with mostly blank stares. This was a conference attended by 100% people who create software for a living. The people attending care enough about their craft to spend (or get their company to spend) a couple thousand US dollars to come. But they had no idea what Continuous Delivery really is. I probably should note, this isn't meant as a knock on that conference at all.&lt;/p&gt;

&lt;p&gt;The lack of knowledge is a really bad thing. Not just for the Go CD project, but for software in general. The world runs on software. Too much of that software is bad. The practices around Continuous Delivery could make some of it better, or kill it before it gets out.&lt;/p&gt;

&lt;h4&gt;So what can we do?&lt;/h4&gt;

&lt;p&gt;Buy or borrow a copy of &lt;a href="http://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912"&gt;Continuous Delivery&lt;/a&gt; by Jez Humble and Dave Farley for your office. Make everyone read at least the chapters that apply to them. Yes, Jez and Dave both worked for ThoughtWorks when they were writing the book. Yes, Jez was the product owner of Go before the book came out. No, we won't make any money off the link if you buy it. I promise this isn&amp;#8217;t bias, it&amp;#8217;s the definitive work on the subject.&lt;/p&gt;

&lt;p&gt;Get &lt;a href="http://www.amazon.com/The-Phoenix-Project-Helping-Business/dp/0988262509/ref=pd_bxgy_14_img_y"&gt;The Phoenix Project&lt;/a&gt; by Gene Kim. It&amp;#8217;s a fictional novel and a bit corny at times, but people will learn a bit even if they don&amp;#8217;t mean to.&lt;/p&gt;

&lt;p&gt;Send people that don&amp;#8217;t know about Continuous Delivery to conferences that are specific to CD and DevOps. My favorite is &lt;a href="http://www.devopsdays.org/"&gt;DevOpsDays&lt;/a&gt;. You don't need huge, expensive conferences where you&amp;#8217;ll have to get finance approval to attend. The next one I&amp;#8217;m going to is 200 bucks. If they don&amp;#8217;t have one in your area create one or find someone that will. (FYI, if anyone in Seattle is interested in doing that let me know)&lt;/p&gt;

&lt;p&gt;Take a friend who&amp;#8217;s CD impaired to a &lt;a href="http://devops.meetup.com/"&gt;DevOps Meetup&lt;/a&gt;. As I&amp;#8217;m writing this there are groups in 404 cities worldwide at that link alone. Trying to get your meetup going and struggling for content and/or speakers? Tell me, I know a few people and might be able to help.&lt;/p&gt;

&lt;p&gt;Stop assuming everyone knows what we&amp;#8217;re talking about when we talk about CD. Many of them are smiling and nodding the same way I do when my mother talks about her flowers.&lt;/p&gt;

&lt;p&gt;Feel free to comment with your own resource, this isn't even close to a definite list.&lt;/p&gt;

&lt;h4&gt;One last thing...&lt;/h4&gt;

&lt;p&gt;Stop telling people that the phrases DevOps and Continuous Delivery are overused. They aren&amp;#8217;t. Hardly anyone knows what Continuous Delivery is.&lt;/p&gt;

&lt;/div&gt;</summary></entry><entry><title>On Antifragility in Systems and Organizational Architecture</title><link href="http://www.ciandcd.com/on-antifragility-in-systems-and-organizational-architecture.html" rel="alternate"></link><updated>2015-06-27T03:32:09+08:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2015-06-27:on-antifragility-in-systems-and-organizational-architecture.html</id><summary type="html">From:&lt;a href="http://continuousdelivery.com/2013/01/on-antifragility-in-systems-and-organizational-architecture/"&gt;http://continuousdelivery.com/2013/01/on-antifragility-in-systems-and-organizational-architecture/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;On Antifragility in Systems and Organizational Architecture&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;In his new book, &lt;a href="http://www.amazon.com/dp/1400067820?tag=contindelive-20"&gt;Antifragile&lt;/a&gt;, Nassim Taleb discusses the behaviour of complex systems and distinguishes three kinds: those that are fragile, those that are robust or resilient, and those that are antifragile. These types of systems differ in how they respond to volatility: &amp;#8220;The fragile wants tranquility, the antifragile grows from disorder, and the robust doesn&amp;#8217;t care too much.&amp;#8221; (p20) Taleb argues that we want to create systems that are antifragile &amp;#8211; that are designed to take advantage of volatility. I think this concept is incredibly powerful when applied to systems and organizational architecture.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h3&gt;Why Continuous Delivery Works&lt;/h3&gt;
&lt;p&gt;Taleb shows why the traditional approach of operations &amp;#8211; making change hard, since change is risky &amp;#8211; is flawed: &amp;#8220;the problem with artificially suppressed volatility is not just that the system tends to become extremely fragile; it is that, at the same time, it exhibits no visible risks&amp;#8230; These artificially constrained systems become prone to Black Swans. Such environments eventually experience massive blowups&amp;#8230; catching everyone off guard and undoing years of stability or, in almost all cases, ending up far worse than they were in their initial volatile state&amp;#8221; (p105)&lt;a href="#1"&gt;1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This a great explanation of how many attempts to manage risk actually result in &lt;a href="http://continuousdelivery.com/2013/08/risk-management-theatre/"&gt;risk management theatre&lt;/a&gt; &amp;#8211; giving the appearance of effective risk management while actually making the system (and the organization) extremely fragile to unexpected events. It also explains why &lt;a href="http://www.amazon.com/dp/0321601912?tag=contindelive-20"&gt;continuous delivery&lt;/a&gt; works. The most important heuristic we describe in the book is &amp;#8220;if it hurts, do it more often, and bring the pain forward.&amp;#8221; The effect of following this principle is to exert a constant stress on your delivery and deployment process to reduce its fragility so that releasing becomes a boring, low-risk activity.&lt;/p&gt;
&lt;h3&gt;Antifragile Systems&lt;/h3&gt;
&lt;p&gt;Another of Taleb&amp;#8217;s key claims is that it is impossible to predict &amp;#8220;Black Swan&amp;#8221; events: &amp;#8220;you cannot say with any reliability that a certain remote event or shock is more likely than another&amp;#8230; but you can state with a lot more confidence that an object or a structure is more fragile than another should a certain event happen.&amp;#8221; (p8). Thus we need &amp;#8220;to switch the blame from the inability to see an event coming&amp;#8230; to the failure to understand (anti)fragility, namely, &amp;#8216;why did we build something so fragile to these types of events?&amp;#8217;&amp;#8221; (p136).&lt;/p&gt;
&lt;p&gt;Unlike risk, fragility is actually measurable. How do we measure the fragility of the systems we build? We try to break them, using techniques such as &lt;a href="http://queue.acm.org/detail.cfm?id=2371297"&gt;game days&lt;/a&gt; and systems like &lt;a href="http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html"&gt;chaos monkey&lt;/a&gt;. The systematic application of stress to your systems is essential &amp;#8211; not just to ensure your systems are antifragile, but to develop the muscles of the people who create and maintain them through constant practice. After all, it&amp;#8217;s the combination of the system and the people who build and run it that has the quality of antifragility.&lt;/p&gt;
&lt;p&gt;In this context, an important quality of legacy systems is their fragility. Legacy systems that aren&amp;#8217;t touched for a long time will turn into fragile &amp;#8220;works of art&amp;#8221;: changing them is considered risky, the number of people who understand the system decreases with time, and their knowledge atrophies from lack of exercise.&lt;/p&gt;
&lt;p&gt;How do we create antifragile systems? Apply stress to them continuously so we are forced to simplify, homogenise, and automate. &lt;/p&gt;
&lt;h3&gt;Antifragile Organizations&lt;/h3&gt;
&lt;p&gt;We can measure the fragility of an organization by how long it takes before it liquidates its assets. Deloitte&amp;#8217;s Shift Index shows that the average life expectancy of a Fortune 500 company has declined from around 75 years half a century ago to less than 15 years today.&lt;/p&gt;
&lt;p&gt;Start-ups are notoriously fragile. But the ones that survive and grow turn into something potentially more dangerous &amp;#8211; robust organizations. The problem with robust organizations is that they resist change. They aren&amp;#8217;t quickly killed by changes to their environment, but they don&amp;#8217;t adapt to them either &amp;#8211; they die slowly. We see this effect all the time &amp;#8211; changing the culture of an established organization is incredibly hard.&lt;/p&gt;
&lt;p&gt;Antifragile organizations are those that have a culture that enables them to learn fast from their environment and adapt to it so they can take advantage of volatility. Here are some characteristics of antifragile organizations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Systems thinking.&lt;/strong&gt; Everybody in the organization knows the goals of the organization and makes sure their work is directly contributing towards these goals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theory Y Management.&lt;/strong&gt; Management needs to assume employees are self-motivated and will be able to learn how to solve problems themselves. Organizations need to make sure they hire antifragile people who will thrive in this environment. As Daniel Pink&amp;#8217;s &lt;a href="http://www.amazon.com/dp/1594484805?tag=contindelive-20"&gt;Drive&lt;/a&gt; points out, giving your employees autonomy, purpose, and the opportunity to learn and master new skills is what stops them from quitting, thus increasing the antifragility of your organization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous experimentation.&lt;/strong&gt; As described in &lt;a href="http://www.amazon.com/dp/0071635238?tag=contindelive-20"&gt;Toyota Kata&lt;/a&gt;, good management knows that the best solutions come from the workers. They create an environment in which practitioners are able to run experiments to learn as rapidly as possible. The feedback loops in command and control organizations are too slow for them to adapt effectively.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disruptive product development.&lt;/strong&gt; Antifragile organizations aren&amp;#8217;t content with stress generated by their environment. Like humans exercising, they also try and disrupt themselves (the organizational equivalent of a game day). For example, &lt;a href="http://blogs.hbr.org/ideacast/2013/01/jeff-bezos-on-leading-for-the.html"&gt;Amazon cannibalized its own business&lt;/a&gt;, creating the Amazon Marketplace and the Kindle. Apple is &lt;a href="http://blogs.hbr.org/cs/2011/10/steve_jobs_solved_the_innovato.html"&gt;cannibalizing its Mac business&lt;/a&gt; with the iPad. Fragile organizations resist disrupting their own product lines, as &lt;a href="http://spectrum.ieee.org/semiconductors/processors/25-microchips-that-shook-the-world/5"&gt;Toshiba did at first with flash memory&lt;/a&gt;. If you do a good job at this you never need to worry about the competition &amp;#8211; you&amp;#8217;ll always beat them to it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Fragility and Agility&lt;/h3&gt;
&lt;p&gt;As Taleb points out, &amp;#8220;antifragility is desirable in general, but not always, as there are cases in which antifragility will be costly, extremely so. Further, it is hard to consider robustness as always desirable&amp;#8212;to quote Nietzsche, one can die from being immortal.&amp;#8221; (p22) Of course working out where on the spectrum you want your systems and your organization to lie is an art, and the great artists are those that know how to build systems, organizations, and products simply, quickly and cheaply so that they are antifragile with respect to our biggest enemy: time. How do they do that? Using the same heuristics described in &amp;#8220;antifragile organizations&amp;#8221;, above, which closely mirror the &lt;a href="http://itrevolution.com/the-three-ways-principles-underpinning-devops/"&gt;Three Ways of Devops&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As I read &lt;a href="http://www.amazon.com/dp/1400067820?tag=contindelive-20"&gt;Antifragile&lt;/a&gt;, it reminded me of something I read a number of years ago: Kent Beck and Cynthia Andres&amp;#8217; &lt;a href="http://www.amazon.com/dp/0321278658?tag=contindelive-20"&gt;Extreme Programming Explained&lt;/a&gt;. The subtitle? Embrace Change. It strikes me that the concept of antifragile is what we were aiming for with agile the whole time: building systems (including human systems &amp;#8211; organizations) that benefit from volatility.&lt;/p&gt;

&lt;h4&gt;Endnotes&lt;/h4&gt;
&lt;p&gt;Thanks to &lt;a href="https://twitter.com/badrij"&gt;Badrinath Janakiraman&lt;/a&gt; for feedback on an earlier draft of this post.&lt;/p&gt;
&lt;p&gt;&lt;a name="1"&gt;1&lt;/a&gt; He is talking about financial markets, which are rather less fragile than IT systems, hence his rather generous &amp;#8220;years of stability&amp;#8221;&lt;/p&gt;
&lt;/div&gt;</summary></entry><entry><title>Announcing FlowCon</title><link href="http://www.ciandcd.com/announcing-flowcon.html" rel="alternate"></link><updated>2013-05-22T05:32:42+00:00</updated><author><name>itech001</name></author><id>tag:www.ciandcd.com,2013-05-22:announcing-flowcon.html</id><summary type="html">from:http://continuousdelivery.com/2013/05/announcing-flowcon/&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Announcing FlowCon&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;I spend quite a lot of time at conferences, and it consistently bothers me that they are so often focused on one particular function: development, testing, UX, systems administration. The point of continuous delivery is to accelerate the rate at which we can learn from each other &amp;#8211; and from our customers. That requires everyone involved in the delivery process (including users, product owners and entrepreneurs) to collaborate throughout. So why isn&amp;#8217;t there a conference which focuses on flow &amp;#8211; the emergent property of great teams?&lt;/p&gt;
&lt;p&gt;So I got together with a bunch of like-minded folks &amp;#8211; &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Elizabeth+Hendrickson"&gt;Elisabeth Hendrickson&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Gene+Kim"&gt;Gene Kim&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/John+Esser"&gt;John Esser&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Lane+Halley"&gt;Lane Halley&lt;/a&gt; &amp;#8211; and now there is a conference about creating flow: &lt;a href="http://flowcon.org/"&gt;FlowCon&lt;/a&gt;. It&amp;#8217;s on &lt;strong&gt;Friday November 1 in San Francisco&lt;/strong&gt;, and it&amp;#8217;s produced by &lt;a href="http://www.thoughtworks.com/"&gt;ThoughtWorks&lt;/a&gt; and &lt;a href="http://www.trifork.com/"&gt;Trifork&lt;/a&gt; (creators of the &lt;a href="http://gotocon.com/"&gt;GOTO conferences&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;The conference is based around four values:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning&lt;/strong&gt;: Our goal is to provide the best possible conference forum for practitioners to learn from each other how to build great products and services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open Information&lt;/strong&gt;: We aim to uncover how great products and services are built in real life and make this information freely available to the widest audience possible.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Diversity&lt;/strong&gt;: We believe the technology community &amp;#8211; and thus the conference speakers and participants &amp;#8211; should reflect the demographics of our customers and the wider world.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spanning boundaries&lt;/strong&gt;: We believe that the best products and services are created collaboratively by people with a range of skills and experiences.&lt;/p&gt;
&lt;p&gt;We have put together nearly half of the &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;program&lt;/a&gt;, and we&amp;#8217;re delighted to announce that &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Adrian+Cockcroft"&gt;Adrian Cockcroft&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Catherine+Courage"&gt;Catherine Courage&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Jeff+Gothelf"&gt;Jeff Gothelf&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Linda+Rising"&gt;Linda Rising&lt;/a&gt; will be giving keynotes. &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;The program&lt;/a&gt; is still a work in process (a minimum viable product, if you will). In particular, the after lunch sessions are empty &amp;#8211; for a good reason: &lt;strong&gt;we want you to speak in those slots&lt;/strong&gt;. We&amp;#8217;re looking for people working to create flow in their organization &amp;#8211; especially those who:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Span multiple roles and work across organizational silos.&lt;/li&gt;
&lt;li&gt;Work in any of the following areas: a highly regulated environment; a large, traditional enterprise; in the pursuit of social and economic justice.&lt;/li&gt;
&lt;li&gt;Are willing to share obstacles encountered or mistakes made and how you overcame them &amp;#8211; whether cultural or technological.&lt;/li&gt;
&lt;li&gt;Offer actionable advice &amp;#8220;the rest of us&amp;#8221; can apply today (even if we don&amp;#8217;t have the resources of Etsy / Amazon / Google).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Your talk could be about culture, technology, design, process &amp;#8211; the only really important criterion is that it draws on what you&amp;#8217;ve learned about helping to create flow in your organization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If that sounds like you, please &lt;a href="http://flowcon.org/flowcon-sanfran-2013/submit"&gt;submit your proposal&lt;/a&gt;. If you know someone who would do a great job, please encourage them to submit. Our submission process is designed to be entirely merit-based, which means that the first round is anonymous. The deadline is midnight Pacific time, Sunday June 23, 2013.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://secure.trifork.com/flowcon-sanfran-2013/registration/"&gt;Tickets for the conference are now on sale&lt;/a&gt; &amp;#8211; at $350 if you register before July 31, or $500 if you register afterwards. Whatever your role or domain, you&amp;#8217;re sure to find inspirational, disruptive thinking that will make you better at creating great products and services. I hope to see you there!&lt;/p&gt;
&lt;/div&gt;</summary></entry></feed>